{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설치안되어있는경우 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 경고 메세지 무시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/train.csv\") # 학습용 데이터\n",
    "df_test = pd.read_csv(\"./data/submission.csv\") # 테스트 데이터(제출파일의 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bant_submit, business_unit, enterprise 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따로 처리한 부분 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_country, customer_country.1 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_customer_country_tokenized(df, column_name):\n",
    "    for i, entry in enumerate(df[column_name]):\n",
    "        if isinstance(entry, str):\n",
    "            tokens = [token.strip() for token in entry.replace('/', ',').split(',') if token.strip() != '']\n",
    "            if tokens:\n",
    "                df.at[i, column_name] = tokens[-1]\n",
    "            else:\n",
    "                df.at[i, column_name] = np.nan\n",
    "        else:\n",
    "            df.at[i, column_name] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer_country, customer_country.1 값을 토큰화 하여 말단 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = process_customer_country_tokenized(df_train, 'customer_country')\n",
    "df_train = process_customer_country_tokenized(df_train, 'customer_country.1')\n",
    "\n",
    "df_test = process_customer_country_tokenized(df_test, 'customer_country')\n",
    "df_test = process_customer_country_tokenized(df_test, 'customer_country.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미국 주 이름 카테고리화\n",
    "us_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "df_train['customer_country'] = df_train['customer_country'].replace(us_states, 'United States')\n",
    "df_train['customer_country.1'] = df_train['customer_country.1'].replace(us_states, 'United States')\n",
    "\n",
    "df_test['customer_country'] = df_test['customer_country'].replace(us_states, 'United States')\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].replace(us_states, 'United States')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LG 사이트에서 작성된 나라정보를 리스트화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 Test데이터셋 값중 Corporate은 특정 국가나 지역을 나타내는 것이 아니라,  \n",
    "보통 기업이나 조직을 나타내는 용어로 국가 리스트에 따로 포함시키지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "asia = ['Australia', 'Bangladesh', 'Brunei', 'Cambodia', 'China', 'Fiji', 'Hong Kong', 'India', 'Indonesia', 'Laos', 'Malaysia', 'Maldives', 'Myanmar', 'Nepal', 'New Zealand', 'Papula New Guinea', 'Philippines', 'Singapore', 'Sri Lanka', 'Taiwan', 'Thailand', 'Vietnam', 'Japan', 'South Korea']\n",
    "cis = ['Belarus', 'Kazakhstan', 'Mongolia', 'Russia', 'Turkmenistan', 'Ukraine', 'Uzbekistan']\n",
    "europe = ['Albania', 'Austria', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Cyprus', 'Czech', 'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Kosovo', 'Latvia', 'Lithuania', 'Luxembourg', 'Macedonia', 'Montenegro', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'United Kingdom', 'Isle of Man', 'Malta']\n",
    "latin_america_and_the_caribbean = ['Anguilla', 'Antigua', 'Argentina', 'Aruba', 'Bahamas', 'Barbados', 'Belize', 'Bermuda', 'Bolivia', 'Brazil', 'British Virgin Islands', 'Cayman Islands', 'Chile', 'Colombia', 'COLOMBIA', 'Costa Rica', 'Cuba', 'Curacao', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Grenada', 'Guatemala', 'Guyana Haiti', 'Honduras', 'Jamaica', 'Mexico', 'Netherlands Antilles', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'Puerto Rico', 'Saint Lucia', 'St Kitts', 'St Maarten', 'St Vincent', 'Suriname', 'Trinidad and Tobago', 'Turks and Caicos Islands', 'Uruguay', 'US Virgin Islands', 'Venezuela', 'Antigua and Barbuda', 'Saint Kitts and Nevis']\n",
    "middle_east_and_africa = ['Afghanistan', 'Algeria', 'Angola', 'Armenia', 'Azerbaijan', 'Bahrain', 'Benin', 'Botswana', 'Burkina Faso Cameroon', 'Central African Republic', 'Congo', \"Cote d'Ivoire\", 'Democratic Republic of the Congo', 'Djibouti', 'Egypt', 'EGYPT', 'Equatorial Guinea', 'Ethiopia', 'Gabon', 'Gambia', 'Georgia', 'Ghana', 'Guinea Iran', 'Iraq', 'Israel', 'Ivory Coast', 'Jordan', 'Kenya', 'Kuwait', 'Lebanon', 'Liberia', 'Mali', 'Mauritania', 'Mauritius', 'Morocco', 'Mozambique', 'Namibia', 'Nigeria', 'Oman', 'Pakistan', 'Palestine', 'Qatar', 'Rwanda', 'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Sierra Leone', 'Somalia', 'South Africa', 'Sudan', 'Swaziland', 'Syria', 'Togo', 'Tunisia', 'Türkiye', 'Turkey', 'U.A.E', 'Uganda', 'United Republic of Tanzania', 'Yemen', 'Zambia', 'Eritrea', 'Libya Malawi', 'Zimbabwe']\n",
    "north_america = ['Canada', 'United States', 'UNITED STATES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_country(country):\n",
    "    if country in asia:\n",
    "        return country\n",
    "    elif country in cis:\n",
    "        return country\n",
    "    elif country in europe:\n",
    "        return country\n",
    "    elif country in latin_america_and_the_caribbean:\n",
    "        return country\n",
    "    elif country in middle_east_and_africa:\n",
    "        return country\n",
    "    elif country in north_america:\n",
    "        return country\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_train['customer_country'] = df_train['customer_country'].apply(update_country)\n",
    "df_test['customer_country'] = df_test['customer_country'].apply(update_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_dict = {country: 'Asia' for country in asia}\n",
    "continent_dict.update({country: 'CIS' for country in cis})\n",
    "continent_dict.update({country: 'Europe' for country in europe})\n",
    "continent_dict.update({country: 'Latin America and the Caribbean' for country in latin_america_and_the_caribbean})\n",
    "continent_dict.update({country: 'Middle East & Africa' for country in middle_east_and_africa})\n",
    "continent_dict.update({country: 'North America' for country in north_america})\n",
    "\n",
    "df_train['customer_country.1'] = df_train['customer_country.1'].replace(continent_dict)\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].replace(continent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer_country.1 빈도수이하값 및 결측값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_country.1'의 빈도 계산\n",
    "counts_train = df_train['customer_country.1'].value_counts()\n",
    "counts_test = df_test['customer_country.1'].value_counts()\n",
    "\n",
    "# 일정 빈도 이하 unknown 처리\n",
    "find_count_train = counts_train[counts_train <= 30].index\n",
    "find_count_test = counts_test[counts_test <= 2].index\n",
    "\n",
    "# 일정 빈도 이하인 국가를 'Unknown'으로 설정\n",
    "df_train.loc[df_train['customer_country.1'].isin(find_count_train), 'customer_country.1'] = 'Other'\n",
    "df_test.loc[df_test['customer_country.1'].isin(find_count_test), 'customer_country.1'] = 'Other'\n",
    "\n",
    "# 결측값에 대한 처리\n",
    "df_train['customer_country.1'] = df_train['customer_country.1'].fillna('Unknown')\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "## {'Corporate'} 값이 test 데이터셋에는 존재하는 반면 train 데이터셋에는 없음\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['customer_country.1'].unique()\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_idx 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_idx'의 빈도 계산\n",
    "counts_train = df_train['customer_idx'].value_counts()\n",
    "\n",
    "# 일정 빈도 이하 처리\n",
    "find_count_train = counts_train[counts_train <= 10].index\n",
    "\n",
    "# 일정 빈도 이하인 customer_idx를 '-1'으로 설정\n",
    "df_train.loc[df_train['customer_idx'].isin(find_count_train), 'customer_idx'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return -1\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['customer_idx'].unique()\n",
    "df_test['customer_idx'] = df_test['customer_idx'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer_idx의 값에 대해서 is_converted에 대한 비율 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_idx' 카테고리별로 'is_converted'의 평균과 갯수를 계산\n",
    "idx_target = df_train.groupby('customer_idx')['is_converted'].agg(['mean', 'count']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계산한 비율에 대해서 customer_idx 값을 특정범위에 대한 범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mean' 값이 0.9보다 크면 1, 아니면 0을 부여\n",
    "idx_target['label'] = ((idx_target['mean'] > 0.99) & (idx_target['count'] >= 10)).astype(int)\n",
    "\n",
    "# 'idx_target'를 기준으로 'label' 값을 매핑\n",
    "idx_map = idx_target['label'].to_dict()\n",
    "\n",
    "# 'customer_idx' 열을 업데이트\n",
    "df_train['customer_idx_99'] = df_train['customer_idx'].map(idx_map)\n",
    "df_test['customer_idx_99'] = df_test['customer_idx'].map(idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mean' 값이 0.01보다 작으면 1, 아니면 0을 부여\n",
    "idx_target['label'] = ((idx_target['mean'] < 0.01)& (idx_target['count'] >= 10)).astype(int)\n",
    "\n",
    "# 'idx_target'를 기준으로 'label' 값을 매핑\n",
    "idx_map = idx_target['label'].to_dict()\n",
    "\n",
    "# 'customer_idx' 열을 업데이트\n",
    "df_train['customer_idx_001'] = df_train['customer_idx'].map(idx_map)\n",
    "df_test['customer_idx_001'] = df_test['customer_idx'].map(idx_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_type 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타나 연관 단어에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 재할당\n",
    "df_train['customer_type'] = df_train['customer_type'].replace({\n",
    "    'Others': 'Other',\n",
    "    'Etc.': 'Other',\n",
    "    'Software / Solution Provider': 'Software/Solution Provider',\n",
    "    'Specifier/ Influencer': 'Specifier/Influencer',\n",
    "    'Specifier / Influencer': 'Specifier/Influencer',\n",
    "    'Distributor': 'Dealer/Distributor',\n",
    "    'Homeowner': 'Home Owner',\n",
    "    'Manager / Director' : 'Manager/Director',\n",
    "    'Commercial end-user': 'End-user',\n",
    "    'End-Customer': 'End Customer',\n",
    "    'Consultant': 'Architect/Consultant',\n",
    "    'Installer': 'Specifier/Influencer',\n",
    "    'Installer/Contractor': 'Specifier/Influencer',\n",
    "    \n",
    "    # LG 카테고리 참고함\n",
    "    'Corporate' : 'End Customer',\n",
    "    'Dealer/Distributor' : 'Channel Partner',\n",
    "    'Reseller' : 'Channel Partner',\n",
    "    'Technician': 'Specifier/Influencer',\n",
    "    'Architect/Consultant': 'Specifier/Influencer',\n",
    "    'Developer': 'End Customer',  \n",
    "})\n",
    "\n",
    "df_test['customer_type'] = df_test['customer_type'].replace({\n",
    "    'Specifier/ Influencer': 'Specifier/Influencer',\n",
    "    'End-Customer': 'End Customer',\n",
    "\n",
    "    # LG 카테고리 참고함\n",
    "    'Developer': 'End Customer',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_type' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['customer_type'] = df_train['customer_type'].fillna('Unknown')\n",
    "df_test['customer_type'] = df_test['customer_type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 customer_type 값을 처리하는 과정에서  \n",
    "End Customer가 End-user에 해당한다는것을 알수 있음으로 값을 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 재할당\n",
    "df_train['customer_type'] = df_train['customer_type'].replace({\n",
    "    'End Customer': 'End-user'\n",
    "})\n",
    "df_test['customer_type'] = df_test['customer_type'].replace({\n",
    "    'End Customer': 'End-user'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### historical_existing_cnt 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median 값으로 대체(이때 median값은 4)\n",
    "cnt_train_med = df_train['historical_existing_cnt'].median()\n",
    "cnt_test_med = df_test['historical_existing_cnt'].median()\n",
    "\n",
    "# median 값으로 결측값 대체\n",
    "df_train['historical_existing_cnt'] = df_train['historical_existing_cnt'].fillna(cnt_train_med)\n",
    "df_test['historical_existing_cnt'] = df_test['historical_existing_cnt'].fillna(cnt_test_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id_strategic_ver, it_strategic_ver, idit_strategic_ver 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 값을 0으로 채우기\n",
    "df_train['id_strategic_ver'].fillna(0, inplace=True)\n",
    "df_train['it_strategic_ver'].fillna(0, inplace=True)\n",
    "df_train['idit_strategic_ver'].fillna(0, inplace=True)\n",
    "\n",
    "df_test['id_strategic_ver'].fillna(0, inplace=True)\n",
    "df_test['it_strategic_ver'].fillna(0, inplace=True)\n",
    "df_test['idit_strategic_ver'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_job 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타관련 값에 대한 변환  \n",
    "LG 홈페이지에서 제공된 job 리스트에 해당 안되는 값에 대한 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_job(customer_job):\n",
    "    # LG list 참고\n",
    "    job = ['accounting','administrative','arts and design','business development','community and social services','consulting','curation','education','engineering', 'entrepreneurship','finance','healthcare services','human resources','information technology','legal','marketing','media and communication','military and protective services operations','product management', 'program and project management','purchasing','quality assurance','real estate','research','sales','support','others']\n",
    "\n",
    "    # (오타변환)'media and communications'를 'media and communication'으로 변환\n",
    "    if customer_job == 'media and communications':\n",
    "        customer_job = 'media and communication'\n",
    "    \n",
    "    if not customer_job:\n",
    "        return 'others'\n",
    "    elif customer_job in job:\n",
    "        return customer_job\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "df_train['customer_job'] = df_train['customer_job'].apply(search_job)\n",
    "df_test['customer_job'] = df_test['customer_job'].apply(search_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lead_desc_length 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Max 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max 스케일링 \n",
    "min_value = df_train['lead_desc_length'].min()\n",
    "max_value = df_train['lead_desc_length'].max()\n",
    "\n",
    "df_train['lead_desc_length'] = (df_train['lead_desc_length'] - min_value) / (max_value - min_value)\n",
    "df_test['lead_desc_length'] = (df_test['lead_desc_length'] - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 값을 0으로 채우기\n",
    "df_train['lead_desc_length'].fillna(0, inplace=True)\n",
    "df_test['lead_desc_length'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inquiry_type 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타나 연관 단어에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'inquiry_type' 열의 철자오류에 대해 일관된 값으로 변환\n",
    "df_train['inquiry_type'] = df_train['inquiry_type'].replace({\n",
    "\n",
    "    'Quotation or purchase consultation': 'Quotation or Purchase Consultation',\n",
    "    'Request for quotation or purchase': 'Quotation or Purchase Consultation',\n",
    "    'quotation_or_purchase_consultation': 'Quotation or Purchase Consultation',\n",
    "    'quotation_': 'Quotation or Purchase Consultation',\n",
    "    'Purchase or Quotation': 'Quotation or Purchase Consultation',\n",
    "    'Quotation or Purchase consultation': 'Quotation or Purchase Consultation',\n",
    "    'Purchase': 'Quotation or Purchase Consultation',\n",
    "    'quotation_or_purchase_consultation': 'Quotation or Purchase Consultation',\n",
    "    'quotation_': 'Quotation or Purchase Consultation',\n",
    "    'quotation_': 'Quotation or Purchase Consultation',\n",
    "\n",
    "    'Usage or technical consultation': 'Usage or Technical Consultation',\n",
    "    'Technical Consultation': 'Usage or Technical Consultation',\n",
    "    'usage or technical consultation': 'Usage or Technical Consultation',\n",
    "    'usage_or_technical_consultation': 'Usage or Technical Consultation',\n",
    "    'Request for technical consulting': 'Usage or Technical Consultation',\n",
    "    'technical_consultation': 'Usage or Technical Consultation',\n",
    "    'technical': 'Usage or Technical Consultation',\n",
    "\n",
    "    'sales':'Sales Inquiry',\n",
    "    'Sales inquiry':'Sales Inquiry',\n",
    "\n",
    "    'other': 'Other',\n",
    "    'other_': 'Other',\n",
    "    'others': 'Other',\n",
    "    'Others' : 'Other',\n",
    "    'Etc.': 'Other',\n",
    "    'ETC.': 'Other'\n",
    "\n",
    "})\n",
    "\n",
    "df_test['inquiry_type'] = df_test['inquiry_type'].replace({\n",
    "\n",
    "    'Technical Consultation': 'Usage or Technical Consultation',\n",
    "\n",
    "    'other_': 'Other',\n",
    "    'Others' : 'Other',\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정값에 대한 처리('Other' 값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'inquiry_type' 열의 값별 개수를 계산합니다.\n",
    "value_counts = df_train['inquiry_type'].value_counts()\n",
    "\n",
    "# 2개 이하인 값들의 리스트를 만듭니다.\n",
    "to_replace = value_counts[value_counts <= 2].index\n",
    "\n",
    "# 2개 이하인 값들을 'Other'로 업데이트합니다.\n",
    "df_train['inquiry_type'] = df_train['inquiry_type'].replace(to_replace, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "## test 데이터셋 값중 {'Media Inquiry'} 값에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['inquiry_type'].unique()\n",
    "df_test['inquiry_type'] = df_test['inquiry_type'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체('Unknown' 값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'inquiry_type' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['inquiry_type'] = df_train['inquiry_type'].fillna('Unknown')\n",
    "df_test['inquiry_type'] = df_test['inquiry_type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### product_category 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정값에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_category'] = df_train['product_category'].replace({\n",
    "    'notebook': 'laptop',\n",
    "    'others': 'other',\n",
    "    'ess': 'other',\n",
    "    'signage care solution': 'other',\n",
    "})\n",
    "\n",
    "df_test['product_category'] = df_test['product_category'].replace({\n",
    "    'notebook': 'laptop',\n",
    "    'others': 'other',\n",
    "    'ess': 'other',\n",
    "    'signage care solution': 'other',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 빈도수 이하 값대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'product_category'의 빈도 계산\n",
    "counts_train = df_train['product_category'].value_counts()\n",
    "\n",
    "# 빈도가 특정수치 이하인 product_category 를 찾음\n",
    "find_count_train = counts_train[counts_train <= 15].index\n",
    "\n",
    "# 빈도가 특정수치 이하값 \n",
    "df_train.loc[df_train['product_category'].isin(find_count_train), 'product_category'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'product_category' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['product_category'] = df_train['product_category'].fillna('unknown')\n",
    "df_test['product_category'] = df_test['product_category'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### product_subcategory, product_modelname 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터셋에 없는 데이터에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "# product_subcategory 결측값 대체\n",
    "unique_subcategory = df_train['product_subcategory'].unique()\n",
    "df_test['product_subcategory'] = df_test['product_subcategory'].apply(lambda x: replace_unknown(x, unique_subcategory))\n",
    "\n",
    "# product_modelname 결측값 대체\n",
    "unique_modelname = df_train['product_modelname'].unique()\n",
    "df_test['product_modelname'] = df_test['product_modelname'].apply(lambda x: replace_unknown(x, unique_modelname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'product_subcategory' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['product_subcategory'] = df_train['product_subcategory'].fillna('Unknown')\n",
    "df_test['product_subcategory'] = df_test['product_subcategory'].fillna('Unknown')\n",
    "\n",
    "# 'product_modelname' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['product_modelname'] = df_train['product_modelname'].fillna('Unknown')\n",
    "df_test['product_modelname'] = df_test['product_modelname'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_position 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타에 대한 값이나 관련값으로 대체가능한 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['customer_position'] = df_train['customer_position'].replace({\n",
    "    'vicepresident': 'vice president',\n",
    "    'vp': 'vice president',\n",
    "    'entrylevel': 'entry level',\n",
    "    'c-levelexecutive': 'c-level executive',\n",
    "    'founder': 'ceo/founder',\n",
    "    'ceo/fundador': 'ceo/founder',\n",
    "    'commercial consultant': 'consultant',\n",
    "    'architect/consultant': 'consultant',\n",
    "    'architecture/consult': 'consultant',\n",
    "    'business unit director': 'director',\n",
    "    'no influence': 'none',\n",
    "    'not applicable': 'none',\n",
    "    'commercial end-user': 'end-user',\n",
    "    'exhibitiontv': 'exhibition',\n",
    "    'decision-influencer': 'decision influencer',\n",
    "    'sales': 'business development/sales',\n",
    "    'subsidiary sales (ise)': 'business development/sales',\n",
    "    'business development': 'business development/sales',\n",
    "    'medical device manufacturer': 'manufacturer',\n",
    "    'assistant professor of enlish': 'assistant professor',\n",
    "    'asst prof.': 'assistant professor',\n",
    "    'prof.': 'professor',\n",
    "    'professor of mathematics': 'professor',\n",
    "    'principal & director': 'director',\n",
    "    'others': 'other',\n",
    "    'decision-maker': 'decision maker',\n",
    "})\n",
    "\n",
    "df_test['customer_position'] = df_test['customer_position'].replace({\n",
    "    'vicepresident': 'vice president',\n",
    "    'vp': 'vice president',\n",
    "    'entrylevel': 'entry level',\n",
    "    'c-levelexecutive': 'c-level executive',\n",
    "    'founder': 'ceo/founder',\n",
    "    'ceo/fundador': 'ceo/founder',\n",
    "    'commercial consultant': 'consultant',\n",
    "    'architect/consultant': 'consultant',\n",
    "    'architecture/consult': 'consultant',\n",
    "    'business unit director': 'director',\n",
    "    'no influence': 'none',\n",
    "    'not applicable': 'none',\n",
    "    'commercial end-user': 'end-user',\n",
    "    'exhibitiontv': 'exhibition',\n",
    "    'decision-influencer': 'decision influencer',\n",
    "    'sales': 'business development/sales',\n",
    "    'subsidiary sales (ise)': 'business development/sales',\n",
    "    'business development': 'business development/sales',\n",
    "    'medical device manufacturer': 'manufacturer',\n",
    "    'assistant professor of enlish': 'assistant professor',\n",
    "    'asst prof.': 'assistant professor',\n",
    "    'prof.': 'professor',\n",
    "    'professor of mathematics': 'professor',\n",
    "    'principal & director': 'director',\n",
    "    'others': 'other'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 범주이하의 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "# 'inquiry_type' 열의 값별 개수 계산\n",
    "counts_train = df_train['customer_position'].value_counts()\n",
    "counts_test = df_test['customer_position'].value_counts()\n",
    "\n",
    "# 특정수 이하인 값들의 리스트로 만듬\n",
    "replace_train = counts_train[counts_train <= 40].index\n",
    "replace_test = counts_test[counts_test <= 2].index\n",
    "\n",
    "# 특정수 이하인 값들을 'other'로 업데이트\n",
    "df_train['customer_position'] = df_train['customer_position'].replace(replace_train, 'other')\n",
    "df_test['customer_position'] = df_test['customer_position'].replace(replace_test, 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### response_corporate 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 범주이하 값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'response_corporate'의 빈도 계산\n",
    "counts_train = df_train['response_corporate'].value_counts()\n",
    "\n",
    "# 빈도가 특정수치 이하인 product_category 를 찾음\n",
    "find_count_train = counts_train[counts_train <= 5].index\n",
    "\n",
    "# 빈도가 특정수치 이하값 \n",
    "df_train.loc[df_train['response_corporate'].isin(find_count_train), 'response_corporate'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터셋에 없는 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['response_corporate'].unique()\n",
    "df_test['response_corporate'] = df_test['response_corporate'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expected_timeline 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'months' , 'year'를 포함하는 값을 추출  \n",
    "(이때 해당안되는 값에 대해서는 etc 값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'months' , 'year' 포함하는 값 추출(아닌경우 'etc' 값으로 변환)\n",
    "df_train['expected_timeline'] = np.where(df_train['expected_timeline'].str.contains('months|year', na=False), df_train['expected_timeline'], 'etc.')\n",
    "df_test['expected_timeline'] = np.where(df_test['expected_timeline'].str.contains('months|year', na=False), df_test['expected_timeline'], 'etc.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추출한 값에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['expected_timeline'] = df_train['expected_timeline'].replace({\n",
    "    'less_than_3_months': 'less than 3 months',\n",
    "    '3_months_~_6_months': '3 months ~ 6 months',\n",
    "    '9_months_~_1_year': '9 months ~ 1 year',\n",
    "    'more_than_a_year': 'more than a year',\n",
    "    '6_months_~_9_months': '6 months ~ 9 months',\n",
    "    '9 months - 1 year': '9 months ~ 1 year',\n",
    "    'duplicate lead - il220100042906. less than 3 months': 'less than 3 months',\n",
    "    'less than 3 months ,meeting with the customer for the more details and tentative boq will ne 32 and 43': 'less than 3 months',\n",
    "\n",
    "    'less_than_3_months': 'less than 3 months',\n",
    "    'less than 3 months- outdoor led requiment': 'less than 3 months',\n",
    "    'need to discuss with client in next two months. they need to check the product and accridngly proceed for personal use.': 'less than 3 months',\n",
    "    'quotation sent – 75tr3dj , work in progress, he will buy after 2 months. he has not even seen the quote yet.': 'less than 3 months',\n",
    "    'quote shared with customer, he will confirm after 2 months. lead shared with partner.': 'less than 3 months',\n",
    "    'less than 3 months- outdoor led requiment': 'less than 3 months',\n",
    "    'less than 3 months. customer not answered . to call back': 'less than 3 months',\n",
    "\n",
    "    'purchase planning after 3 months': '3 months ~ 6 months',\n",
    "    'needs hotel tv after 4 months, will call us.': '3 months ~ 6 months',\n",
    "\n",
    "    'we are already in touch with this cutsomer from last 2 years, he has never purchased any product till date. i called him up twice but no reponse.' : 'etc.',\n",
    "    'very abrupt customer. said the inquiry was made months ago and was rude enough. closing in the system as the client behaviour has no scope to discuss on requirement. need marketing team to check if the case was received in dec or jan as per client.' : 'etc.',\n",
    "\n",
    "    # 아래 값들은 근사 기간으로 넣어줌\n",
    "    'more then 3 months': '3 months ~ 6 months',\n",
    "    'less than 5 months': '3 months ~ 6 months',\n",
    "    'less than 6 months': '3 months ~ 6 months',\n",
    "    'less then 6 months': '3 months ~ 6 months',\n",
    "    '3 months': '3 months ~ 6 months',\n",
    "    '4/8 months': '3 months ~ 6 months',\n",
    "\n",
    "})\n",
    "df_test['customer_position'] = df_test['customer_position'].replace({\n",
    "    'less_than_3_months': 'less than 3 months',\n",
    "    '3_months_~_6_months': '3 months ~ 6 months',\n",
    "    '9_months_~_1_year': '9 months ~ 1 year',\n",
    "    'more_than_a_year': 'more than a year',\n",
    "    '6_months_~_9_months': '6 months ~ 9 months'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver_cus, ver_pro 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따로처리할 부분 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver_win_rate_x 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ver_win_rate_x' 변수에서 NaN 값을 0으로 대체\n",
    "df_train['ver_win_rate_x'] = df_train['ver_win_rate_x'].fillna(0)\n",
    "df_test['ver_win_rate_x'] = df_test['ver_win_rate_x'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver_win_ratio_per_bu 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "business_area, business_unit 의 변수로 그룹화 진행  \n",
    "해당하는 그룹에서 'ver_win_ratio_per_bu' 의 결측값에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_train.groupby([\"business_area\",\"business_unit\"])\n",
    "\n",
    "# business_area, business_unit 그룹화하여 샘플 수 계산\n",
    "grouped_counts = df_train.groupby(['business_area', 'business_unit']).size()\n",
    "\n",
    "# business_area, business_unit, is_converted 그룹화하여 영업 전환된(is_converted) 샘플 수 계산\n",
    "converted_counts = df_train[df_train['is_converted']].groupby(['business_area', 'business_unit']).size()\n",
    "\n",
    "# business_area, business_unit별 샘플 수 대비 영업 전환된(is_converted) 샘플 수의 비율 계산\n",
    "conversion_rates = converted_counts / grouped_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 통해 구한 값에 대해서 해당하는 부분의 값이 결측값인 경우 값대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 값을 딕셔너리로 정의\n",
    "group_values = {\n",
    "    ('corporate / office', 'AS'): 0.029734,\n",
    "    ('corporate / office', 'ID'): 0.088618,\n",
    "    ('corporate / office', 'IT'): 0.033333,\n",
    "    ('corporate / office', 'Solution'): 0.034483,\n",
    "    ('education', 'AS'): 0.066667,\n",
    "    ('education', 'ID'): 0.064897,\n",
    "    ('education', 'IT'): 0.046667,\n",
    "    ('education', 'Solution'): None,\n",
    "    ('factory', 'AS'): 0.059553,\n",
    "    ('factory', 'ID'): 0.068519,\n",
    "    ('factory', 'IT'): 0.337349,\n",
    "    ('factory', 'Solution'): None,\n",
    "    ('government department', 'AS'): 0.040462,\n",
    "    ('government department', 'ID'): 0.076010,\n",
    "    ('government department', 'IT'): None,\n",
    "    ('government department', 'Solution'): None,\n",
    "    ('hospital & health care', 'AS'): 0.096154,\n",
    "    ('hospital & health care', 'ID'): 0.128378,\n",
    "    ('hospital & health care', 'IT'): 0.378771,\n",
    "    ('hotel & accommodation', 'AS'): 0.004831,\n",
    "    ('hotel & accommodation', 'ID'): 0.118902,\n",
    "    ('hotel & accommodation', 'IT'): 0.002528,\n",
    "    ('hotel & accommodation', 'Solution'): None,\n",
    "    ('power plant / renewable energy', 'AS'): 0.129032,\n",
    "    ('power plant / renewable energy', 'ID'): 0.279070,\n",
    "    ('power plant / renewable energy', 'IT'): None,\n",
    "    ('public facility', 'AS'): 0.030000,\n",
    "    ('public facility', 'ID'): 0.099631,\n",
    "    ('public facility', 'IT'): 0.025000,\n",
    "    ('public facility', 'Solution'): None,\n",
    "    ('residential (home)', 'AS'): 0.017582,\n",
    "    ('residential (home)', 'ID'): 0.038961,\n",
    "    ('residential (home)', 'IT'): 0.142857,\n",
    "    ('residential (home)', 'Solution'): None,\n",
    "    ('retail', 'AS'): 0.026650,\n",
    "    ('retail', 'ID'): 0.061637,\n",
    "    ('retail', 'IT'): 0.073620,\n",
    "    ('retail', 'Solution'): None,\n",
    "    ('special purpose', 'AS'): 0.028050,\n",
    "    ('special purpose', 'ID'): 0.070698,\n",
    "    ('special purpose', 'IT'): 0.046296,\n",
    "    ('special purpose', 'Solution'): None,\n",
    "    ('transportation', 'AS'): 0.037736,\n",
    "    ('transportation', 'ID'): 0.064815,\n",
    "    ('transportation', 'IT'): 0.060606,\n",
    "    ('transportation', 'Solution'): None,\n",
    "}\n",
    "\n",
    "# 'business_area'와 'business_unit'에 해당하는 그룹별 값을 'ver_win_ratio_per_bu' 변수에 적용\n",
    "df_train['ver_win_ratio_per_bu'] = df_train.apply(lambda row: group_values.get((row['business_area'], row['business_unit'])), axis=1)\n",
    "df_test['ver_win_ratio_per_bu'] = df_test.apply(lambda row: group_values.get((row['business_area'], row['business_unit'])), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 0값으로 대체\n",
    "df_train['ver_win_ratio_per_bu'].fillna(0, inplace=True)\n",
    "df_test['ver_win_ratio_per_bu'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### business_area, business_subarea 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 'unknown' 값으로 대체\n",
    "df_train['business_area'].fillna('unknown', inplace=True)\n",
    "df_test['business_area'].fillna('unknown', inplace=True)\n",
    "\n",
    "# 결측값 'Unknown' 값으로 대체\n",
    "df_train['business_subarea'].fillna('Unknown', inplace=True)\n",
    "df_test['business_subarea'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lead_owner 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 빈도수 이하 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lead_owner'의 빈도 계산\n",
    "counts_train = df_train['lead_owner'].value_counts()\n",
    "\n",
    "# 빈도가 특정수치 이하인 lead_owner 를 찾음\n",
    "find_count_train = counts_train[counts_train <= 10].index\n",
    "\n",
    "# 빈도가 특정수치 이하값 \n",
    "df_train.loc[df_train['lead_owner'].isin(find_count_train), 'lead_owner'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return -1\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['lead_owner'].unique()\n",
    "df_test['lead_owner'] = df_test['lead_owner'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lead_owner에 대하여 카테고리화하여 is_converted의 비율을 계산  \n",
    "계산한 값에대해서 특정 비율에 해당하는 값에대해서 범주화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_idx' 카테고리별로 'is_converted'의 평균과 갯수를 계산\n",
    "owner_target = df_train.groupby('lead_owner')['is_converted'].agg(['mean', 'count']).sort_values(by='mean', ascending=False)\n",
    "\n",
    "# 'mean' 값이 특정 값보다 크면 1, 아니면 0을 부여\n",
    "owner_target['label_09'] = (owner_target['mean'] > 0.9).astype(int)\n",
    "owner_target['label_07'] = ((0.9 >= owner_target['mean']) & (owner_target['mean'] > 0.7)).astype(int)\n",
    "owner_target['label_05'] = ((0.7 >= owner_target['mean']) & (owner_target['mean'] > 0.5)).astype(int)\n",
    "owner_target['label_03'] = ((0.5 >= owner_target['mean']) & (owner_target['mean'] > 0.3)).astype(int)\n",
    "owner_target['label_00'] = ((0.001 >= owner_target['mean']) & (owner_target['count'] <= 100)).astype(int)\n",
    "\n",
    "\n",
    "# 'owner_target'를 기준으로 'label' 값을 매핑\n",
    "label_map_09 = owner_target['label_09'].to_dict()\n",
    "label_map_07 = owner_target['label_07'].to_dict()\n",
    "label_map_05 = owner_target['label_05'].to_dict()\n",
    "label_map_03 = owner_target['label_03'].to_dict()\n",
    "label_map_00 = owner_target['label_00'].to_dict()\n",
    "\n",
    "\n",
    "# 'lead_owner' 열을 업데이트\n",
    "df_train['lead_owner_09'] = df_train['lead_owner'].map(label_map_09)\n",
    "df_train['lead_owner_07'] = df_train['lead_owner'].map(label_map_07)\n",
    "df_train['lead_owner_05'] = df_train['lead_owner'].map(label_map_05)\n",
    "df_train['lead_owner_03'] = df_train['lead_owner'].map(label_map_03)\n",
    "df_train['lead_owner_00'] = df_train['lead_owner'].map(label_map_00)\n",
    "\n",
    "df_test['lead_owner_09'] = df_test['lead_owner'].map(label_map_09)\n",
    "df_test['lead_owner_07'] = df_test['lead_owner'].map(label_map_07)\n",
    "df_test['lead_owner_05'] = df_test['lead_owner'].map(label_map_05)\n",
    "df_test['lead_owner_03'] = df_test['lead_owner'].map(label_map_03)\n",
    "df_test['lead_owner_00'] = df_test['lead_owner'].map(label_map_00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩할 컬럼 목록\n",
    "columns_to_encode = [\n",
    "    \"customer_country\",\n",
    "    \"business_subarea\",\n",
    "    \"business_area\",\n",
    "    \"business_unit\",\n",
    "    \"customer_type\",\n",
    "    \"enterprise\",\n",
    "    \"customer_job\",\n",
    "    \"inquiry_type\",\n",
    "    \"product_category\",\n",
    "    \"product_subcategory\",\n",
    "    \"product_modelname\",\n",
    "    \"customer_country.1\",\n",
    "    \"customer_position\",\n",
    "    \"response_corporate\",\n",
    "    \"expected_timeline\",\n",
    "]\n",
    "\n",
    "# df_train과 df_test를 복사하여 새로운 데이터프레임을 생성\n",
    "df_train_encoded = df_train.copy()\n",
    "df_test_encoded = df_test.copy()\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    df_train_encoded[col] = df_train_encoded[col].astype('category')\n",
    "    df_test_encoded[col] = df_test_encoded[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer_idx, customer_idx 변수의 경우 타겟변수인 is_converted의 비율계산을 통해  \n",
    "범주화한 변수를 생성하였음으로 drop을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = df_train_encoded.drop(['customer_idx', 'lead_owner'], axis=1)\n",
    "df_test_encoded = df_test_encoded.drop(['customer_idx', 'lead_owner'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟인코딩을 통해 범주형 변수들 수치형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "smoothing1_list = ['enterprise','response_corporate','business_unit','business_area']\n",
    "smoothing2_list = [item for item in columns_to_encode if item not in smoothing1_list]\n",
    "\n",
    "for col in smoothing1_list:\n",
    "    encoders = {col: TargetEncoder(smoothing=1) for col in smoothing1_list}\n",
    "    df_train_encoded[col] = encoders[col].fit_transform(df_train[col], df_train['is_converted'])\n",
    "    df_test_encoded[col] = encoders[col].transform(df_test[col])\n",
    "\n",
    "for col in smoothing2_list:\n",
    "    encoders = {col: TargetEncoder(smoothing=10) for col in smoothing2_list}\n",
    "    df_train_encoded[col] = encoders[col].fit_transform(df_train[col], df_train['is_converted'])\n",
    "    df_test_encoded[col] = encoders[col].transform(df_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### com_reg_ver_win_rate 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주형 데이터에 대해서 수치형으로 변환을 함  \n",
    "이에 com_reg_ver_win_rate 결측값에 대한 예측이 가능해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤포레스트의 회귀모델을 이용하여 결측값을 예측하여 결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    # 데이터에서 결측치가 없는 행과 결측치가 있는 행 분리\n",
    "    train_data = df[df['com_reg_ver_win_rate'].notna()]\n",
    "    test_data = df[df['com_reg_ver_win_rate'].isna()]\n",
    "\n",
    "    # 'com_reg_ver_win_rate'를 예측하는 데 사용할 피처 선택\n",
    "    features = ['business_area', 'business_unit', 'customer_country.1']   \n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 준비\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data['com_reg_ver_win_rate']\n",
    "    X_test = test_data[features]\n",
    "\n",
    "    # 랜덤 포레스트 모델 생성 및 훈련\n",
    "    model = RandomForestRegressor(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 모델을 사용해 결측치 예측\n",
    "    predicted_values = model.predict(X_test)\n",
    "\n",
    "    # 예측값으로 결측치 대체\n",
    "    df.loc[df['com_reg_ver_win_rate'].isna(), 'com_reg_ver_win_rate'] = predicted_values\n",
    "\n",
    "\n",
    "# df_train_encoded에 대한 데이터 처리\n",
    "fill_missing_values(df_train_encoded)\n",
    "\n",
    "# df_test_encoded에 대한 데이터 처리\n",
    "fill_missing_values(df_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상관관계와 다중공산성을 판단하여 결측값이 많은 product_modelname 변수와  \n",
    "의미없는 변수라고 생각되는 customer_country 변수에 대해서 drop을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = df_train_encoded.drop(['customer_country','product_modelname'], axis=1)\n",
    "df_test_encoded = df_test_encoded.drop(['customer_country','product_modelname'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59299 entries, 0 to 59298\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   bant_submit              59299 non-null  float64\n",
      " 1   business_unit            59299 non-null  float64\n",
      " 2   com_reg_ver_win_rate     59299 non-null  float64\n",
      " 3   customer_type            59299 non-null  float64\n",
      " 4   enterprise               59299 non-null  float64\n",
      " 5   historical_existing_cnt  59299 non-null  float64\n",
      " 6   id_strategic_ver         59299 non-null  float64\n",
      " 7   it_strategic_ver         59299 non-null  float64\n",
      " 8   idit_strategic_ver       59299 non-null  float64\n",
      " 9   customer_job             59299 non-null  float64\n",
      " 10  lead_desc_length         59299 non-null  float64\n",
      " 11  inquiry_type             59299 non-null  float64\n",
      " 12  product_category         59299 non-null  float64\n",
      " 13  product_subcategory      59299 non-null  float64\n",
      " 14  customer_country.1       59299 non-null  float64\n",
      " 15  customer_position        59299 non-null  float64\n",
      " 16  response_corporate       59299 non-null  float64\n",
      " 17  expected_timeline        59299 non-null  float64\n",
      " 18  ver_cus                  59299 non-null  int64  \n",
      " 19  ver_pro                  59299 non-null  int64  \n",
      " 20  ver_win_rate_x           59299 non-null  float64\n",
      " 21  ver_win_ratio_per_bu     59299 non-null  float64\n",
      " 22  business_area            59299 non-null  float64\n",
      " 23  business_subarea         59299 non-null  float64\n",
      " 24  is_converted             59299 non-null  bool   \n",
      " 25  customer_idx_99          59299 non-null  int64  \n",
      " 26  customer_idx_001         59299 non-null  int64  \n",
      " 27  lead_owner_09            59299 non-null  int64  \n",
      " 28  lead_owner_07            59299 non-null  int64  \n",
      " 29  lead_owner_05            59299 non-null  int64  \n",
      " 30  lead_owner_03            59299 non-null  int64  \n",
      " 31  lead_owner_00            59299 non-null  int64  \n",
      "dtypes: bool(1), float64(22), int64(9)\n",
      "memory usage: 14.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오버샘플링 및 언더샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟변수에 대한 값을 변환  \n",
    "(데이터의 오버샘플링과 언더샘플링을 적용하기 위함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 타겟변수에 대한 값 변환\n",
    "df_train_encoded.loc[df_train_encoded['is_converted'] == True, 'is_converted'] = 1\n",
    "df_train_encoded.loc[df_train_encoded['is_converted'] == False, 'is_converted'] = 0\n",
    "\n",
    "df_train_encoded['is_converted'] = df_train_encoded['is_converted'].astype(float)\n",
    "\n",
    "X = df_train_encoded[df_train_encoded.columns.drop('is_converted')]\n",
    "Y = df_train_encoded['is_converted']\n",
    "\n",
    "# X와 Y로 나누기\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_encoded.drop([\"is_converted\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# 오버샘플링과 언더샘플링\n",
    "# SMOTE와 RandomUnderSampler를 파이프라인으로 결합\n",
    "resample = Pipeline([('SMOTE', SMOTE(random_state=0)), \n",
    "                     ('RandomUnderSampler', RandomUnderSampler(random_state=0))])\n",
    "\n",
    "# 데이터에 오버샘플링과 언더샘플링 적용\n",
    "x_train, y_train = resample.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna를 이용하여 파라미터를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일모델\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# LightGBM_dart\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=1029\n",
    "    , num_leaves=167\n",
    "    , max_depth=30\n",
    "    , learning_rate=0.05767571715999541\n",
    "    , min_child_samples=25\n",
    "    , verbose=-1\n",
    "    , boosting='dart'  # dart 사용\n",
    "    , random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(boosting=&#x27;dart&#x27;, learning_rate=0.05767571715999541, max_depth=30,\n",
       "               min_child_samples=25, n_estimators=1029, num_leaves=167,\n",
       "               random_state=0, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boosting=&#x27;dart&#x27;, learning_rate=0.05767571715999541, max_depth=30,\n",
       "               min_child_samples=25, n_estimators=1029, num_leaves=167,\n",
       "               random_state=0, verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.05767571715999541, max_depth=30,\n",
       "               min_child_samples=25, n_estimators=1029, num_leaves=167,\n",
       "               random_state=0, verbose=-1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성능확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "오차행렬:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>807</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>150</td>\n",
       "      <td>10716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       True  False\n",
       "True    807    187\n",
       "False   150  10716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 지표:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정확도</th>\n",
       "      <th>정밀도</th>\n",
       "      <th>재현율</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971585</td>\n",
       "      <td>0.84326</td>\n",
       "      <td>0.811871</td>\n",
       "      <td>0.827268</td>\n",
       "      <td>0.97134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        정확도      정밀도       재현율  F1 Score  Weighted F1\n",
       "0  0.971585  0.84326  0.811871  0.827268      0.97134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
    "    weighted_F1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        '정확도': [accuracy],\n",
    "        '정밀도': [precision],\n",
    "        '재현율': [recall],\n",
    "        'F1 Score': [F1],\n",
    "        'Weighted F1': [weighted_F1]\n",
    "    })\n",
    "\n",
    "    confusion_df = pd.DataFrame(confusion, index=['True', 'False'], columns=['True', 'False'])\n",
    "\n",
    "    print(\"\\n오차행렬:\")\n",
    "    display(confusion_df)\n",
    "    print(\"평가 지표:\")\n",
    "    display(metrics)\n",
    "\n",
    "pred = model.predict(x_val)\n",
    "get_clf_eval(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_encoded.drop([\"is_converted\", \"id\"], axis=1)\n",
    "\n",
    "test_pred = model.predict(x_test)\n",
    "sum(test_pred) # True로 예측된 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"is_converted\"] = test_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission_total.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
