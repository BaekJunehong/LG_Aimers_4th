{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "acdab431",
      "metadata": {
        "id": "acdab431"
      },
      "source": [
        "## 1. 데이터 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b8341e8",
      "metadata": {
        "id": "2b8341e8"
      },
      "source": [
        "### 필수 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a315cc58",
      "metadata": {
        "id": "a315cc58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_49256\\4117284284.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # 경고 메세지 무시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "38ccd6b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_origin = pd.read_csv(\"data/train.csv\") # 학습용 데이터\n",
        "df_test_origin = pd.read_csv(\"data/submission.csv\") # 테스트 데이터(제출파일의 데이터)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0b323c11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59299 entries, 0 to 59298\n",
            "Data columns (total 29 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   bant_submit              59299 non-null  float64\n",
            " 1   customer_country         58317 non-null  object \n",
            " 2   business_unit            59299 non-null  object \n",
            " 3   com_reg_ver_win_rate     14568 non-null  float64\n",
            " 4   customer_idx             59299 non-null  int64  \n",
            " 5   customer_type            15338 non-null  object \n",
            " 6   enterprise               59299 non-null  object \n",
            " 7   historical_existing_cnt  13756 non-null  float64\n",
            " 8   id_strategic_ver         3444 non-null   float64\n",
            " 9   it_strategic_ver         1121 non-null   float64\n",
            " 10  idit_strategic_ver       4565 non-null   float64\n",
            " 11  customer_job             40566 non-null  object \n",
            " 12  lead_desc_length         59299 non-null  int64  \n",
            " 13  inquiry_type             58358 non-null  object \n",
            " 14  product_category         39925 non-null  object \n",
            " 15  product_subcategory      9235 non-null   object \n",
            " 16  product_modelname        9229 non-null   object \n",
            " 17  customer_country.1       58317 non-null  object \n",
            " 18  customer_position        59299 non-null  object \n",
            " 19  response_corporate       59299 non-null  object \n",
            " 20  expected_timeline        28436 non-null  object \n",
            " 21  ver_cus                  59299 non-null  int64  \n",
            " 22  ver_pro                  59299 non-null  int64  \n",
            " 23  ver_win_rate_x           18417 non-null  float64\n",
            " 24  ver_win_ratio_per_bu     15304 non-null  float64\n",
            " 25  business_area            18417 non-null  object \n",
            " 26  business_subarea         5526 non-null   object \n",
            " 27  lead_owner               59299 non-null  int64  \n",
            " 28  is_converted             59299 non-null  bool   \n",
            "dtypes: bool(1), float64(8), int64(5), object(15)\n",
            "memory usage: 12.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train_origin.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af526c13",
      "metadata": {
        "id": "af526c13"
      },
      "source": [
        "## 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc30f10",
      "metadata": {
        "id": "2cc30f10"
      },
      "source": [
        "### 각 변수별 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "596c0909",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_process = pd.read_csv('data/Ch2/df_train.csv')\n",
        "df_test_process = pd.read_csv('data/Ch2/df_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e0437e17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59299 entries, 0 to 59298\n",
            "Data columns (total 29 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   bant_submit              59299 non-null  float64\n",
            " 1   customer_country         59299 non-null  object \n",
            " 2   business_unit            59299 non-null  object \n",
            " 3   com_reg_ver_win_rate     14568 non-null  float64\n",
            " 4   customer_idx             59299 non-null  int64  \n",
            " 5   customer_type            59299 non-null  object \n",
            " 6   enterprise               59299 non-null  object \n",
            " 7   historical_existing_cnt  59299 non-null  float64\n",
            " 8   id_strategic_ver         59299 non-null  float64\n",
            " 9   it_strategic_ver         59299 non-null  float64\n",
            " 10  idit_strategic_ver       59299 non-null  float64\n",
            " 11  customer_job             59299 non-null  object \n",
            " 12  lead_desc_length         59299 non-null  int64  \n",
            " 13  inquiry_type             59299 non-null  object \n",
            " 14  product_category         59299 non-null  object \n",
            " 15  product_subcategory      59299 non-null  object \n",
            " 16  product_modelname        59299 non-null  object \n",
            " 17  customer_country.1       59299 non-null  object \n",
            " 18  customer_position        59299 non-null  object \n",
            " 19  response_corporate       59299 non-null  object \n",
            " 20  expected_timeline        59299 non-null  object \n",
            " 21  ver_cus                  59299 non-null  int64  \n",
            " 22  ver_pro                  59299 non-null  int64  \n",
            " 23  ver_win_rate_x           59299 non-null  float64\n",
            " 24  ver_win_ratio_per_bu     59299 non-null  float64\n",
            " 25  business_area            59299 non-null  object \n",
            " 26  business_subarea         59299 non-null  object \n",
            " 27  lead_owner               59299 non-null  int64  \n",
            " 28  is_converted             59299 non-null  bool   \n",
            "dtypes: bool(1), float64(8), int64(5), object(15)\n",
            "memory usage: 12.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train_process.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08efd9a3",
      "metadata": {},
      "source": [
        "## 3. 피처엔지니어링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd47e00",
      "metadata": {
        "id": "4bd47e00"
      },
      "source": [
        "### 레이블 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b53d4d09",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_encoded = pd.read_csv('data/Ch3/df_train.csv')\n",
        "df_test_encoded = pd.read_csv('data/Ch3/df_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ca62d87e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59299 entries, 0 to 59298\n",
            "Data columns (total 24 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   bant_submit               59299 non-null  float64\n",
            " 1   customer_country          59299 non-null  int64  \n",
            " 2   business_unit             59299 non-null  int64  \n",
            " 3   com_reg_ver_win_rate      59299 non-null  float64\n",
            " 4   customer_idx              59299 non-null  int64  \n",
            " 5   customer_type             59299 non-null  int64  \n",
            " 6   enterprise                59299 non-null  int64  \n",
            " 7   historical_existing_cnt   59299 non-null  float64\n",
            " 8   customer_job              59299 non-null  int64  \n",
            " 9   lead_desc_length          59299 non-null  int64  \n",
            " 10  customer_country.1        59299 non-null  int64  \n",
            " 11  customer_position         59299 non-null  int64  \n",
            " 12  response_corporate        59299 non-null  int64  \n",
            " 13  expected_timeline         59299 non-null  int64  \n",
            " 14  lead_owner                59299 non-null  int64  \n",
            " 15  is_converted              59299 non-null  bool   \n",
            " 16  id_business_area          59299 non-null  float64\n",
            " 17  it_business_area          59299 non-null  float64\n",
            " 18  idit_business_area        59299 non-null  float64\n",
            " 19  ver_cus_business_area     59299 non-null  int64  \n",
            " 20  ver_pro_product_category  59299 non-null  int64  \n",
            " 21  ver_win_business_area     59299 non-null  float64\n",
            " 22  ver_ratio_business_area   59299 non-null  float64\n",
            " 23  category_modelname        59299 non-null  int64  \n",
            "dtypes: bool(1), float64(8), int64(15)\n",
            "memory usage: 10.5 MB\n"
          ]
        }
      ],
      "source": [
        "df_train_encoded.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ecfa9b",
      "metadata": {
        "id": "79ecfa9b"
      },
      "source": [
        "## 4. 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549e5839",
      "metadata": {},
      "source": [
        "### 데이터 분할"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "260c49ec",
      "metadata": {},
      "source": [
        "학습, 검증 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7af1b057",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    df_train_encoded.drop(\"is_converted\", axis=1),\n",
        "    df_train_encoded[\"is_converted\"],\n",
        "    test_size=0.2,\n",
        "    shuffle=True,\n",
        "    random_state=400,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "295c9479",
      "metadata": {
        "id": "295c9479"
      },
      "source": [
        "### 모델 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b97e189",
      "metadata": {
        "id": "2b97e189"
      },
      "source": [
        "#### 단일모델 기준으로 사용할수 있는 모델들의 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b870e254",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# 보팅\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "# 스테킹\n",
        "from sklearn.ensemble import StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed61ca3",
      "metadata": {},
      "outputs": [],
      "source": [
        "break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3caf257b",
      "metadata": {
        "id": "3caf257b"
      },
      "source": [
        "### 최적 하이퍼 파라미터 찾기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bd19c1",
      "metadata": {
        "id": "c9bd19c1"
      },
      "source": [
        "#### optuna를 통한 최적의 파라미터 찾기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "926b9b02",
      "metadata": {},
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "71289338",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 20:56:00,741] A new study created in memory with name: no-name-0b67fc6c-954f-4e89-9045-4526584049f4\n",
            "[W 2024-02-17 20:56:06,129] Trial 0 failed with parameters: {'n_estimators': 729, 'max_depth': 28, 'min_samples_split': 16, 'min_samples_leaf': 15, 'criterion': 'entropy'} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_33336\\4050503408.py\", line 32, in <lambda>\n",
            "    study.optimize(lambda trial: objectiveRF(trial, x_train, y_train, x_val, y_val), n_trials=50)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_33336\\4050503408.py\", line 23, in objectiveRF\n",
            "    model.fit(x_tr, y_tr)\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
            "    trees = Parallel(\n",
            "            ^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1863, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1792, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
            "    tree._fit(\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
            "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
            "KeyboardInterrupt\n",
            "[W 2024-02-17 20:56:06,135] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 하이퍼 파라미터 튜닝\u001b[39;00m\n\u001b[0;32m     31\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 32\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjectiveRF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial: score \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mparams \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams))\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 하이퍼 파라미터 튜닝\u001b[39;00m\n\u001b[0;32m     31\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 32\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjectiveRF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial: score \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mparams \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams))\n",
            "Cell \u001b[1;32mIn[10], line 23\u001b[0m, in \u001b[0;36mobjectiveRF\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     12\u001b[0m criterion \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[0;32m     15\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m     16\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_val)\n\u001b[0;32m     25\u001b[0m score \u001b[38;5;241m=\u001b[39m f1_score(y_val, pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "def objectiveRF(trial, x_tr, y_tr, x_val, y_val):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 400, 1000)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 35)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 10, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 8, 20)\n",
        "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        criterion=criterion,\n",
        "        random_state=0\n",
        "    )\n",
        "\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveRF(trial, x_train, y_train, x_val, y_val), n_trials=50)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2d2d36",
      "metadata": {},
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "038aa9b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-18 14:01:04,993] A new study created in memory with name: no-name-b273e4f3-fc1c-4eeb-91f1-4ba7ff2c1666\n",
            "[I 2024-02-18 14:01:08,875] Trial 0 finished with value: 0.9749413873456999 and parameters: {'num_leaves': 310, 'max_depth': 12, 'n_estimators': 762, 'learning_rate': 0.05903948646972072, 'min_child_samples': 23}. Best is trial 0 with value: 0.9749413873456999.\n",
            "[I 2024-02-18 14:01:11,627] Trial 1 finished with value: 0.9760634541025287 and parameters: {'num_leaves': 329, 'max_depth': 9, 'n_estimators': 935, 'learning_rate': 0.09672964844509264, 'min_child_samples': 23}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:14,623] Trial 2 finished with value: 0.9749834384484493 and parameters: {'num_leaves': 359, 'max_depth': 10, 'n_estimators': 741, 'learning_rate': 0.0933036974463395, 'min_child_samples': 16}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:15,610] Trial 3 finished with value: 0.9747332021713773 and parameters: {'num_leaves': 217, 'max_depth': 5, 'n_estimators': 900, 'learning_rate': 0.08003410758548654, 'min_child_samples': 33}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:19,656] Trial 4 finished with value: 0.9752930871724269 and parameters: {'num_leaves': 396, 'max_depth': 13, 'n_estimators': 677, 'learning_rate': 0.08024762586578099, 'min_child_samples': 17}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:21,004] Trial 5 finished with value: 0.9750681403569933 and parameters: {'num_leaves': 328, 'max_depth': 6, 'n_estimators': 967, 'learning_rate': 0.056966348957506456, 'min_child_samples': 23}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:24,378] Trial 6 finished with value: 0.9756848138663954 and parameters: {'num_leaves': 253, 'max_depth': 13, 'n_estimators': 674, 'learning_rate': 0.061159055398178376, 'min_child_samples': 15}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:27,548] Trial 7 finished with value: 0.9753482995769152 and parameters: {'num_leaves': 324, 'max_depth': 11, 'n_estimators': 770, 'learning_rate': 0.09493732706631618, 'min_child_samples': 29}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:30,006] Trial 8 finished with value: 0.973606201186508 and parameters: {'num_leaves': 272, 'max_depth': 9, 'n_estimators': 819, 'learning_rate': 0.015420292446634285, 'min_child_samples': 29}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:30,890] Trial 9 finished with value: 0.9724350871998716 and parameters: {'num_leaves': 334, 'max_depth': 7, 'n_estimators': 477, 'learning_rate': 0.03838855158317655, 'min_child_samples': 22}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:33,774] Trial 10 finished with value: 0.9752260054008168 and parameters: {'num_leaves': 388, 'max_depth': 15, 'n_estimators': 412, 'learning_rate': 0.03086461804368433, 'min_child_samples': 27}. Best is trial 1 with value: 0.9760634541025287.\n",
            "[I 2024-02-18 14:01:35,207] Trial 11 finished with value: 0.9761841844753832 and parameters: {'num_leaves': 260, 'max_depth': 8, 'n_estimators': 578, 'learning_rate': 0.07095170072154812, 'min_child_samples': 18}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:36,601] Trial 12 finished with value: 0.9754972693869687 and parameters: {'num_leaves': 272, 'max_depth': 8, 'n_estimators': 550, 'learning_rate': 0.07797633087919414, 'min_child_samples': 19}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:38,045] Trial 13 finished with value: 0.9756588356035165 and parameters: {'num_leaves': 203, 'max_depth': 8, 'n_estimators': 591, 'learning_rate': 0.07082145625556208, 'min_child_samples': 19}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:41,528] Trial 14 finished with value: 0.9749834384484493 and parameters: {'num_leaves': 287, 'max_depth': 10, 'n_estimators': 989, 'learning_rate': 0.09578542860629202, 'min_child_samples': 20}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:42,900] Trial 15 finished with value: 0.9742955579218366 and parameters: {'num_leaves': 233, 'max_depth': 8, 'n_estimators': 567, 'learning_rate': 0.039230058776240626, 'min_child_samples': 26}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:44,137] Trial 16 finished with value: 0.9752424890258254 and parameters: {'num_leaves': 359, 'max_depth': 6, 'n_estimators': 868, 'learning_rate': 0.06912639789099183, 'min_child_samples': 21}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:46,051] Trial 17 finished with value: 0.9748663619022726 and parameters: {'num_leaves': 245, 'max_depth': 9, 'n_estimators': 636, 'learning_rate': 0.08901365156610241, 'min_child_samples': 25}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:47,730] Trial 18 finished with value: 0.9761032360892211 and parameters: {'num_leaves': 299, 'max_depth': 10, 'n_estimators': 473, 'learning_rate': 0.04760026850632489, 'min_child_samples': 35}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:49,754] Trial 19 finished with value: 0.9754565180025648 and parameters: {'num_leaves': 295, 'max_depth': 11, 'n_estimators': 479, 'learning_rate': 0.044791332230279424, 'min_child_samples': 35}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:52,369] Trial 20 finished with value: 0.9757801927384016 and parameters: {'num_leaves': 265, 'max_depth': 14, 'n_estimators': 493, 'learning_rate': 0.04847257157296236, 'min_child_samples': 32}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:54,122] Trial 21 finished with value: 0.9739009315803585 and parameters: {'num_leaves': 306, 'max_depth': 9, 'n_estimators': 523, 'learning_rate': 0.028064921526238563, 'min_child_samples': 18}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:55,990] Trial 22 finished with value: 0.9749554393952936 and parameters: {'num_leaves': 286, 'max_depth': 11, 'n_estimators': 414, 'learning_rate': 0.06921111553280575, 'min_child_samples': 24}. Best is trial 11 with value: 0.9761841844753832.\n",
            "[I 2024-02-18 14:01:57,101] Trial 23 finished with value: 0.9764243088895003 and parameters: {'num_leaves': 342, 'max_depth': 7, 'n_estimators': 593, 'learning_rate': 0.08614597651948248, 'min_child_samples': 28}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:01:58,224] Trial 24 finished with value: 0.9740251342411844 and parameters: {'num_leaves': 355, 'max_depth': 7, 'n_estimators': 611, 'learning_rate': 0.05049882603268707, 'min_child_samples': 30}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:01:59,403] Trial 25 finished with value: 0.9748777610168736 and parameters: {'num_leaves': 345, 'max_depth': 7, 'n_estimators': 642, 'learning_rate': 0.06429497809979917, 'min_child_samples': 31}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:01:59,918] Trial 26 finished with value: 0.9718876657030547 and parameters: {'num_leaves': 312, 'max_depth': 5, 'n_estimators': 448, 'learning_rate': 0.08588518062548654, 'min_child_samples': 35}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:00,697] Trial 27 finished with value: 0.9741256557430192 and parameters: {'num_leaves': 236, 'max_depth': 6, 'n_estimators': 538, 'learning_rate': 0.07475600330665055, 'min_child_samples': 28}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:02,076] Trial 28 finished with value: 0.9762078869832229 and parameters: {'num_leaves': 379, 'max_depth': 8, 'n_estimators': 592, 'learning_rate': 0.08265940884941869, 'min_child_samples': 33}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:03,315] Trial 29 finished with value: 0.9757638238945749 and parameters: {'num_leaves': 379, 'max_depth': 7, 'n_estimators': 697, 'learning_rate': 0.08622118520770874, 'min_child_samples': 32}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:05,061] Trial 30 finished with value: 0.976411371563894 and parameters: {'num_leaves': 374, 'max_depth': 8, 'n_estimators': 730, 'learning_rate': 0.08353963240952186, 'min_child_samples': 25}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:06,823] Trial 31 finished with value: 0.97588550470844 and parameters: {'num_leaves': 372, 'max_depth': 8, 'n_estimators': 739, 'learning_rate': 0.08299049131277268, 'min_child_samples': 26}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:08,842] Trial 32 finished with value: 0.9750528288843519 and parameters: {'num_leaves': 374, 'max_depth': 8, 'n_estimators': 588, 'learning_rate': 0.0744960718258196, 'min_child_samples': 33}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:15,172] Trial 33 finished with value: 0.9759811376365077 and parameters: {'num_leaves': 397, 'max_depth': 9, 'n_estimators': 795, 'learning_rate': 0.0901528959817531, 'min_child_samples': 28}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:17,467] Trial 34 finished with value: 0.9739076726972948 and parameters: {'num_leaves': 352, 'max_depth': 6, 'n_estimators': 640, 'learning_rate': 0.0643487736713547, 'min_child_samples': 24}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:20,717] Trial 35 finished with value: 0.9760881359764677 and parameters: {'num_leaves': 368, 'max_depth': 7, 'n_estimators': 720, 'learning_rate': 0.07678486434662112, 'min_child_samples': 33}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:22,432] Trial 36 finished with value: 0.9740923953926821 and parameters: {'num_leaves': 384, 'max_depth': 5, 'n_estimators': 668, 'learning_rate': 0.09954693101161433, 'min_child_samples': 30}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:28,264] Trial 37 finished with value: 0.975537718658853 and parameters: {'num_leaves': 343, 'max_depth': 9, 'n_estimators': 608, 'learning_rate': 0.0822764825751308, 'min_child_samples': 16}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:34,352] Trial 38 finished with value: 0.9752004381294069 and parameters: {'num_leaves': 316, 'max_depth': 10, 'n_estimators': 521, 'learning_rate': 0.09184104183658166, 'min_child_samples': 21}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:39,524] Trial 39 finished with value: 0.9755778688851935 and parameters: {'num_leaves': 365, 'max_depth': 8, 'n_estimators': 850, 'learning_rate': 0.08510940507062578, 'min_child_samples': 23}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:41,858] Trial 40 finished with value: 0.9741631958478161 and parameters: {'num_leaves': 334, 'max_depth': 6, 'n_estimators': 771, 'learning_rate': 0.0576281612861818, 'min_child_samples': 15}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:47,100] Trial 41 finished with value: 0.9758205621913865 and parameters: {'num_leaves': 388, 'max_depth': 10, 'n_estimators': 565, 'learning_rate': 0.0802719138609823, 'min_child_samples': 34}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:53,169] Trial 42 finished with value: 0.9758880947919244 and parameters: {'num_leaves': 323, 'max_depth': 11, 'n_estimators': 505, 'learning_rate': 0.06525543632294492, 'min_child_samples': 34}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:02:55,068] Trial 43 finished with value: 0.9738350267717678 and parameters: {'num_leaves': 400, 'max_depth': 7, 'n_estimators': 450, 'learning_rate': 0.0549528985031123, 'min_child_samples': 31}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:03:03,609] Trial 44 finished with value: 0.9752949222390254 and parameters: {'num_leaves': 263, 'max_depth': 12, 'n_estimators': 704, 'learning_rate': 0.07183506429020675, 'min_child_samples': 34}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:03:09,153] Trial 45 finished with value: 0.9759547185301212 and parameters: {'num_leaves': 297, 'max_depth': 9, 'n_estimators': 678, 'learning_rate': 0.08915793141103726, 'min_child_samples': 27}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:03:15,442] Trial 46 finished with value: 0.9754017074901729 and parameters: {'num_leaves': 283, 'max_depth': 12, 'n_estimators': 449, 'learning_rate': 0.09491194997969331, 'min_child_samples': 17}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:03:18,581] Trial 47 finished with value: 0.9762496741405337 and parameters: {'num_leaves': 345, 'max_depth': 8, 'n_estimators': 581, 'learning_rate': 0.07951432949167708, 'min_child_samples': 35}. Best is trial 23 with value: 0.9764243088895003.\n",
            "[I 2024-02-18 14:03:21,900] Trial 48 finished with value: 0.9764500878535796 and parameters: {'num_leaves': 343, 'max_depth': 8, 'n_estimators': 589, 'learning_rate': 0.07748219242255186, 'min_child_samples': 29}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:25,451] Trial 49 finished with value: 0.9756451244235135 and parameters: {'num_leaves': 344, 'max_depth': 8, 'n_estimators': 611, 'learning_rate': 0.07912021415837074, 'min_child_samples': 29}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:28,062] Trial 50 finished with value: 0.9764372142833805 and parameters: {'num_leaves': 336, 'max_depth': 7, 'n_estimators': 658, 'learning_rate': 0.09943699945160979, 'min_child_samples': 26}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:30,972] Trial 51 finished with value: 0.9759398837011543 and parameters: {'num_leaves': 335, 'max_depth': 7, 'n_estimators': 665, 'learning_rate': 0.09873552349247, 'min_child_samples': 26}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:32,966] Trial 52 finished with value: 0.9752552194328157 and parameters: {'num_leaves': 362, 'max_depth': 6, 'n_estimators': 553, 'learning_rate': 0.09266123643350548, 'min_child_samples': 27}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:36,900] Trial 53 finished with value: 0.9761949184355219 and parameters: {'num_leaves': 350, 'max_depth': 8, 'n_estimators': 637, 'learning_rate': 0.0872582371719967, 'min_child_samples': 25}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:39,419] Trial 54 finished with value: 0.9754165462283602 and parameters: {'num_leaves': 338, 'max_depth': 7, 'n_estimators': 594, 'learning_rate': 0.08223969168149936, 'min_child_samples': 28}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:45,323] Trial 55 finished with value: 0.9760619104018775 and parameters: {'num_leaves': 324, 'max_depth': 9, 'n_estimators': 745, 'learning_rate': 0.09514952688541947, 'min_child_samples': 25}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:47,222] Trial 56 finished with value: 0.9736445878280776 and parameters: {'num_leaves': 379, 'max_depth': 6, 'n_estimators': 618, 'learning_rate': 0.07448159866807097, 'min_child_samples': 30}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:50,800] Trial 57 finished with value: 0.9754436086699089 and parameters: {'num_leaves': 356, 'max_depth': 8, 'n_estimators': 571, 'learning_rate': 0.07840084665298472, 'min_child_samples': 24}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:54,229] Trial 58 finished with value: 0.9759660413328647 and parameters: {'num_leaves': 318, 'max_depth': 8, 'n_estimators': 652, 'learning_rate': 0.09264523979013589, 'min_child_samples': 32}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:55,733] Trial 59 finished with value: 0.9732662211057463 and parameters: {'num_leaves': 329, 'max_depth': 5, 'n_estimators': 691, 'learning_rate': 0.08403214142767093, 'min_child_samples': 27}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:03:58,269] Trial 60 finished with value: 0.975430094207142 and parameters: {'num_leaves': 363, 'max_depth': 7, 'n_estimators': 541, 'learning_rate': 0.06719938830259056, 'min_child_samples': 29}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:04:02,374] Trial 61 finished with value: 0.9756717298297088 and parameters: {'num_leaves': 351, 'max_depth': 8, 'n_estimators': 717, 'learning_rate': 0.08783611674278681, 'min_child_samples': 22}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:04:07,351] Trial 62 finished with value: 0.9757798437557946 and parameters: {'num_leaves': 346, 'max_depth': 9, 'n_estimators': 623, 'learning_rate': 0.08833989407767759, 'min_child_samples': 25}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:04:11,720] Trial 63 finished with value: 0.9707686045437673 and parameters: {'num_leaves': 390, 'max_depth': 8, 'n_estimators': 651, 'learning_rate': 0.014602402843348267, 'min_child_samples': 26}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:04:14,323] Trial 64 finished with value: 0.9758197113452084 and parameters: {'num_leaves': 351, 'max_depth': 7, 'n_estimators': 597, 'learning_rate': 0.09717962135123107, 'min_child_samples': 25}. Best is trial 48 with value: 0.9764500878535796.\n",
            "[I 2024-02-18 14:04:19,207] Trial 65 finished with value: 0.9766413446369117 and parameters: {'num_leaves': 373, 'max_depth': 9, 'n_estimators': 580, 'learning_rate': 0.08041759844325626, 'min_child_samples': 28}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:23,635] Trial 66 finished with value: 0.9764500878535796 and parameters: {'num_leaves': 371, 'max_depth': 9, 'n_estimators': 577, 'learning_rate': 0.07558846744429136, 'min_child_samples': 28}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:29,186] Trial 67 finished with value: 0.9751058968311729 and parameters: {'num_leaves': 370, 'max_depth': 10, 'n_estimators': 571, 'learning_rate': 0.07348611997751621, 'min_child_samples': 28}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:33,294] Trial 68 finished with value: 0.9759004046426004 and parameters: {'num_leaves': 359, 'max_depth': 9, 'n_estimators': 526, 'learning_rate': 0.07649454559038749, 'min_child_samples': 27}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:37,917] Trial 69 finished with value: 0.9763723669088628 and parameters: {'num_leaves': 374, 'max_depth': 9, 'n_estimators': 627, 'learning_rate': 0.060243896704902836, 'min_child_samples': 29}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:43,801] Trial 70 finished with value: 0.9758739222468693 and parameters: {'num_leaves': 393, 'max_depth': 10, 'n_estimators': 623, 'learning_rate': 0.06087944417912269, 'min_child_samples': 29}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:47,822] Trial 71 finished with value: 0.9764922801857847 and parameters: {'num_leaves': 374, 'max_depth': 9, 'n_estimators': 559, 'learning_rate': 0.07993465016873534, 'min_child_samples': 30}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:51,615] Trial 72 finished with value: 0.9752959505801228 and parameters: {'num_leaves': 376, 'max_depth': 9, 'n_estimators': 503, 'learning_rate': 0.0704694101576602, 'min_child_samples': 31}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:04:58,356] Trial 73 finished with value: 0.974919272911971 and parameters: {'num_leaves': 384, 'max_depth': 9, 'n_estimators': 934, 'learning_rate': 0.08162612507293435, 'min_child_samples': 30}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:05,143] Trial 74 finished with value: 0.9705444581438771 and parameters: {'num_leaves': 368, 'max_depth': 10, 'n_estimators': 553, 'learning_rate': 0.011089794206868057, 'min_child_samples': 28}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:10,871] Trial 75 finished with value: 0.9755509619721008 and parameters: {'num_leaves': 383, 'max_depth': 9, 'n_estimators': 660, 'learning_rate': 0.07670277704680725, 'min_child_samples': 29}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:15,804] Trial 76 finished with value: 0.9765051855426203 and parameters: {'num_leaves': 371, 'max_depth': 9, 'n_estimators': 685, 'learning_rate': 0.08503606309528772, 'min_child_samples': 28}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:18,539] Trial 77 finished with value: 0.9756584435410302 and parameters: {'num_leaves': 339, 'max_depth': 7, 'n_estimators': 682, 'learning_rate': 0.08545836571875408, 'min_child_samples': 26}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:25,513] Trial 78 finished with value: 0.9761709888262939 and parameters: {'num_leaves': 358, 'max_depth': 10, 'n_estimators': 737, 'learning_rate': 0.09000973893934122, 'min_child_samples': 27}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:37,282] Trial 79 finished with value: 0.9751172372590635 and parameters: {'num_leaves': 304, 'max_depth': 15, 'n_estimators': 777, 'learning_rate': 0.07213578185295699, 'min_child_samples': 28}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:46,450] Trial 80 finished with value: 0.975564514039121 and parameters: {'num_leaves': 367, 'max_depth': 11, 'n_estimators': 799, 'learning_rate': 0.06780954410161283, 'min_child_samples': 30}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:50,949] Trial 81 finished with value: 0.9754570897303951 and parameters: {'num_leaves': 375, 'max_depth': 9, 'n_estimators': 632, 'learning_rate': 0.03980206920220365, 'min_child_samples': 31}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:55,433] Trial 82 finished with value: 0.9758205621913865 and parameters: {'num_leaves': 373, 'max_depth': 9, 'n_estimators': 609, 'learning_rate': 0.0545804952324903, 'min_child_samples': 29}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:05:59,883] Trial 83 finished with value: 0.9757798437557946 and parameters: {'num_leaves': 387, 'max_depth': 9, 'n_estimators': 584, 'learning_rate': 0.08047209041753539, 'min_child_samples': 29}. Best is trial 65 with value: 0.9766413446369117.\n",
            "[I 2024-02-18 14:06:03,237] Trial 84 finished with value: 0.9766542176274267 and parameters: {'num_leaves': 363, 'max_depth': 8, 'n_estimators': 559, 'learning_rate': 0.08402776693894054, 'min_child_samples': 24}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:06,104] Trial 85 finished with value: 0.9759660413328647 and parameters: {'num_leaves': 364, 'max_depth': 8, 'n_estimators': 524, 'learning_rate': 0.08507237687274986, 'min_child_samples': 26}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:09,469] Trial 86 finished with value: 0.9762885810388187 and parameters: {'num_leaves': 379, 'max_depth': 8, 'n_estimators': 564, 'learning_rate': 0.09063071824551557, 'min_child_samples': 24}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:12,351] Trial 87 finished with value: 0.976611753436837 and parameters: {'num_leaves': 329, 'max_depth': 7, 'n_estimators': 710, 'learning_rate': 0.07730379385752506, 'min_child_samples': 23}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:14,705] Trial 88 finished with value: 0.9753629880778448 and parameters: {'num_leaves': 329, 'max_depth': 7, 'n_estimators': 539, 'learning_rate': 0.07639591949122429, 'min_child_samples': 23}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:18,374] Trial 89 finished with value: 0.9754973336277715 and parameters: {'num_leaves': 354, 'max_depth': 7, 'n_estimators': 757, 'learning_rate': 0.08140634866305696, 'min_child_samples': 22}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:20,535] Trial 90 finished with value: 0.970212264779508 and parameters: {'num_leaves': 339, 'max_depth': 6, 'n_estimators': 715, 'learning_rate': 0.02826704904247103, 'min_child_samples': 27}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:24,382] Trial 91 finished with value: 0.975631772365766 and parameters: {'num_leaves': 360, 'max_depth': 8, 'n_estimators': 698, 'learning_rate': 0.08336314812577597, 'min_child_samples': 24}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:27,973] Trial 92 finished with value: 0.9758197113452084 and parameters: {'num_leaves': 334, 'max_depth': 8, 'n_estimators': 602, 'learning_rate': 0.08684714034556974, 'min_child_samples': 21}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:30,793] Trial 93 finished with value: 0.9763950300449288 and parameters: {'num_leaves': 346, 'max_depth': 7, 'n_estimators': 733, 'learning_rate': 0.07907082255963654, 'min_child_samples': 28}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:33,155] Trial 94 finished with value: 0.9753765003957003 and parameters: {'num_leaves': 319, 'max_depth': 7, 'n_estimators': 559, 'learning_rate': 0.07503000178323431, 'min_child_samples': 23}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:36,854] Trial 95 finished with value: 0.9760487488972541 and parameters: {'num_leaves': 312, 'max_depth': 8, 'n_estimators': 682, 'learning_rate': 0.0840837280510944, 'min_child_samples': 30}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:42,283] Trial 96 finished with value: 0.9757664886308034 and parameters: {'num_leaves': 201, 'max_depth': 10, 'n_estimators': 581, 'learning_rate': 0.09420178069499764, 'min_child_samples': 26}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:52,892] Trial 97 finished with value: 0.9745231970433933 and parameters: {'num_leaves': 369, 'max_depth': 14, 'n_estimators': 649, 'learning_rate': 0.0775595549794583, 'min_child_samples': 28}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:56,779] Trial 98 finished with value: 0.9752552194328157 and parameters: {'num_leaves': 216, 'max_depth': 8, 'n_estimators': 708, 'learning_rate': 0.09747429214983683, 'min_child_samples': 24}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:06:58,364] Trial 99 finished with value: 0.9746361711038103 and parameters: {'num_leaves': 394, 'max_depth': 6, 'n_estimators': 545, 'learning_rate': 0.07344590926742374, 'min_child_samples': 23}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:02,101] Trial 100 finished with value: 0.9754570897303951 and parameters: {'num_leaves': 325, 'max_depth': 9, 'n_estimators': 490, 'learning_rate': 0.08690326777823373, 'min_child_samples': 27}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:05,177] Trial 101 finished with value: 0.9762756440599023 and parameters: {'num_leaves': 347, 'max_depth': 7, 'n_estimators': 762, 'learning_rate': 0.07963343777479574, 'min_child_samples': 28}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:08,099] Trial 102 finished with value: 0.9758064550011369 and parameters: {'num_leaves': 356, 'max_depth': 7, 'n_estimators': 731, 'learning_rate': 0.07823632607769763, 'min_child_samples': 25}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:11,010] Trial 103 finished with value: 0.9757124492398613 and parameters: {'num_leaves': 341, 'max_depth': 7, 'n_estimators': 725, 'learning_rate': 0.08197653790658872, 'min_child_samples': 31}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:13,185] Trial 104 finished with value: 0.9759267564725479 and parameters: {'num_leaves': 348, 'max_depth': 6, 'n_estimators': 745, 'learning_rate': 0.09163993543365719, 'min_child_samples': 28}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:16,909] Trial 105 finished with value: 0.9755505313357027 and parameters: {'num_leaves': 363, 'max_depth': 8, 'n_estimators': 691, 'learning_rate': 0.08397166609627349, 'min_child_samples': 29}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:19,710] Trial 106 finished with value: 0.9762496741405337 and parameters: {'num_leaves': 383, 'max_depth': 7, 'n_estimators': 669, 'learning_rate': 0.0801634242055986, 'min_child_samples': 27}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:22,985] Trial 107 finished with value: 0.9756990955964842 and parameters: {'num_leaves': 332, 'max_depth': 8, 'n_estimators': 596, 'learning_rate': 0.08869293660022873, 'min_child_samples': 26}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:28,571] Trial 108 finished with value: 0.9756451244235135 and parameters: {'num_leaves': 353, 'max_depth': 9, 'n_estimators': 783, 'learning_rate': 0.06992576935113395, 'min_child_samples': 30}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:33,059] Trial 109 finished with value: 0.9758197113452084 and parameters: {'num_leaves': 378, 'max_depth': 8, 'n_estimators': 814, 'learning_rate': 0.07216785574305416, 'min_child_samples': 28}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:38,808] Trial 110 finished with value: 0.9756588356035165 and parameters: {'num_leaves': 366, 'max_depth': 9, 'n_estimators': 754, 'learning_rate': 0.07548582343652693, 'min_child_samples': 25}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:44,664] Trial 111 finished with value: 0.9758880947919244 and parameters: {'num_leaves': 373, 'max_depth': 10, 'n_estimators': 626, 'learning_rate': 0.07788600618968898, 'min_child_samples': 29}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:49,100] Trial 112 finished with value: 0.9760487488972541 and parameters: {'num_leaves': 373, 'max_depth': 9, 'n_estimators': 574, 'learning_rate': 0.05243928740986302, 'min_child_samples': 29}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:53,630] Trial 113 finished with value: 0.9765861021449022 and parameters: {'num_leaves': 360, 'max_depth': 9, 'n_estimators': 616, 'learning_rate': 0.062436124254622444, 'min_child_samples': 30}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:56,069] Trial 114 finished with value: 0.9746361711038103 and parameters: {'num_leaves': 359, 'max_depth': 7, 'n_estimators': 612, 'learning_rate': 0.06304806211956758, 'min_child_samples': 30}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:07:59,978] Trial 115 finished with value: 0.9760487488972541 and parameters: {'num_leaves': 343, 'max_depth': 9, 'n_estimators': 514, 'learning_rate': 0.06626279572768289, 'min_child_samples': 27}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:08:05,430] Trial 116 finished with value: 0.9760900083608604 and parameters: {'num_leaves': 362, 'max_depth': 10, 'n_estimators': 591, 'learning_rate': 0.08089777506724703, 'min_child_samples': 32}. Best is trial 84 with value: 0.9766542176274267.\n",
            "[I 2024-02-18 14:08:08,856] Trial 117 finished with value: 0.9766626778159702 and parameters: {'num_leaves': 337, 'max_depth': 8, 'n_estimators': 642, 'learning_rate': 0.08571565289986106, 'min_child_samples': 31}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:12,340] Trial 118 finished with value: 0.9753497915229329 and parameters: {'num_leaves': 336, 'max_depth': 8, 'n_estimators': 640, 'learning_rate': 0.08712353982231777, 'min_child_samples': 32}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:15,858] Trial 119 finished with value: 0.9757523126788707 and parameters: {'num_leaves': 331, 'max_depth': 8, 'n_estimators': 656, 'learning_rate': 0.08519607094307136, 'min_child_samples': 31}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:19,600] Trial 120 finished with value: 0.9761032360892211 and parameters: {'num_leaves': 369, 'max_depth': 9, 'n_estimators': 530, 'learning_rate': 0.0896596497274794, 'min_child_samples': 31}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:22,722] Trial 121 finished with value: 0.9756584435410302 and parameters: {'num_leaves': 349, 'max_depth': 7, 'n_estimators': 705, 'learning_rate': 0.0827390811999268, 'min_child_samples': 30}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:26,311] Trial 122 finished with value: 0.9759398837011543 and parameters: {'num_leaves': 342, 'max_depth': 8, 'n_estimators': 671, 'learning_rate': 0.07850283980325427, 'min_child_samples': 28}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:28,701] Trial 123 finished with value: 0.9754570897303951 and parameters: {'num_leaves': 354, 'max_depth': 7, 'n_estimators': 565, 'learning_rate': 0.07294830716166507, 'min_child_samples': 30}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:33,799] Trial 124 finished with value: 0.9762104777249531 and parameters: {'num_leaves': 382, 'max_depth': 9, 'n_estimators': 603, 'learning_rate': 0.08379404026419197, 'min_child_samples': 28}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:37,119] Trial 125 finished with value: 0.9759811376365077 and parameters: {'num_leaves': 336, 'max_depth': 8, 'n_estimators': 551, 'learning_rate': 0.06892141579624204, 'min_child_samples': 29}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:39,149] Trial 126 finished with value: 0.9748525961488003 and parameters: {'num_leaves': 327, 'max_depth': 6, 'n_estimators': 616, 'learning_rate': 0.07594414968755668, 'min_child_samples': 29}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:42,731] Trial 127 finished with value: 0.9758064550011369 and parameters: {'num_leaves': 322, 'max_depth': 8, 'n_estimators': 585, 'learning_rate': 0.07990880051417676, 'min_child_samples': 22}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:45,606] Trial 128 finished with value: 0.9760074264293308 and parameters: {'num_leaves': 357, 'max_depth': 7, 'n_estimators': 641, 'learning_rate': 0.08590036606119467, 'min_child_samples': 25}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:53,437] Trial 129 finished with value: 0.975267458439289 and parameters: {'num_leaves': 292, 'max_depth': 10, 'n_estimators': 681, 'learning_rate': 0.08133047886686232, 'min_child_samples': 26}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:08:59,796] Trial 130 finished with value: 0.9757936827278147 and parameters: {'num_leaves': 387, 'max_depth': 9, 'n_estimators': 724, 'learning_rate': 0.043370184963832846, 'min_child_samples': 24}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:09:05,054] Trial 131 finished with value: 0.9761164310332465 and parameters: {'num_leaves': 376, 'max_depth': 9, 'n_estimators': 628, 'learning_rate': 0.06038154186720003, 'min_child_samples': 30}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:09:09,845] Trial 132 finished with value: 0.9757523126788707 and parameters: {'num_leaves': 366, 'max_depth': 9, 'n_estimators': 602, 'learning_rate': 0.09305071533876369, 'min_child_samples': 28}. Best is trial 117 with value: 0.9766626778159702.\n",
            "[I 2024-02-18 14:09:14,189] Trial 133 finished with value: 0.9769050917602714 and parameters: {'num_leaves': 370, 'max_depth': 9, 'n_estimators': 580, 'learning_rate': 0.06318252430660709, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:17,852] Trial 134 finished with value: 0.9758329349851804 and parameters: {'num_leaves': 371, 'max_depth': 8, 'n_estimators': 558, 'learning_rate': 0.05758793523640236, 'min_child_samples': 23}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:21,731] Trial 135 finished with value: 0.9762626751299242 and parameters: {'num_leaves': 350, 'max_depth': 8, 'n_estimators': 574, 'learning_rate': 0.07398649498950804, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:26,218] Trial 136 finished with value: 0.9757664886308034 and parameters: {'num_leaves': 345, 'max_depth': 9, 'n_estimators': 585, 'learning_rate': 0.07877810511327112, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:28,695] Trial 137 finished with value: 0.9747026931493954 and parameters: {'num_leaves': 363, 'max_depth': 7, 'n_estimators': 540, 'learning_rate': 0.08205005598615904, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:37,259] Trial 138 finished with value: 0.9760487488972541 and parameters: {'num_leaves': 380, 'max_depth': 9, 'n_estimators': 694, 'learning_rate': 0.07694361188698137, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:40,653] Trial 139 finished with value: 0.9750272308977669 and parameters: {'num_leaves': 338, 'max_depth': 7, 'n_estimators': 657, 'learning_rate': 0.06385405405899194, 'min_child_samples': 31}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:47,256] Trial 140 finished with value: 0.9755645185160984 and parameters: {'num_leaves': 369, 'max_depth': 10, 'n_estimators': 577, 'learning_rate': 0.08856453079253983, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:52,254] Trial 141 finished with value: 0.9767608327259103 and parameters: {'num_leaves': 391, 'max_depth': 9, 'n_estimators': 623, 'learning_rate': 0.0625585100856873, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:09:57,711] Trial 142 finished with value: 0.9768163158381333 and parameters: {'num_leaves': 398, 'max_depth': 9, 'n_estimators': 619, 'learning_rate': 0.056387909443292236, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:02,593] Trial 143 finished with value: 0.9749860170196197 and parameters: {'num_leaves': 391, 'max_depth': 9, 'n_estimators': 611, 'learning_rate': 0.062211168585547864, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:08,058] Trial 144 finished with value: 0.9757798437557946 and parameters: {'num_leaves': 398, 'max_depth': 9, 'n_estimators': 636, 'learning_rate': 0.053564419288210915, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:12,873] Trial 145 finished with value: 0.976304468078774 and parameters: {'num_leaves': 389, 'max_depth': 9, 'n_estimators': 619, 'learning_rate': 0.05722734476909844, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:19,787] Trial 146 finished with value: 0.9765051855426203 and parameters: {'num_leaves': 395, 'max_depth': 10, 'n_estimators': 588, 'learning_rate': 0.049862838388347076, 'min_child_samples': 31}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:26,719] Trial 147 finished with value: 0.975591517429582 and parameters: {'num_leaves': 398, 'max_depth': 10, 'n_estimators': 593, 'learning_rate': 0.055916525875833366, 'min_child_samples': 31}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:32,568] Trial 148 finished with value: 0.9756049689814684 and parameters: {'num_leaves': 400, 'max_depth': 10, 'n_estimators': 601, 'learning_rate': 0.049219718100217615, 'min_child_samples': 32}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:38,901] Trial 149 finished with value: 0.9754701355564791 and parameters: {'num_leaves': 385, 'max_depth': 10, 'n_estimators': 555, 'learning_rate': 0.05920076196674962, 'min_child_samples': 31}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:44,037] Trial 150 finished with value: 0.9761164310332465 and parameters: {'num_leaves': 395, 'max_depth': 9, 'n_estimators': 570, 'learning_rate': 0.051062161262424174, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:51,971] Trial 151 finished with value: 0.9752536751892363 and parameters: {'num_leaves': 378, 'max_depth': 9, 'n_estimators': 649, 'learning_rate': 0.06517903081234162, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:10:58,174] Trial 152 finished with value: 0.9763593007660053 and parameters: {'num_leaves': 388, 'max_depth': 9, 'n_estimators': 588, 'learning_rate': 0.0586961251721638, 'min_child_samples': 24}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:11,665] Trial 153 finished with value: 0.975564514039121 and parameters: {'num_leaves': 382, 'max_depth': 11, 'n_estimators': 625, 'learning_rate': 0.04297139562725209, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:16,518] Trial 154 finished with value: 0.9753757000507538 and parameters: {'num_leaves': 376, 'max_depth': 8, 'n_estimators': 610, 'learning_rate': 0.04614318695559667, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:21,728] Trial 155 finished with value: 0.975591517429582 and parameters: {'num_leaves': 396, 'max_depth': 9, 'n_estimators': 567, 'learning_rate': 0.0671246212898975, 'min_child_samples': 23}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:25,711] Trial 156 finished with value: 0.9757396788130341 and parameters: {'num_leaves': 392, 'max_depth': 8, 'n_estimators': 665, 'learning_rate': 0.05162950876540332, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:31,860] Trial 157 finished with value: 0.9761558202718786 and parameters: {'num_leaves': 372, 'max_depth': 10, 'n_estimators': 598, 'learning_rate': 0.05535480032399271, 'min_child_samples': 32}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:35,435] Trial 158 finished with value: 0.9756990955964842 and parameters: {'num_leaves': 366, 'max_depth': 8, 'n_estimators': 583, 'learning_rate': 0.0842974093868551, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:44,000] Trial 159 finished with value: 0.974930586245477 and parameters: {'num_leaves': 361, 'max_depth': 11, 'n_estimators': 643, 'learning_rate': 0.061888926580000704, 'min_child_samples': 31}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:49,161] Trial 160 finished with value: 0.9760767477361417 and parameters: {'num_leaves': 386, 'max_depth': 9, 'n_estimators': 546, 'learning_rate': 0.046482640086435066, 'min_child_samples': 33}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:52,332] Trial 161 finished with value: 0.9752961885758329 and parameters: {'num_leaves': 346, 'max_depth': 7, 'n_estimators': 710, 'learning_rate': 0.08030219607016391, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:11:58,688] Trial 162 finished with value: 0.9763175015998053 and parameters: {'num_leaves': 333, 'max_depth': 9, 'n_estimators': 747, 'learning_rate': 0.08581809755468779, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:03,645] Trial 163 finished with value: 0.9760074264293308 and parameters: {'num_leaves': 342, 'max_depth': 8, 'n_estimators': 731, 'learning_rate': 0.09969346750331792, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:06,608] Trial 164 finished with value: 0.9739364792721912 and parameters: {'num_leaves': 357, 'max_depth': 7, 'n_estimators': 614, 'learning_rate': 0.04912876057441726, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:09,116] Trial 165 finished with value: 0.9752961885758329 and parameters: {'num_leaves': 354, 'max_depth': 6, 'n_estimators': 679, 'learning_rate': 0.08265205359087749, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:13,863] Trial 166 finished with value: 0.9759267564725479 and parameters: {'num_leaves': 369, 'max_depth': 8, 'n_estimators': 634, 'learning_rate': 0.07125613222240645, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:19,170] Trial 167 finished with value: 0.9755645185160984 and parameters: {'num_leaves': 339, 'max_depth': 9, 'n_estimators': 575, 'learning_rate': 0.07581650860365866, 'min_child_samples': 26}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:23,943] Trial 168 finished with value: 0.9758205621913865 and parameters: {'num_leaves': 374, 'max_depth': 9, 'n_estimators': 559, 'learning_rate': 0.07876511229800788, 'min_child_samples': 24}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:28,192] Trial 169 finished with value: 0.9763821881774851 and parameters: {'num_leaves': 379, 'max_depth': 8, 'n_estimators': 716, 'learning_rate': 0.08292213194338079, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:31,262] Trial 170 finished with value: 0.9755778688851935 and parameters: {'num_leaves': 364, 'max_depth': 7, 'n_estimators': 690, 'learning_rate': 0.08759946823473279, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:35,602] Trial 171 finished with value: 0.9755505313357027 and parameters: {'num_leaves': 379, 'max_depth': 8, 'n_estimators': 714, 'learning_rate': 0.08414842682112338, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:40,127] Trial 172 finished with value: 0.975228981297839 and parameters: {'num_leaves': 393, 'max_depth': 8, 'n_estimators': 735, 'learning_rate': 0.08109105555112626, 'min_child_samples': 31}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:43,951] Trial 173 finished with value: 0.9765309007617818 and parameters: {'num_leaves': 375, 'max_depth': 8, 'n_estimators': 594, 'learning_rate': 0.08262215423598418, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:46,583] Trial 174 finished with value: 0.9749860170196197 and parameters: {'num_leaves': 373, 'max_depth': 7, 'n_estimators': 591, 'learning_rate': 0.07711772593059762, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:51,606] Trial 175 finished with value: 0.976611753436837 and parameters: {'num_leaves': 370, 'max_depth': 9, 'n_estimators': 606, 'learning_rate': 0.09062654686354273, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:12:56,880] Trial 176 finished with value: 0.9757931658418674 and parameters: {'num_leaves': 370, 'max_depth': 9, 'n_estimators': 604, 'learning_rate': 0.09094851723327166, 'min_child_samples': 25}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:02,011] Trial 177 finished with value: 0.9759811376365077 and parameters: {'num_leaves': 366, 'max_depth': 9, 'n_estimators': 622, 'learning_rate': 0.08636641439138212, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:06,661] Trial 178 finished with value: 0.9764141727237371 and parameters: {'num_leaves': 376, 'max_depth': 9, 'n_estimators': 581, 'learning_rate': 0.09602291918513708, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:11,520] Trial 179 finished with value: 0.9757931658418674 and parameters: {'num_leaves': 384, 'max_depth': 9, 'n_estimators': 587, 'learning_rate': 0.09643003131950234, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:19,602] Trial 180 finished with value: 0.9756588356035165 and parameters: {'num_leaves': 375, 'max_depth': 10, 'n_estimators': 578, 'learning_rate': 0.09913188333116082, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:26,299] Trial 181 finished with value: 0.9754165462283602 and parameters: {'num_leaves': 370, 'max_depth': 9, 'n_estimators': 599, 'learning_rate': 0.0961629110126628, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:31,078] Trial 182 finished with value: 0.97522789675183 and parameters: {'num_leaves': 376, 'max_depth': 9, 'n_estimators': 565, 'learning_rate': 0.09743242810376121, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:37,198] Trial 183 finished with value: 0.9744138376056093 and parameters: {'num_leaves': 361, 'max_depth': 9, 'n_estimators': 615, 'learning_rate': 0.023124634369058608, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:40,859] Trial 184 finished with value: 0.9760074264293308 and parameters: {'num_leaves': 390, 'max_depth': 8, 'n_estimators': 578, 'learning_rate': 0.09450830800054091, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:46,038] Trial 185 finished with value: 0.975765535032322 and parameters: {'num_leaves': 380, 'max_depth': 9, 'n_estimators': 595, 'learning_rate': 0.0926503447506504, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:51,126] Trial 186 finished with value: 0.9759811376365077 and parameters: {'num_leaves': 249, 'max_depth': 9, 'n_estimators': 629, 'learning_rate': 0.08947941839670899, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:55,915] Trial 187 finished with value: 0.9756584435410302 and parameters: {'num_leaves': 366, 'max_depth': 9, 'n_estimators': 531, 'learning_rate': 0.08541669912669549, 'min_child_samples': 24}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:13:59,384] Trial 188 finished with value: 0.976181917873481 and parameters: {'num_leaves': 400, 'max_depth': 8, 'n_estimators': 551, 'learning_rate': 0.08752840572755656, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:08,819] Trial 189 finished with value: 0.9751172372590635 and parameters: {'num_leaves': 372, 'max_depth': 12, 'n_estimators': 610, 'learning_rate': 0.08343550273058095, 'min_child_samples': 29}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:14,976] Trial 190 finished with value: 0.9753765003957003 and parameters: {'num_leaves': 360, 'max_depth': 10, 'n_estimators': 566, 'learning_rate': 0.09067336616911559, 'min_child_samples': 30}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:19,747] Trial 191 finished with value: 0.9758205621913865 and parameters: {'num_leaves': 331, 'max_depth': 9, 'n_estimators': 588, 'learning_rate': 0.07976715675544699, 'min_child_samples': 28}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:23,610] Trial 192 finished with value: 0.976411371563894 and parameters: {'num_leaves': 350, 'max_depth': 8, 'n_estimators': 607, 'learning_rate': 0.08139139128706328, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:27,538] Trial 193 finished with value: 0.9749346837774369 and parameters: {'num_leaves': 352, 'max_depth': 8, 'n_estimators': 649, 'learning_rate': 0.08495127734764038, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:31,198] Trial 194 finished with value: 0.9754436086699089 and parameters: {'num_leaves': 369, 'max_depth': 8, 'n_estimators': 604, 'learning_rate': 0.08136265132109198, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:35,016] Trial 195 finished with value: 0.9763462021437477 and parameters: {'num_leaves': 274, 'max_depth': 8, 'n_estimators': 621, 'learning_rate': 0.05380271045448008, 'min_child_samples': 27}. Best is trial 133 with value: 0.9769050917602714.\n",
            "[I 2024-02-18 14:14:40,572] Trial 196 finished with value: 0.9770977087995643 and parameters: {'num_leaves': 349, 'max_depth': 9, 'n_estimators': 596, 'learning_rate': 0.08291117193234496, 'min_child_samples': 26}. Best is trial 196 with value: 0.9770977087995643.\n",
            "[I 2024-02-18 14:14:45,484] Trial 197 finished with value: 0.9759004046426004 and parameters: {'num_leaves': 382, 'max_depth': 9, 'n_estimators': 578, 'learning_rate': 0.059177454861213646, 'min_child_samples': 25}. Best is trial 196 with value: 0.9770977087995643.\n",
            "[I 2024-02-18 14:14:50,282] Trial 198 finished with value: 0.9758473083957263 and parameters: {'num_leaves': 339, 'max_depth': 9, 'n_estimators': 592, 'learning_rate': 0.08852510158963328, 'min_child_samples': 26}. Best is trial 196 with value: 0.9770977087995643.\n",
            "[I 2024-02-18 14:14:55,088] Trial 199 finished with value: 0.9764793428531003 and parameters: {'num_leaves': 364, 'max_depth': 9, 'n_estimators': 563, 'learning_rate': 0.06315649610019122, 'min_child_samples': 25}. Best is trial 196 with value: 0.9770977087995643.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9770977087995643, \n",
            "params {'num_leaves': 349, 'max_depth': 9, 'n_estimators': 596, 'learning_rate': 0.08291117193234496, 'min_child_samples': 26}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveLGBM(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 200, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 400, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 15, 35),\n",
        "        'verbose' : -1,\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = LGBMClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveLGBM(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4263c482",
      "metadata": {},
      "source": [
        "LGBM_dart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f99c7ba8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 23:42:14,548] A new study created in memory with name: no-name-afd4f68e-35a9-470c-933b-2eafb64b810d\n",
            "[I 2024-02-17 23:42:34,065] Trial 0 finished with value: 0.9757931658418674 and parameters: {'num_leaves': 166, 'max_depth': 19, 'n_estimators': 643, 'learning_rate': 0.05903948646972072, 'min_child_samples': 24}. Best is trial 0 with value: 0.9757931658418674.\n",
            "[I 2024-02-17 23:43:07,845] Trial 1 finished with value: 0.9765732288484092 and parameters: {'num_leaves': 195, 'max_depth': 12, 'n_estimators': 903, 'learning_rate': 0.09672964844509264, 'min_child_samples': 22}. Best is trial 1 with value: 0.9765732288484092.\n",
            "[I 2024-02-17 23:43:26,090] Trial 2 finished with value: 0.9768418373577431 and parameters: {'num_leaves': 238, 'max_depth': 14, 'n_estimators': 611, 'learning_rate': 0.0933036974463395, 'min_child_samples': 8}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:43:31,667] Trial 3 finished with value: 0.9579651760987544 and parameters: {'num_leaves': 28, 'max_depth': 2, 'n_estimators': 850, 'learning_rate': 0.08003410758548654, 'min_child_samples': 45}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:43:46,197] Trial 4 finished with value: 0.9761012002662252 and parameters: {'num_leaves': 294, 'max_depth': 21, 'n_estimators': 515, 'learning_rate': 0.08024762586578099, 'min_child_samples': 10}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:44:02,744] Trial 5 finished with value: 0.9667215022703566 and parameters: {'num_leaves': 193, 'max_depth': 5, 'n_estimators': 951, 'learning_rate': 0.056966348957506456, 'min_child_samples': 24}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:44:11,631] Trial 6 finished with value: 0.9723080391705282 and parameters: {'num_leaves': 81, 'max_depth': 20, 'n_estimators': 510, 'learning_rate': 0.061159055398178376, 'min_child_samples': 5}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:44:31,663] Trial 7 finished with value: 0.9762235755476393 and parameters: {'num_leaves': 186, 'max_depth': 16, 'n_estimators': 655, 'learning_rate': 0.09493732706631618, 'min_child_samples': 36}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:44:48,040] Trial 8 finished with value: 0.9670079041713718 and parameters: {'num_leaves': 109, 'max_depth': 12, 'n_estimators': 728, 'learning_rate': 0.015420292446634285, 'min_child_samples': 35}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:44:50,290] Trial 9 finished with value: 0.9627118080930148 and parameters: {'num_leaves': 202, 'max_depth': 7, 'n_estimators': 216, 'learning_rate': 0.03838855158317655, 'min_child_samples': 21}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:44:55,866] Trial 10 finished with value: 0.9711848573456312 and parameters: {'num_leaves': 283, 'max_depth': 24, 'n_estimators': 313, 'learning_rate': 0.03086461804368433, 'min_child_samples': 13}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:45:34,045] Trial 11 finished with value: 0.9763462021437477 and parameters: {'num_leaves': 239, 'max_depth': 12, 'n_estimators': 945, 'learning_rate': 0.09966369832266204, 'min_child_samples': 17}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:45:44,311] Trial 12 finished with value: 0.9734497153953208 and parameters: {'num_leaves': 246, 'max_depth': 9, 'n_estimators': 401, 'learning_rate': 0.08057396705197298, 'min_child_samples': 6}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:46:16,694] Trial 13 finished with value: 0.9758064550011369 and parameters: {'num_leaves': 222, 'max_depth': 16, 'n_estimators': 808, 'learning_rate': 0.08822302004836759, 'min_child_samples': 30}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:46:38,992] Trial 14 finished with value: 0.9752824070950243 and parameters: {'num_leaves': 132, 'max_depth': 14, 'n_estimators': 790, 'learning_rate': 0.07095466498587788, 'min_child_samples': 16}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:46:40,170] Trial 15 finished with value: 0.9666481110542339 and parameters: {'num_leaves': 147, 'max_depth': 10, 'n_estimators': 113, 'learning_rate': 0.09053238794534162, 'min_child_samples': 48}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:47:01,380] Trial 16 finished with value: 0.9741256557430192 and parameters: {'num_leaves': 260, 'max_depth': 16, 'n_estimators': 622, 'learning_rate': 0.044877204427445666, 'min_child_samples': 32}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:47:07,039] Trial 17 finished with value: 0.9569798477426323 and parameters: {'num_leaves': 3, 'max_depth': 9, 'n_estimators': 990, 'learning_rate': 0.0688259136846836, 'min_child_samples': 41}. Best is trial 2 with value: 0.9768418373577431.\n",
            "[I 2024-02-17 23:47:17,497] Trial 18 finished with value: 0.9770292334487328 and parameters: {'num_leaves': 213, 'max_depth': 14, 'n_estimators': 423, 'learning_rate': 0.09863735046967562, 'min_child_samples': 11}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:47:28,261] Trial 19 finished with value: 0.976611753436837 and parameters: {'num_leaves': 266, 'max_depth': 25, 'n_estimators': 437, 'learning_rate': 0.07205858941673529, 'min_child_samples': 10}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:47:36,875] Trial 20 finished with value: 0.9760881359764677 and parameters: {'num_leaves': 225, 'max_depth': 18, 'n_estimators': 388, 'learning_rate': 0.08499190791723252, 'min_child_samples': 17}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:47:48,549] Trial 21 finished with value: 0.9756990955964842 and parameters: {'num_leaves': 276, 'max_depth': 25, 'n_estimators': 447, 'learning_rate': 0.07268683890931182, 'min_child_samples': 9}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:48:06,232] Trial 22 finished with value: 0.9764243088895003 and parameters: {'num_leaves': 257, 'max_depth': 22, 'n_estimators': 566, 'learning_rate': 0.09039545236930413, 'min_child_samples': 11}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:48:10,105] Trial 23 finished with value: 0.9742812191768266 and parameters: {'num_leaves': 218, 'max_depth': 14, 'n_estimators': 262, 'learning_rate': 0.06819909741957494, 'min_child_samples': 14}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:48:20,957] Trial 24 finished with value: 0.9746779613998338 and parameters: {'num_leaves': 297, 'max_depth': 23, 'n_estimators': 444, 'learning_rate': 0.048086784397685337, 'min_child_samples': 8}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:48:23,760] Trial 25 finished with value: 0.9632138803121084 and parameters: {'num_leaves': 267, 'max_depth': 5, 'n_estimators': 316, 'learning_rate': 0.07659761005090428, 'min_child_samples': 19}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:48:39,169] Trial 26 finished with value: 0.9763854006828581 and parameters: {'num_leaves': 172, 'max_depth': 18, 'n_estimators': 589, 'learning_rate': 0.09925065823936566, 'min_child_samples': 5}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:49:02,564] Trial 27 finished with value: 0.976181917873481 and parameters: {'num_leaves': 239, 'max_depth': 17, 'n_estimators': 712, 'learning_rate': 0.08590973484248846, 'min_child_samples': 13}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:49:15,338] Trial 28 finished with value: 0.9746501356941741 and parameters: {'num_leaves': 217, 'max_depth': 14, 'n_estimators': 494, 'learning_rate': 0.06364454275208574, 'min_child_samples': 26}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:49:21,249] Trial 29 finished with value: 0.9758612125379773 and parameters: {'num_leaves': 145, 'max_depth': 20, 'n_estimators': 357, 'learning_rate': 0.09210961646828805, 'min_child_samples': 8}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:49:23,094] Trial 30 finished with value: 0.9708748235211746 and parameters: {'num_leaves': 164, 'max_depth': 10, 'n_estimators': 172, 'learning_rate': 0.08491661660227422, 'min_child_samples': 13}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:49:53,907] Trial 31 finished with value: 0.9757931658418674 and parameters: {'num_leaves': 200, 'max_depth': 12, 'n_estimators': 878, 'learning_rate': 0.09609054992106947, 'min_child_samples': 22}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:50:13,904] Trial 32 finished with value: 0.9759811376365077 and parameters: {'num_leaves': 178, 'max_depth': 13, 'n_estimators': 678, 'learning_rate': 0.09409181979296903, 'min_child_samples': 20}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:50:16,868] Trial 33 finished with value: 0.9581867649027772 and parameters: {'num_leaves': 243, 'max_depth': 3, 'n_estimators': 452, 'learning_rate': 0.07861182969637612, 'min_child_samples': 9}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:50:30,373] Trial 34 finished with value: 0.9709849879295572 and parameters: {'num_leaves': 215, 'max_depth': 8, 'n_estimators': 559, 'learning_rate': 0.08186490551871806, 'min_child_samples': 25}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:50:51,473] Trial 35 finished with value: 0.975306942000272 and parameters: {'num_leaves': 80, 'max_depth': 11, 'n_estimators': 866, 'learning_rate': 0.07633639713993322, 'min_child_samples': 11}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:51:05,217] Trial 36 finished with value: 0.9757931658418674 and parameters: {'num_leaves': 202, 'max_depth': 15, 'n_estimators': 512, 'learning_rate': 0.09994823320212756, 'min_child_samples': 28}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:51:31,723] Trial 37 finished with value: 0.9765393207553622 and parameters: {'num_leaves': 284, 'max_depth': 19, 'n_estimators': 762, 'learning_rate': 0.05542608280078085, 'min_child_samples': 15}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:51:46,871] Trial 38 finished with value: 0.9615196795309346 and parameters: {'num_leaves': 191, 'max_depth': 7, 'n_estimators': 617, 'learning_rate': 0.010399657570694464, 'min_child_samples': 7}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:51:49,598] Trial 39 finished with value: 0.9646455703899859 and parameters: {'num_leaves': 255, 'max_depth': 5, 'n_estimators': 309, 'learning_rate': 0.09489981765748046, 'min_child_samples': 11}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:52:14,176] Trial 40 finished with value: 0.9753757000507538 and parameters: {'num_leaves': 105, 'max_depth': 21, 'n_estimators': 920, 'learning_rate': 0.06347652496011533, 'min_child_samples': 23}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:52:40,411] Trial 41 finished with value: 0.9766499937307901 and parameters: {'num_leaves': 283, 'max_depth': 19, 'n_estimators': 771, 'learning_rate': 0.05502895886717944, 'min_child_samples': 16}. Best is trial 18 with value: 0.9770292334487328.\n",
            "[I 2024-02-17 23:53:10,904] Trial 42 finished with value: 0.977302984142506 and parameters: {'num_leaves': 271, 'max_depth': 25, 'n_estimators': 842, 'learning_rate': 0.049672512714030864, 'min_child_samples': 18}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:53:41,150] Trial 43 finished with value: 0.9771290606493451 and parameters: {'num_leaves': 300, 'max_depth': 25, 'n_estimators': 838, 'learning_rate': 0.04825718909747558, 'min_child_samples': 12}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:54:08,203] Trial 44 finished with value: 0.9750817097276341 and parameters: {'num_leaves': 298, 'max_depth': 23, 'n_estimators': 798, 'learning_rate': 0.02722424563481733, 'min_child_samples': 18}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:54:38,135] Trial 45 finished with value: 0.9767005435075128 and parameters: {'num_leaves': 286, 'max_depth': 24, 'n_estimators': 831, 'learning_rate': 0.04979179470790943, 'min_child_samples': 16}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:55:05,847] Trial 46 finished with value: 0.9764757399526617 and parameters: {'num_leaves': 233, 'max_depth': 24, 'n_estimators': 838, 'learning_rate': 0.04782014589422446, 'min_child_samples': 12}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:55:41,423] Trial 47 finished with value: 0.9771353708972064 and parameters: {'num_leaves': 274, 'max_depth': 22, 'n_estimators': 1000, 'learning_rate': 0.039226768708864705, 'min_child_samples': 15}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:56:15,035] Trial 48 finished with value: 0.9764078403465244 and parameters: {'num_leaves': 268, 'max_depth': 22, 'n_estimators': 997, 'learning_rate': 0.03701749478567963, 'min_child_samples': 6}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:56:47,177] Trial 49 finished with value: 0.9766753307373371 and parameters: {'num_leaves': 252, 'max_depth': 21, 'n_estimators': 928, 'learning_rate': 0.038635966353564345, 'min_child_samples': 20}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:57:19,122] Trial 50 finished with value: 0.975040901055729 and parameters: {'num_leaves': 275, 'max_depth': 25, 'n_estimators': 961, 'learning_rate': 0.02467467987539127, 'min_child_samples': 14}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:57:49,417] Trial 51 finished with value: 0.9771603243829798 and parameters: {'num_leaves': 292, 'max_depth': 24, 'n_estimators': 828, 'learning_rate': 0.051272238758326844, 'min_child_samples': 16}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:58:15,273] Trial 52 finished with value: 0.9763527904255355 and parameters: {'num_leaves': 292, 'max_depth': 23, 'n_estimators': 726, 'learning_rate': 0.04048166021052583, 'min_child_samples': 15}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:58:47,657] Trial 53 finished with value: 0.9767434428855939 and parameters: {'num_leaves': 277, 'max_depth': 25, 'n_estimators': 877, 'learning_rate': 0.05151473125345438, 'min_child_samples': 18}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:59:07,393] Trial 54 finished with value: 0.9753757000507538 and parameters: {'num_leaves': 230, 'max_depth': 22, 'n_estimators': 688, 'learning_rate': 0.04323904028755475, 'min_child_samples': 10}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-17 23:59:41,198] Trial 55 finished with value: 0.9760335857889609 and parameters: {'num_leaves': 299, 'max_depth': 24, 'n_estimators': 955, 'learning_rate': 0.03202396511451129, 'min_child_samples': 12}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:00:05,405] Trial 56 finished with value: 0.9766926459536849 and parameters: {'num_leaves': 248, 'max_depth': 23, 'n_estimators': 755, 'learning_rate': 0.058460174495273964, 'min_child_samples': 7}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:00:38,104] Trial 57 finished with value: 0.977228866538383 and parameters: {'num_leaves': 264, 'max_depth': 21, 'n_estimators': 892, 'learning_rate': 0.052127429349018914, 'min_child_samples': 18}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:01:15,032] Trial 58 finished with value: 0.9763984021980243 and parameters: {'num_leaves': 262, 'max_depth': 21, 'n_estimators': 965, 'learning_rate': 0.050921757698812825, 'min_child_samples': 22}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:01:49,159] Trial 59 finished with value: 0.9762885810388187 and parameters: {'num_leaves': 269, 'max_depth': 20, 'n_estimators': 897, 'learning_rate': 0.04363737504546735, 'min_child_samples': 18}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:02:22,053] Trial 60 finished with value: 0.9763723669088628 and parameters: {'num_leaves': 288, 'max_depth': 22, 'n_estimators': 825, 'learning_rate': 0.05263980889856364, 'min_child_samples': 39}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:02:53,850] Trial 61 finished with value: 0.9763014861745333 and parameters: {'num_leaves': 274, 'max_depth': 24, 'n_estimators': 901, 'learning_rate': 0.060541053549184994, 'min_child_samples': 14}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:03:21,458] Trial 62 finished with value: 0.9760355547670483 and parameters: {'num_leaves': 249, 'max_depth': 25, 'n_estimators': 853, 'learning_rate': 0.046828612700628255, 'min_child_samples': 9}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:03:47,357] Trial 63 finished with value: 0.9758197113452084 and parameters: {'num_leaves': 260, 'max_depth': 15, 'n_estimators': 795, 'learning_rate': 0.04052840255203815, 'min_child_samples': 17}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:04:16,764] Trial 64 finished with value: 0.9757798437557946 and parameters: {'num_leaves': 234, 'max_depth': 17, 'n_estimators': 935, 'learning_rate': 0.03291828785225363, 'min_child_samples': 12}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:04:37,202] Trial 65 finished with value: 0.975765535032322 and parameters: {'num_leaves': 300, 'max_depth': 23, 'n_estimators': 649, 'learning_rate': 0.03510976787996199, 'min_child_samples': 20}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:05:12,877] Trial 66 finished with value: 0.9767053922059321 and parameters: {'num_leaves': 279, 'max_depth': 20, 'n_estimators': 977, 'learning_rate': 0.05780100170715203, 'min_child_samples': 15}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:05:24,328] Trial 67 finished with value: 0.9747583591889117 and parameters: {'num_leaves': 289, 'max_depth': 24, 'n_estimators': 475, 'learning_rate': 0.044586592768127244, 'min_child_samples': 5}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:05:54,764] Trial 68 finished with value: 0.976304468078774 and parameters: {'num_leaves': 214, 'max_depth': 15, 'n_estimators': 883, 'learning_rate': 0.05436836586695652, 'min_child_samples': 33}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:06:08,904] Trial 69 finished with value: 0.97646637343569 and parameters: {'num_leaves': 245, 'max_depth': 13, 'n_estimators': 537, 'learning_rate': 0.066587750142736, 'min_child_samples': 13}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:06:12,865] Trial 70 finished with value: 0.9648417426962325 and parameters: {'num_leaves': 42, 'max_depth': 25, 'n_estimators': 386, 'learning_rate': 0.027847152584374223, 'min_child_samples': 24}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:06:43,969] Trial 71 finished with value: 0.9765437108393968 and parameters: {'num_leaves': 274, 'max_depth': 25, 'n_estimators': 860, 'learning_rate': 0.05227421124808539, 'min_child_samples': 18}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:07:17,155] Trial 72 finished with value: 0.9762626751299242 and parameters: {'num_leaves': 265, 'max_depth': 24, 'n_estimators': 912, 'learning_rate': 0.04915082185051032, 'min_child_samples': 19}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:07:44,310] Trial 73 finished with value: 0.9770109960575228 and parameters: {'num_leaves': 280, 'max_depth': 22, 'n_estimators': 820, 'learning_rate': 0.04534218891540738, 'min_child_samples': 10}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:08:06,610] Trial 74 finished with value: 0.9766542176274267 and parameters: {'num_leaves': 256, 'max_depth': 22, 'n_estimators': 744, 'learning_rate': 0.04721750877859792, 'min_child_samples': 10}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:08:34,457] Trial 75 finished with value: 0.9754964152023249 and parameters: {'num_leaves': 292, 'max_depth': 11, 'n_estimators': 814, 'learning_rate': 0.04130497371903702, 'min_child_samples': 8}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:08:59,783] Trial 76 finished with value: 0.9764629297076509 and parameters: {'num_leaves': 240, 'max_depth': 23, 'n_estimators': 776, 'learning_rate': 0.04642386407040923, 'min_child_samples': 11}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:09:23,314] Trial 77 finished with value: 0.9759135968230114 and parameters: {'num_leaves': 282, 'max_depth': 18, 'n_estimators': 712, 'learning_rate': 0.062434441249595005, 'min_child_samples': 9}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:09:43,125] Trial 78 finished with value: 0.9767735783874336 and parameters: {'num_leaves': 208, 'max_depth': 21, 'n_estimators': 606, 'learning_rate': 0.08920013684100092, 'min_child_samples': 47}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:10:13,478] Trial 79 finished with value: 0.9759014858147946 and parameters: {'num_leaves': 227, 'max_depth': 19, 'n_estimators': 843, 'learning_rate': 0.09800914885981829, 'min_child_samples': 7}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:10:41,841] Trial 80 finished with value: 0.9765437108393968 and parameters: {'num_leaves': 271, 'max_depth': 16, 'n_estimators': 804, 'learning_rate': 0.05415019137491767, 'min_child_samples': 14}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:11:02,656] Trial 81 finished with value: 0.9770166159437226 and parameters: {'num_leaves': 208, 'max_depth': 21, 'n_estimators': 592, 'learning_rate': 0.09083409255295904, 'min_child_samples': 50}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:11:20,786] Trial 82 finished with value: 0.9761164310332465 and parameters: {'num_leaves': 162, 'max_depth': 22, 'n_estimators': 591, 'learning_rate': 0.08731397656423437, 'min_child_samples': 43}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:11:37,002] Trial 83 finished with value: 0.9760205222335842 and parameters: {'num_leaves': 258, 'max_depth': 21, 'n_estimators': 527, 'learning_rate': 0.09306395885397417, 'min_child_samples': 16}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:11:59,615] Trial 84 finished with value: 0.9763305029072495 and parameters: {'num_leaves': 187, 'max_depth': 23, 'n_estimators': 681, 'learning_rate': 0.09086359132622121, 'min_child_samples': 29}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:12:04,297] Trial 85 finished with value: 0.9742812191768266 and parameters: {'num_leaves': 283, 'max_depth': 24, 'n_estimators': 251, 'learning_rate': 0.0833153007775327, 'min_child_samples': 36}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:12:29,639] Trial 86 finished with value: 0.9729614001184289 and parameters: {'num_leaves': 292, 'max_depth': 20, 'n_estimators': 630, 'learning_rate': 0.03695170493287634, 'min_child_samples': 49}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:12:45,145] Trial 87 finished with value: 0.97532224988259 and parameters: {'num_leaves': 222, 'max_depth': 13, 'n_estimators': 560, 'learning_rate': 0.04955420927268203, 'min_child_samples': 12}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:13:16,206] Trial 88 finished with value: 0.9762756440599023 and parameters: {'num_leaves': 208, 'max_depth': 23, 'n_estimators': 939, 'learning_rate': 0.04202629421023923, 'min_child_samples': 13}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:13:27,882] Trial 89 finished with value: 0.9759014858147946 and parameters: {'num_leaves': 180, 'max_depth': 22, 'n_estimators': 496, 'learning_rate': 0.09734043230239928, 'min_child_samples': 21}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:13:34,234] Trial 90 finished with value: 0.9740453799820744 and parameters: {'num_leaves': 236, 'max_depth': 25, 'n_estimators': 340, 'learning_rate': 0.060253583001044685, 'min_child_samples': 26}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:13:49,125] Trial 91 finished with value: 0.9750528288843519 and parameters: {'num_leaves': 125, 'max_depth': 21, 'n_estimators': 600, 'learning_rate': 0.09126502059504599, 'min_child_samples': 47}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:14:16,275] Trial 92 finished with value: 0.9755778688851935 and parameters: {'num_leaves': 196, 'max_depth': 20, 'n_estimators': 740, 'learning_rate': 0.09561674526745374, 'min_child_samples': 50}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:14:41,593] Trial 93 finished with value: 0.9758064550011369 and parameters: {'num_leaves': 263, 'max_depth': 21, 'n_estimators': 671, 'learning_rate': 0.056430050399003305, 'min_child_samples': 47}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:14:59,522] Trial 94 finished with value: 0.975510785893334 and parameters: {'num_leaves': 208, 'max_depth': 22, 'n_estimators': 576, 'learning_rate': 0.09343258038746537, 'min_child_samples': 44}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:15:22,054] Trial 95 finished with value: 0.9761558202718786 and parameters: {'num_leaves': 250, 'max_depth': 19, 'n_estimators': 704, 'learning_rate': 0.08917074915088691, 'min_child_samples': 10}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:15:53,530] Trial 96 finished with value: 0.9761427230138261 and parameters: {'num_leaves': 211, 'max_depth': 24, 'n_estimators': 892, 'learning_rate': 0.05283963103261615, 'min_child_samples': 46}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:16:13,059] Trial 97 finished with value: 0.9772222687310164 and parameters: {'num_leaves': 227, 'max_depth': 17, 'n_estimators': 610, 'learning_rate': 0.08815778767881034, 'min_child_samples': 49}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:16:23,525] Trial 98 finished with value: 0.9711957736139285 and parameters: {'num_leaves': 243, 'max_depth': 17, 'n_estimators': 419, 'learning_rate': 0.04478237374066403, 'min_child_samples': 50}. Best is trial 42 with value: 0.977302984142506.\n",
            "[I 2024-02-18 00:16:48,230] Trial 99 finished with value: 0.9772725354499492 and parameters: {'num_leaves': 229, 'max_depth': 15, 'n_estimators': 784, 'learning_rate': 0.0859802593209955, 'min_child_samples': 6}. Best is trial 42 with value: 0.977302984142506.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.977302984142506, \n",
            "params {'num_leaves': 271, 'max_depth': 25, 'n_estimators': 842, 'learning_rate': 0.049672512714030864, 'min_child_samples': 18}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveLGBM(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 25),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
        "        'verbose' : -1,\n",
        "        'boosting' : 'dart',\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = LGBMClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveLGBM(trial, x_train, y_train, x_val, y_val), n_trials=100)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f42df31",
      "metadata": {},
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9067b7c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:24:19,281] A new study created in memory with name: no-name-cf715e54-a711-4222-a128-5a64ca99952b\n",
            "[I 2024-02-17 17:24:22,336] Trial 0 finished with value: 0.9742965682985676 and parameters: {'n_estimators': 959, 'learning_rate': 0.07436704297351776, 'max_depth': 16, 'eval_metric': 'error'}. Best is trial 0 with value: 0.9742965682985676.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9742965682985676, \n",
            "params {'n_estimators': 959, 'learning_rate': 0.07436704297351776, 'max_depth': 16, 'eval_metric': 'error'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveXGB(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 1500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 25),\n",
        "        'objective': 'binary:logistic',  # 이진 분류\n",
        "        'eval_metric': trial.suggest_categorical(\"eval_metric\", [\"logloss\", \"auc\", \"error\"]),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveXGB(trial, x_train, y_train, x_val, y_val), n_trials=1)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1fcab3",
      "metadata": {},
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2630cbaa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:24:29,037] A new study created in memory with name: no-name-a651a7a3-95ce-4a8a-84f8-6916ff40f76a\n",
            "[I 2024-02-17 17:24:29,257] Trial 0 finished with value: 0.9615427574699139 and parameters: {'max_depth': 30, 'min_samples_split': 37, 'min_samples_leaf': 13, 'criterion': 'gini'}. Best is trial 0 with value: 0.9615427574699139.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9615427574699139, \n",
            "params {'max_depth': 30, 'min_samples_split': 37, 'min_samples_leaf': 13, 'criterion': 'gini'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveDT(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = DecisionTreeClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveDT(trial, x_train, y_train, x_val, y_val), n_trials=1)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2959a287",
      "metadata": {},
      "source": [
        "ExtraTrees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cefd4703",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:24:34,746] A new study created in memory with name: no-name-4aca2d4a-d2ce-4e08-b4e7-56f635543340\n",
            "[I 2024-02-17 17:24:48,227] Trial 0 finished with value: 0.922567475656384 and parameters: {'n_estimators': 729, 'max_depth': 28, 'min_samples_split': 13, 'min_samples_leaf': 6, 'criterion': 'entropy'}. Best is trial 0 with value: 0.922567475656384.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.922567475656384, \n",
            "params {'n_estimators': 729, 'max_depth': 28, 'min_samples_split': 13, 'min_samples_leaf': 6, 'criterion': 'entropy'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveET(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 400, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 10, 35),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = ExtraTreesClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveET(trial, x_train, y_train, x_val, y_val), n_trials=1)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1baf6cfe",
      "metadata": {},
      "source": [
        "GradientBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3ca1019e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 22:02:38,993] A new study created in memory with name: no-name-3073e005-1f46-4a38-9705-749d1a85fb09\n",
            "[I 2024-02-17 22:07:59,240] Trial 0 finished with value: 0.9766670587717639 and parameters: {'n_estimators': 1139, 'learning_rate': 0.08006325564606936, 'max_depth': 11, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.9766670587717639.\n",
            "[I 2024-02-17 22:12:05,140] Trial 1 finished with value: 0.9775900880510222 and parameters: {'n_estimators': 1039, 'learning_rate': 0.07521258791466592, 'max_depth': 9, 'min_samples_leaf': 19}. Best is trial 1 with value: 0.9775900880510222.\n",
            "[I 2024-02-17 22:19:18,939] Trial 2 finished with value: 0.9763564093176315 and parameters: {'n_estimators': 1471, 'learning_rate': 0.05684090631780444, 'max_depth': 13, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.9775900880510222.\n",
            "[I 2024-02-17 22:21:26,008] Trial 3 finished with value: 0.9763527904255355 and parameters: {'n_estimators': 1155, 'learning_rate': 0.09479176468048628, 'max_depth': 5, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.9775900880510222.\n",
            "[I 2024-02-17 22:24:48,518] Trial 4 finished with value: 0.976411371563894 and parameters: {'n_estimators': 716, 'learning_rate': 0.08828338918835565, 'max_depth': 13, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.9775900880510222.\n",
            "[I 2024-02-17 22:30:25,291] Trial 5 finished with value: 0.977950898925844 and parameters: {'n_estimators': 1483, 'learning_rate': 0.08594109949517065, 'max_depth': 10, 'min_samples_leaf': 17}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:31:58,248] Trial 6 finished with value: 0.9756451244235135 and parameters: {'n_estimators': 794, 'learning_rate': 0.07479447149292667, 'max_depth': 6, 'min_samples_leaf': 20}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:34:36,946] Trial 7 finished with value: 0.9771727550651755 and parameters: {'n_estimators': 1118, 'learning_rate': 0.05902633579933665, 'max_depth': 7, 'min_samples_leaf': 17}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:36:26,977] Trial 8 finished with value: 0.9747332021713773 and parameters: {'n_estimators': 1065, 'learning_rate': 0.0697903764208054, 'max_depth': 5, 'min_samples_leaf': 14}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:42:59,044] Trial 9 finished with value: 0.9768290924017532 and parameters: {'n_estimators': 1190, 'learning_rate': 0.07318537978123299, 'max_depth': 15, 'min_samples_leaf': 15}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:47:56,128] Trial 10 finished with value: 0.9765861021449022 and parameters: {'n_estimators': 1474, 'learning_rate': 0.039721853505293225, 'max_depth': 9, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:50:59,624] Trial 11 finished with value: 0.9765564893717472 and parameters: {'n_estimators': 936, 'learning_rate': 0.0989502950754531, 'max_depth': 9, 'min_samples_leaf': 20}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:56:41,093] Trial 12 finished with value: 0.9769355633069186 and parameters: {'n_estimators': 1321, 'learning_rate': 0.08201484591986404, 'max_depth': 11, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 22:59:35,928] Trial 13 finished with value: 0.9774156918490846 and parameters: {'n_estimators': 967, 'learning_rate': 0.04778944266526734, 'max_depth': 8, 'min_samples_leaf': 17}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:04:35,508] Trial 14 finished with value: 0.9766499937307901 and parameters: {'n_estimators': 1324, 'learning_rate': 0.08942219803956243, 'max_depth': 10, 'min_samples_leaf': 16}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:10:30,235] Trial 15 finished with value: 0.9770166159437226 and parameters: {'n_estimators': 1299, 'learning_rate': 0.06334192866446264, 'max_depth': 12, 'min_samples_leaf': 19}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:13:19,622] Trial 16 finished with value: 0.9769859757141476 and parameters: {'n_estimators': 931, 'learning_rate': 0.08361765646231559, 'max_depth': 8, 'min_samples_leaf': 11}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:17:21,719] Trial 17 finished with value: 0.9770918557262593 and parameters: {'n_estimators': 1051, 'learning_rate': 0.05260907820083393, 'max_depth': 10, 'min_samples_leaf': 18}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:20:35,338] Trial 18 finished with value: 0.9775090217206441 and parameters: {'n_estimators': 1246, 'learning_rate': 0.06803643644478456, 'max_depth': 7, 'min_samples_leaf': 15}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:28:43,193] Trial 19 finished with value: 0.9771353708972064 and parameters: {'n_estimators': 1405, 'learning_rate': 0.03101021349133149, 'max_depth': 15, 'min_samples_leaf': 11}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:31:24,339] Trial 20 finished with value: 0.9774156918490846 and parameters: {'n_estimators': 843, 'learning_rate': 0.07671176330839087, 'max_depth': 9, 'min_samples_leaf': 20}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:34:33,511] Trial 21 finished with value: 0.9775334734198516 and parameters: {'n_estimators': 1253, 'learning_rate': 0.06770322311517651, 'max_depth': 7, 'min_samples_leaf': 15}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:37:58,933] Trial 22 finished with value: 0.9767434428855939 and parameters: {'n_estimators': 1388, 'learning_rate': 0.06464336988093557, 'max_depth': 7, 'min_samples_leaf': 16}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:41:26,562] Trial 23 finished with value: 0.9769859757141476 and parameters: {'n_estimators': 1224, 'learning_rate': 0.08968803517433059, 'max_depth': 8, 'min_samples_leaf': 18}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:45:56,162] Trial 24 finished with value: 0.9775655805621609 and parameters: {'n_estimators': 1014, 'learning_rate': 0.08428393368421147, 'max_depth': 11, 'min_samples_leaf': 15}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:50:27,450] Trial 25 finished with value: 0.9766626778159702 and parameters: {'n_estimators': 999, 'learning_rate': 0.08637386061944977, 'max_depth': 11, 'min_samples_leaf': 17}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:54:41,180] Trial 26 finished with value: 0.9767989754409336 and parameters: {'n_estimators': 883, 'learning_rate': 0.09542527772206062, 'max_depth': 12, 'min_samples_leaf': 19}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-17 23:59:39,593] Trial 27 finished with value: 0.9765732288484092 and parameters: {'n_estimators': 1019, 'learning_rate': 0.07844135435585584, 'max_depth': 12, 'min_samples_leaf': 14}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-18 00:03:59,630] Trial 28 finished with value: 0.9768116270453153 and parameters: {'n_estimators': 1082, 'learning_rate': 0.09402076022750888, 'max_depth': 10, 'min_samples_leaf': 16}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-18 00:09:01,493] Trial 29 finished with value: 0.977241295647147 and parameters: {'n_estimators': 1151, 'learning_rate': 0.08075356880384957, 'max_depth': 11, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-18 00:13:47,966] Trial 30 finished with value: 0.9766670587717639 and parameters: {'n_estimators': 887, 'learning_rate': 0.07249275198357576, 'max_depth': 13, 'min_samples_leaf': 13}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-18 00:18:22,865] Trial 31 finished with value: 0.9774647246119109 and parameters: {'n_estimators': 1407, 'learning_rate': 0.08396303398887327, 'max_depth': 9, 'min_samples_leaf': 15}. Best is trial 5 with value: 0.977950898925844.\n",
            "[I 2024-02-18 00:22:25,368] Trial 32 finished with value: 0.9779960216302004 and parameters: {'n_estimators': 1274, 'learning_rate': 0.06889562347388267, 'max_depth': 10, 'min_samples_leaf': 14}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 00:26:14,486] Trial 33 finished with value: 0.97696083174375 and parameters: {'n_estimators': 1105, 'learning_rate': 0.06040921133353103, 'max_depth': 10, 'min_samples_leaf': 14}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 00:30:06,780] Trial 34 finished with value: 0.9772974826343336 and parameters: {'n_estimators': 1020, 'learning_rate': 0.07854778885296917, 'max_depth': 10, 'min_samples_leaf': 5}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 00:36:52,279] Trial 35 finished with value: 0.976598943638467 and parameters: {'n_estimators': 1490, 'learning_rate': 0.09194926039139031, 'max_depth': 12, 'min_samples_leaf': 19}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 00:41:37,528] Trial 36 finished with value: 0.9770418197970752 and parameters: {'n_estimators': 1168, 'learning_rate': 0.0718065187720291, 'max_depth': 11, 'min_samples_leaf': 12}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 00:44:21,331] Trial 37 finished with value: 0.9771478630282882 and parameters: {'n_estimators': 764, 'learning_rate': 0.07689068758650537, 'max_depth': 9, 'min_samples_leaf': 18}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 00:52:39,774] Trial 38 finished with value: 0.9761688851885991 and parameters: {'n_estimators': 1443, 'learning_rate': 0.05358429825010236, 'max_depth': 14, 'min_samples_leaf': 17}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 00:58:13,772] Trial 39 finished with value: 0.9770793929545335 and parameters: {'n_estimators': 1205, 'learning_rate': 0.08719143082515629, 'max_depth': 11, 'min_samples_leaf': 13}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:02:47,379] Trial 40 finished with value: 0.9773396352766691 and parameters: {'n_estimators': 1367, 'learning_rate': 0.08530654556047675, 'max_depth': 8, 'min_samples_leaf': 9}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:05:44,311] Trial 41 finished with value: 0.9774279953430577 and parameters: {'n_estimators': 1277, 'learning_rate': 0.06826192379107554, 'max_depth': 6, 'min_samples_leaf': 14}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:08:16,671] Trial 42 finished with value: 0.9767812136630234 and parameters: {'n_estimators': 1118, 'learning_rate': 0.07481279445394587, 'max_depth': 6, 'min_samples_leaf': 15}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:13:01,332] Trial 43 finished with value: 0.9767560641052474 and parameters: {'n_estimators': 1256, 'learning_rate': 0.0692329696292406, 'max_depth': 10, 'min_samples_leaf': 16}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:15:28,915] Trial 44 finished with value: 0.9752694048497594 and parameters: {'n_estimators': 1345, 'learning_rate': 0.06070507956204523, 'max_depth': 5, 'min_samples_leaf': 17}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:18:43,100] Trial 45 finished with value: 0.9766245316472566 and parameters: {'n_estimators': 1036, 'learning_rate': 0.08208619486916448, 'max_depth': 9, 'min_samples_leaf': 15}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:22:12,993] Trial 46 finished with value: 0.9776955163995608 and parameters: {'n_estimators': 1440, 'learning_rate': 0.09986577910563535, 'max_depth': 7, 'min_samples_leaf': 14}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:26:06,482] Trial 47 finished with value: 0.9775578051146651 and parameters: {'n_estimators': 1455, 'learning_rate': 0.09952694768724925, 'max_depth': 8, 'min_samples_leaf': 19}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:28:50,456] Trial 48 finished with value: 0.9776628904409673 and parameters: {'n_estimators': 1437, 'learning_rate': 0.09585444059961169, 'max_depth': 6, 'min_samples_leaf': 14}. Best is trial 32 with value: 0.9779960216302004.\n",
            "[I 2024-02-18 01:31:40,383] Trial 49 finished with value: 0.9783465251014711 and parameters: {'n_estimators': 1499, 'learning_rate': 0.09584635579147395, 'max_depth': 6, 'min_samples_leaf': 12}. Best is trial 49 with value: 0.9783465251014711.\n",
            "[I 2024-02-18 01:34:24,681] Trial 50 finished with value: 0.9771851551782991 and parameters: {'n_estimators': 1433, 'learning_rate': 0.09637287873120322, 'max_depth': 6, 'min_samples_leaf': 11}. Best is trial 49 with value: 0.9783465251014711.\n",
            "[I 2024-02-18 01:36:55,976] Trial 51 finished with value: 0.9773760182626234 and parameters: {'n_estimators': 1492, 'learning_rate': 0.09244388976178157, 'max_depth': 5, 'min_samples_leaf': 12}. Best is trial 49 with value: 0.9783465251014711.\n",
            "[I 2024-02-18 01:39:43,102] Trial 52 finished with value: 0.97847409187267 and parameters: {'n_estimators': 1425, 'learning_rate': 0.09883679411048218, 'max_depth': 6, 'min_samples_leaf': 13}. Best is trial 52 with value: 0.97847409187267.\n",
            "[I 2024-02-18 01:42:24,349] Trial 53 finished with value: 0.9777076325406282 and parameters: {'n_estimators': 1420, 'learning_rate': 0.09742239053615016, 'max_depth': 6, 'min_samples_leaf': 10}. Best is trial 52 with value: 0.97847409187267.\n",
            "[I 2024-02-18 01:44:36,233] Trial 54 finished with value: 0.9771851551782991 and parameters: {'n_estimators': 1368, 'learning_rate': 0.09805419668896645, 'max_depth': 5, 'min_samples_leaf': 10}. Best is trial 52 with value: 0.97847409187267.\n",
            "[I 2024-02-18 01:47:28,346] Trial 55 finished with value: 0.9771659926351111 and parameters: {'n_estimators': 1469, 'learning_rate': 0.09968059757757716, 'max_depth': 6, 'min_samples_leaf': 8}. Best is trial 52 with value: 0.97847409187267.\n",
            "[I 2024-02-18 01:50:38,475] Trial 56 finished with value: 0.9767862925902935 and parameters: {'n_estimators': 1415, 'learning_rate': 0.09078813453022319, 'max_depth': 7, 'min_samples_leaf': 9}. Best is trial 52 with value: 0.97847409187267.\n",
            "[I 2024-02-18 01:52:52,894] Trial 57 finished with value: 0.9771166894707821 and parameters: {'n_estimators': 1318, 'learning_rate': 0.09724443837887807, 'max_depth': 5, 'min_samples_leaf': 10}. Best is trial 52 with value: 0.97847409187267.\n",
            "[I 2024-02-18 01:56:26,127] Trial 58 finished with value: 0.9771975248253071 and parameters: {'n_estimators': 1496, 'learning_rate': 0.09370353135198299, 'max_depth': 7, 'min_samples_leaf': 13}. Best is trial 52 with value: 0.97847409187267.\n",
            "[I 2024-02-18 01:59:25,588] Trial 59 finished with value: 0.9771659926351111 and parameters: {'n_estimators': 1373, 'learning_rate': 0.08854441246758993, 'max_depth': 6, 'min_samples_leaf': 11}. Best is trial 52 with value: 0.97847409187267.\n",
            "[W 2024-02-18 02:00:36,567] Trial 60 failed with parameters: {'n_estimators': 1343, 'learning_rate': 0.09373345626103254, 'max_depth': 7, 'min_samples_leaf': 12} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_33336\\3917606402.py\", line 25, in <lambda>\n",
            "    study.optimize(lambda trial: objectiveGB(trial, x_train, y_train, x_val, y_val), n_trials=70)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_33336\\3917606402.py\", line 16, in objectiveGB\n",
            "    model.fit(x_tr, y_tr)\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 784, in fit\n",
            "    n_stages = self._fit_stages(\n",
            "               ^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 880, in _fit_stages\n",
            "    raw_predictions = self._fit_stage(\n",
            "                      ^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 490, in _fit_stage\n",
            "    tree.fit(\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1377, in fit\n",
            "    super()._fit(\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
            "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
            "KeyboardInterrupt\n",
            "[W 2024-02-18 02:00:36,574] Trial 60 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 하이퍼 파라미터 튜닝\u001b[39;00m\n\u001b[0;32m     24\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 25\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjectiveGB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial: score \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mparams \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams))\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[16], line 25\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 하이퍼 파라미터 튜닝\u001b[39;00m\n\u001b[0;32m     24\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 25\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjectiveGB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial: score \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mparams \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams))\n",
            "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mobjectiveGB\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m      7\u001b[0m param \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m700\u001b[39m, \u001b[38;5;241m1500\u001b[39m),\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.03\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_val)\n\u001b[0;32m     18\u001b[0m score \u001b[38;5;241m=\u001b[39m f1_score(y_val, pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    877\u001b[0m         )\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 490\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveGB(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 700, 1500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 20),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = GradientBoostingClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveGB(trial, x_train, y_train, x_val, y_val), n_trials=70)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40c1c554",
      "metadata": {},
      "source": [
        "AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ea58a2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:30:13,485] A new study created in memory with name: no-name-13940382-acb4-4b58-981e-660f38516d26\n",
            "[I 2024-02-17 17:30:55,339] Trial 0 finished with value: 0.9561994360135005 and parameters: {'n_estimators': 1549, 'learning_rate': 0.7436704297351775, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.9561994360135005.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9561994360135005, \n",
            "params {'n_estimators': 1549, 'learning_rate': 0.7436704297351775, 'algorithm': 'SAMME'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveAdaBoost(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 1000, 2000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 1.0),\n",
        "        'algorithm': trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R']),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = AdaBoostClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveAdaBoost(trial, x_train, y_train, x_val, y_val), n_trials=1)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3401ec15",
      "metadata": {
        "id": "3401ec15"
      },
      "source": [
        "### 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a019f4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# 보팅\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "# 스테킹\n",
        "from sklearn.ensemble import StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9193fac9",
      "metadata": {
        "id": "9193fac9"
      },
      "outputs": [],
      "source": [
        "# RandomForest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=1056     \n",
        "    , max_depth=30    \n",
        "    , min_samples_split=3   \n",
        "    , min_samples_leaf=1   \n",
        "    , bootstrap=True\n",
        "    , criterion='entropy'\n",
        ")\n",
        "\n",
        "# LightGBM\n",
        "lgb_model = LGBMClassifier(\n",
        "    num_leaves=162\n",
        "    , max_depth=10\n",
        "    , n_estimators=487\n",
        "    , learning_rate=0.07324658507873466\n",
        "    , min_child_samples=31\n",
        "    , verbose = -1\n",
        ")\n",
        "\n",
        "# LightGBM_dart\n",
        "lgb_dart_model = LGBMClassifier(\n",
        "    num_leaves=170\n",
        "    , max_depth=13\n",
        "    , n_estimators=692\n",
        "    , learning_rate=0.0916736042020453\n",
        "    , min_child_samples=10\n",
        "    , verbose = -1\n",
        "    , boosting_type=\"dart\"\n",
        ")\n",
        "\n",
        "# XGBoost \n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=1427\n",
        "    , learning_rate=0.08645845446703926\n",
        "    , max_depth=7\n",
        "    , objective='binary:logistic'\n",
        "    , eval_metric = 'error'\n",
        ")\n",
        "\n",
        "# GradientBoosting\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=1425\n",
        "    , learning_rate=0.09883679411048218\n",
        "    , max_depth=6\n",
        "    , min_samples_leaf=13\n",
        ")\n",
        "\n",
        "# DecisionTree\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=24\n",
        "    , min_samples_split=2  # 노드를 분할하기 위한 최소 샘플 수\n",
        "    , min_samples_leaf=1  # 리프 노드에 필요한 최소 샘플 수\n",
        "    , criterion = 'entropy'\n",
        ")  \n",
        "\n",
        "# ExtraTrees\n",
        "et_model = ExtraTreesClassifier(\n",
        "    n_estimators=486\n",
        "    , min_samples_split=3  # 노드를 분할하기 위한 최소 샘플 수\n",
        "    , min_samples_leaf=1   # 리프 노드에 필요한 최소 샘플 수\n",
        "    , max_depth=26 \n",
        "    , criterion = 'entropy'\n",
        ")  \n",
        "\n",
        "# AdaBoost\n",
        "ada_model = AdaBoostClassifier(\n",
        "    n_estimators=1399\n",
        "    , learning_rate=0.9987147599335517\n",
        "    , algorithm='SAMME.R'\n",
        ")  \n",
        "\n",
        "# CatBoost\n",
        "#cat_model = CatBoostClassifier(\n",
        "#    iterations=1045\n",
        "#   , learning_rate=0.21147352826666405\n",
        "#    , depth=9\n",
        "#    , verbose=False\n",
        "#)\n",
        "\n",
        "\n",
        "### 스태킹 분류기 생성 ###\n",
        "model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rf_model),\n",
        "        ('lgb', lgb_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('gb', gb_model),\n",
        "        ('dt', dt_model),\n",
        "        ('et', et_model),\n",
        "        ('lgb_dart',lgb_dart_model)\n",
        "        #('cat', cat_model)\n",
        "    ],\n",
        "    final_estimator=lgb_model  # 최종 메타 모델\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cacd5ed8",
      "metadata": {
        "id": "cacd5ed8"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "9df5f040",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "9df5f040",
        "outputId": "a8b64c9c-5378-4f4b-d555-1213436c7e99"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
              "                                                       max_depth=30,\n",
              "                                                       min_samples_split=3,\n",
              "                                                       n_estimators=1056)),\n",
              "                               (&#x27;lgb&#x27;,\n",
              "                                LGBMClassifier(learning_rate=0.07324658507873466,\n",
              "                                               max_depth=10,\n",
              "                                               min_child_samples=31,\n",
              "                                               n_estimators=487, num_leaves=162,\n",
              "                                               verbose=-1)),\n",
              "                               (&#x27;xgb&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel...\n",
              "                                                     min_samples_split=3,\n",
              "                                                     n_estimators=486)),\n",
              "                               (&#x27;lgb_dart&#x27;,\n",
              "                                LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                               learning_rate=0.0916736042020453,\n",
              "                                               max_depth=13,\n",
              "                                               min_child_samples=10,\n",
              "                                               n_estimators=692, num_leaves=170,\n",
              "                                               verbose=-1))],\n",
              "                   final_estimator=LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                                  learning_rate=0.0916736042020453,\n",
              "                                                  max_depth=13,\n",
              "                                                  min_child_samples=10,\n",
              "                                                  n_estimators=692,\n",
              "                                                  num_leaves=170, verbose=-1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
              "                                                       max_depth=30,\n",
              "                                                       min_samples_split=3,\n",
              "                                                       n_estimators=1056)),\n",
              "                               (&#x27;lgb&#x27;,\n",
              "                                LGBMClassifier(learning_rate=0.07324658507873466,\n",
              "                                               max_depth=10,\n",
              "                                               min_child_samples=31,\n",
              "                                               n_estimators=487, num_leaves=162,\n",
              "                                               verbose=-1)),\n",
              "                               (&#x27;xgb&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel...\n",
              "                                                     min_samples_split=3,\n",
              "                                                     n_estimators=486)),\n",
              "                               (&#x27;lgb_dart&#x27;,\n",
              "                                LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                               learning_rate=0.0916736042020453,\n",
              "                                               max_depth=13,\n",
              "                                               min_child_samples=10,\n",
              "                                               n_estimators=692, num_leaves=170,\n",
              "                                               verbose=-1))],\n",
              "                   final_estimator=LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                                  learning_rate=0.0916736042020453,\n",
              "                                                  max_depth=13,\n",
              "                                                  min_child_samples=10,\n",
              "                                                  n_estimators=692,\n",
              "                                                  num_leaves=170, verbose=-1))</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=30, min_samples_split=3,\n",
              "                       n_estimators=1056)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.07324658507873466, max_depth=10,\n",
              "               min_child_samples=31, n_estimators=487, num_leaves=162,\n",
              "               verbose=-1)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;error&#x27;, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.08645845446703926,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1427, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.09883679411048218, max_depth=6,\n",
              "                           min_samples_leaf=13, n_estimators=1425)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=24)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>et</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier(criterion=&#x27;entropy&#x27;, max_depth=26, min_samples_split=3,\n",
              "                     n_estimators=486)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb_dart</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(boosting_type=&#x27;dart&#x27;, learning_rate=0.0916736042020453,\n",
              "               max_depth=13, min_child_samples=10, n_estimators=692,\n",
              "               num_leaves=170, verbose=-1)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(boosting_type=&#x27;dart&#x27;, learning_rate=0.0916736042020453,\n",
              "               max_depth=13, min_child_samples=10, n_estimators=692,\n",
              "               num_leaves=170, verbose=-1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "StackingClassifier(estimators=[('rf',\n",
              "                                RandomForestClassifier(criterion='entropy',\n",
              "                                                       max_depth=30,\n",
              "                                                       min_samples_split=3,\n",
              "                                                       n_estimators=1056)),\n",
              "                               ('lgb',\n",
              "                                LGBMClassifier(learning_rate=0.07324658507873466,\n",
              "                                               max_depth=10,\n",
              "                                               min_child_samples=31,\n",
              "                                               n_estimators=487, num_leaves=162,\n",
              "                                               verbose=-1)),\n",
              "                               ('xgb',\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel...\n",
              "                                                     min_samples_split=3,\n",
              "                                                     n_estimators=486)),\n",
              "                               ('lgb_dart',\n",
              "                                LGBMClassifier(boosting_type='dart',\n",
              "                                               learning_rate=0.0916736042020453,\n",
              "                                               max_depth=13,\n",
              "                                               min_child_samples=10,\n",
              "                                               n_estimators=692, num_leaves=170,\n",
              "                                               verbose=-1))],\n",
              "                   final_estimator=LGBMClassifier(boosting_type='dart',\n",
              "                                                  learning_rate=0.0916736042020453,\n",
              "                                                  max_depth=13,\n",
              "                                                  min_child_samples=10,\n",
              "                                                  n_estimators=692,\n",
              "                                                  num_leaves=170, verbose=-1))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bf2de5f",
      "metadata": {
        "id": "6bf2de5f"
      },
      "source": [
        "### 모델 성능 보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c8871444",
      "metadata": {
        "id": "c8871444"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "\n",
        "def get_clf_eval(y_test, y_pred=None):\n",
        "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
        "    weighted_F1 = f1_score(y_test, y_pred, average='weighted')  # 추가된 부분 \n",
        "\n",
        "    metrics = pd.DataFrame({\n",
        "        '정확도': [accuracy],\n",
        "        '정밀도': [precision],\n",
        "        '재현율': [recall],\n",
        "        'F1 Score': [F1],\n",
        "        'Weighted F1': [weighted_F1]  # 추가된 부분\n",
        "    })\n",
        "\n",
        "    confusion_df = pd.DataFrame(confusion, index=['True', 'False'], columns=['True', 'False'])\n",
        "\n",
        "    print(\"\\n오차행렬:\")\n",
        "    display(confusion_df)\n",
        "    print(\"평가 지표:\")\n",
        "    display(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "56a86373",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "56a86373",
        "outputId": "b0c0f95b-f5c0-4530-fdb2-a0ecc2b31b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "오차행렬:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True</th>\n",
              "      <th>False</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>762</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>99</td>\n",
              "      <td>10814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       True  False\n",
              "True    762    185\n",
              "False    99  10814"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "평가 지표:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>정확도</th>\n",
              "      <th>정밀도</th>\n",
              "      <th>재현율</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.976054</td>\n",
              "      <td>0.885017</td>\n",
              "      <td>0.804646</td>\n",
              "      <td>0.84292</td>\n",
              "      <td>0.975531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        정확도       정밀도       재현율  F1 Score  Weighted F1\n",
              "0  0.976054  0.885017  0.804646   0.84292     0.975531"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = model.predict(x_val)\n",
        "get_clf_eval(y_val, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7adf8300",
      "metadata": {
        "id": "7adf8300"
      },
      "source": [
        "## 4. 제출하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d0b6e17",
      "metadata": {
        "id": "9d0b6e17"
      },
      "source": [
        "### 테스트 데이터 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "43daa73c",
      "metadata": {
        "id": "43daa73c"
      },
      "outputs": [],
      "source": [
        "# 예측에 필요한 데이터 분리\n",
        "x_test = df_test_encoded.drop([\"is_converted\", \"id\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d13f7a6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d13f7a6e",
        "outputId": "dcef4162-f5dc-4624-a9d8-b997299b4591"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "718"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_pred = model.predict(x_test)\n",
        "sum(test_pred) # True로 예측된 개수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f18e6a",
      "metadata": {
        "id": "47f18e6a"
      },
      "source": [
        "### 제출 파일 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3128a458",
      "metadata": {
        "id": "3128a458"
      },
      "outputs": [],
      "source": [
        "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
        "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
        "df_sub[\"is_converted\"] = test_pred\n",
        "\n",
        "# 제출 파일 저장\n",
        "df_sub.to_csv(\"submission_model_12.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7867ce",
      "metadata": {
        "id": "ec7867ce"
      },
      "source": [
        "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "413b3cb9",
      "metadata": {},
      "source": [
        "."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
