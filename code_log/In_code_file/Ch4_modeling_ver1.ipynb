{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "acdab431",
      "metadata": {
        "id": "acdab431"
      },
      "source": [
        "## 1. 데이터 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b8341e8",
      "metadata": {
        "id": "2b8341e8"
      },
      "source": [
        "### 필수 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a315cc58",
      "metadata": {
        "id": "a315cc58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_18648\\4117284284.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # 경고 메세지 무시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "38ccd6b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_origin = pd.read_csv(\"data/train.csv\") # 학습용 데이터\n",
        "df_test_origin = pd.read_csv(\"data/submission.csv\") # 테스트 데이터(제출파일의 데이터)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0b323c11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59299 entries, 0 to 59298\n",
            "Data columns (total 29 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   bant_submit              59299 non-null  float64\n",
            " 1   customer_country         58317 non-null  object \n",
            " 2   business_unit            59299 non-null  object \n",
            " 3   com_reg_ver_win_rate     14568 non-null  float64\n",
            " 4   customer_idx             59299 non-null  int64  \n",
            " 5   customer_type            15338 non-null  object \n",
            " 6   enterprise               59299 non-null  object \n",
            " 7   historical_existing_cnt  13756 non-null  float64\n",
            " 8   id_strategic_ver         3444 non-null   float64\n",
            " 9   it_strategic_ver         1121 non-null   float64\n",
            " 10  idit_strategic_ver       4565 non-null   float64\n",
            " 11  customer_job             40566 non-null  object \n",
            " 12  lead_desc_length         59299 non-null  int64  \n",
            " 13  inquiry_type             58358 non-null  object \n",
            " 14  product_category         39925 non-null  object \n",
            " 15  product_subcategory      9235 non-null   object \n",
            " 16  product_modelname        9229 non-null   object \n",
            " 17  customer_country.1       58317 non-null  object \n",
            " 18  customer_position        59299 non-null  object \n",
            " 19  response_corporate       59299 non-null  object \n",
            " 20  expected_timeline        28436 non-null  object \n",
            " 21  ver_cus                  59299 non-null  int64  \n",
            " 22  ver_pro                  59299 non-null  int64  \n",
            " 23  ver_win_rate_x           18417 non-null  float64\n",
            " 24  ver_win_ratio_per_bu     15304 non-null  float64\n",
            " 25  business_area            18417 non-null  object \n",
            " 26  business_subarea         5526 non-null   object \n",
            " 27  lead_owner               59299 non-null  int64  \n",
            " 28  is_converted             59299 non-null  bool   \n",
            "dtypes: bool(1), float64(8), int64(5), object(15)\n",
            "memory usage: 12.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train_origin.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af526c13",
      "metadata": {
        "id": "af526c13"
      },
      "source": [
        "## 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc30f10",
      "metadata": {
        "id": "2cc30f10"
      },
      "source": [
        "### 각 변수별 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "596c0909",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_process = pd.read_csv('data/Ch2/df_train.csv')\n",
        "df_test_process = pd.read_csv('data/Ch2/df_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e0437e17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59299 entries, 0 to 59298\n",
            "Data columns (total 29 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   bant_submit              59299 non-null  float64\n",
            " 1   customer_country         59299 non-null  object \n",
            " 2   business_unit            59299 non-null  object \n",
            " 3   com_reg_ver_win_rate     14568 non-null  float64\n",
            " 4   customer_idx             59299 non-null  int64  \n",
            " 5   customer_type            59299 non-null  object \n",
            " 6   enterprise               59299 non-null  object \n",
            " 7   historical_existing_cnt  59299 non-null  float64\n",
            " 8   id_strategic_ver         59299 non-null  float64\n",
            " 9   it_strategic_ver         59299 non-null  float64\n",
            " 10  idit_strategic_ver       59299 non-null  float64\n",
            " 11  customer_job             59299 non-null  object \n",
            " 12  lead_desc_length         59299 non-null  int64  \n",
            " 13  inquiry_type             59299 non-null  object \n",
            " 14  product_category         59299 non-null  object \n",
            " 15  product_subcategory      59299 non-null  object \n",
            " 16  product_modelname        59299 non-null  object \n",
            " 17  customer_country.1       59299 non-null  object \n",
            " 18  customer_position        59299 non-null  object \n",
            " 19  response_corporate       59299 non-null  object \n",
            " 20  expected_timeline        59299 non-null  object \n",
            " 21  ver_cus                  59299 non-null  int64  \n",
            " 22  ver_pro                  59299 non-null  int64  \n",
            " 23  ver_win_rate_x           59299 non-null  float64\n",
            " 24  ver_win_ratio_per_bu     59299 non-null  float64\n",
            " 25  business_area            59299 non-null  object \n",
            " 26  business_subarea         59299 non-null  object \n",
            " 27  lead_owner               59299 non-null  int64  \n",
            " 28  is_converted             59299 non-null  bool   \n",
            "dtypes: bool(1), float64(8), int64(5), object(15)\n",
            "memory usage: 12.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train_process.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08efd9a3",
      "metadata": {},
      "source": [
        "## 3. 피처엔지니어링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd47e00",
      "metadata": {
        "id": "4bd47e00"
      },
      "source": [
        "### 레이블 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b53d4d09",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_encoded = pd.read_csv('data/Ch3/df_train_encoded.csv')\n",
        "df_test_encoded = pd.read_csv('data/Ch3/df_test_encoded.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ca62d87e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59299 entries, 0 to 59298\n",
            "Data columns (total 25 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   bant_submit               59299 non-null  float64\n",
            " 1   customer_country          59299 non-null  int64  \n",
            " 2   business_unit             59299 non-null  int64  \n",
            " 3   com_reg_ver_win_rate      59299 non-null  float64\n",
            " 4   customer_idx              59299 non-null  int64  \n",
            " 5   customer_type             59299 non-null  int64  \n",
            " 6   enterprise                59299 non-null  int64  \n",
            " 7   historical_existing_cnt   59299 non-null  float64\n",
            " 8   customer_job              59299 non-null  int64  \n",
            " 9   lead_desc_length          59299 non-null  int64  \n",
            " 10  inquiry_type              59299 non-null  int64  \n",
            " 11  customer_country.1        59299 non-null  int64  \n",
            " 12  customer_position         59299 non-null  int64  \n",
            " 13  response_corporate        59299 non-null  int64  \n",
            " 14  expected_timeline         59299 non-null  int64  \n",
            " 15  lead_owner                59299 non-null  int64  \n",
            " 16  is_converted              59299 non-null  bool   \n",
            " 17  id_business_area          59299 non-null  float64\n",
            " 18  it_business_area          59299 non-null  float64\n",
            " 19  idit_business_area        59299 non-null  float64\n",
            " 20  ver_cus_business_area     59299 non-null  int64  \n",
            " 21  ver_pro_product_category  59299 non-null  int64  \n",
            " 22  ver_win_business_area     59299 non-null  float64\n",
            " 23  ver_ratio_business_area   59299 non-null  float64\n",
            " 24  category_modelname        59299 non-null  int64  \n",
            "dtypes: bool(1), float64(8), int64(16)\n",
            "memory usage: 10.9 MB\n"
          ]
        }
      ],
      "source": [
        "df_train_encoded.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ecfa9b",
      "metadata": {
        "id": "79ecfa9b"
      },
      "source": [
        "## 4. 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549e5839",
      "metadata": {},
      "source": [
        "### 데이터 분할"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "260c49ec",
      "metadata": {},
      "source": [
        "학습, 검증 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7af1b057",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    df_train_encoded.drop(\"is_converted\", axis=1),\n",
        "    df_train_encoded[\"is_converted\"],\n",
        "    test_size=0.2,\n",
        "    shuffle=True,\n",
        "    random_state=400,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "295c9479",
      "metadata": {
        "id": "295c9479"
      },
      "source": [
        "### 모델 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b97e189",
      "metadata": {
        "id": "2b97e189"
      },
      "source": [
        "#### 단일모델 기준으로 사용할수 있는 모델들의 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b870e254",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# 보팅\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "# 스테킹\n",
        "from sklearn.ensemble import StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "27ccff4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3caf257b",
      "metadata": {
        "id": "3caf257b"
      },
      "source": [
        "### 최적 하이퍼 파라미터 찾기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bd19c1",
      "metadata": {
        "id": "c9bd19c1"
      },
      "source": [
        "#### optuna를 통한 최적의 파라미터 찾기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "926b9b02",
      "metadata": {},
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "71289338",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-18 23:04:32,512] A new study created in memory with name: no-name-a538f3a4-a02a-489f-a061-863c8de97693\n",
            "[W 2024-02-18 23:04:36,963] Trial 0 failed with parameters: {'n_estimators': 1139, 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 4, 'criterion': 'entropy'} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_18648\\892554665.py\", line 32, in <lambda>\n",
            "    study.optimize(lambda trial: objectiveRF(trial, x_train, y_train, x_val, y_val), n_trials=75)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\HamIG\\AppData\\Local\\Temp\\ipykernel_18648\\892554665.py\", line 23, in objectiveRF\n",
            "    model.fit(x_tr, y_tr)\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
            "    trees = Parallel(\n",
            "            ^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 67, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1863, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1792, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 129, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
            "    tree._fit(\n",
            "  File \"c:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
            "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
            "KeyboardInterrupt\n",
            "[W 2024-02-18 23:04:36,967] Trial 0 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 하이퍼 파라미터 튜닝\u001b[39;00m\n\u001b[0;32m     31\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 32\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjectiveRF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial: score \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mparams \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams))\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[32], line 32\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 하이퍼 파라미터 튜닝\u001b[39;00m\n\u001b[0;32m     31\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 32\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjectiveRF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial: score \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mparams \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams))\n",
            "Cell \u001b[1;32mIn[32], line 23\u001b[0m, in \u001b[0;36mobjectiveRF\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     12\u001b[0m criterion \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[0;32m     15\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[0;32m     16\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_val)\n\u001b[0;32m     25\u001b[0m score \u001b[38;5;241m=\u001b[39m f1_score(y_val, pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\HamIG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "def objectiveRF(trial, x_tr, y_tr, x_val, y_val):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 700, 1500)\n",
        "    max_depth = trial.suggest_int('max_depth', 15, 30)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 13)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 7)\n",
        "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        criterion=criterion,\n",
        "        random_state=0\n",
        "    )\n",
        "\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveRF(trial, x_train, y_train, x_val, y_val), n_trials=75)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2d2d36",
      "metadata": {},
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "038aa9b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:24:10,277] A new study created in memory with name: no-name-5e1786de-1c89-42be-88aa-05fa97c761ec\n",
            "[I 2024-02-17 17:24:12,914] Trial 0 finished with value: 0.9753345480842605 and parameters: {'num_leaves': 166, 'max_depth': 19, 'n_estimators': 643, 'learning_rate': 0.05903948646972072, 'min_child_samples': 24}. Best is trial 0 with value: 0.9753345480842605.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9753345480842605, \n",
            "params {'num_leaves': 166, 'max_depth': 19, 'n_estimators': 643, 'learning_rate': 0.05903948646972072, 'min_child_samples': 24}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveLGBM(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 25),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
        "        'verbose' : -1,\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = LGBMClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveLGBM(trial, x_train, y_train, x_val, y_val), n_trials=100)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21851117",
      "metadata": {},
      "source": [
        "LGBM_dart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ba04ac84",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-18 00:23:28,236] A new study created in memory with name: no-name-e0d4abad-5400-4f09-a743-60617f9af5a6\n",
            "[I 2024-02-18 00:23:48,860] Trial 0 finished with value: 0.9769482131364002 and parameters: {'num_leaves': 210, 'max_depth': 25, 'n_estimators': 722, 'learning_rate': 0.05903948646972072, 'min_child_samples': 13}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:24:20,312] Trial 1 finished with value: 0.9764793428531003 and parameters: {'num_leaves': 229, 'max_depth': 19, 'n_estimators': 925, 'learning_rate': 0.09672964844509264, 'min_child_samples': 13}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:24:41,715] Trial 2 finished with value: 0.9764922801857847 and parameters: {'num_leaves': 259, 'max_depth': 21, 'n_estimators': 698, 'learning_rate': 0.0933036974463395, 'min_child_samples': 6}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:25:05,586] Trial 3 finished with value: 0.9753893492652078 and parameters: {'num_leaves': 117, 'max_depth': 10, 'n_estimators': 883, 'learning_rate': 0.08003410758548654, 'min_child_samples': 23}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:25:24,489] Trial 4 finished with value: 0.9767735783874336 and parameters: {'num_leaves': 296, 'max_depth': 26, 'n_estimators': 623, 'learning_rate': 0.08024762586578099, 'min_child_samples': 7}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:25:55,794] Trial 5 finished with value: 0.9765180590319894 and parameters: {'num_leaves': 228, 'max_depth': 13, 'n_estimators': 962, 'learning_rate': 0.056966348957506456, 'min_child_samples': 13}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:26:09,831] Trial 6 finished with value: 0.9760634541025287 and parameters: {'num_leaves': 153, 'max_depth': 26, 'n_estimators': 619, 'learning_rate': 0.061159055398178376, 'min_child_samples': 5}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:26:32,962] Trial 7 finished with value: 0.9768418373577431 and parameters: {'num_leaves': 224, 'max_depth': 22, 'n_estimators': 732, 'learning_rate': 0.09493732706631618, 'min_child_samples': 19}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:26:52,993] Trial 8 finished with value: 0.9697152748115202 and parameters: {'num_leaves': 172, 'max_depth': 19, 'n_estimators': 789, 'learning_rate': 0.015420292446634285, 'min_child_samples': 19}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:27:00,124] Trial 9 finished with value: 0.9724173704947517 and parameters: {'num_leaves': 234, 'max_depth': 14, 'n_estimators': 390, 'learning_rate': 0.03838855158317655, 'min_child_samples': 12}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:27:09,591] Trial 10 finished with value: 0.9722724594488985 and parameters: {'num_leaves': 184, 'max_depth': 30, 'n_estimators': 480, 'learning_rate': 0.037083839624988964, 'min_child_samples': 17}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:27:31,142] Trial 11 finished with value: 0.9762756440599023 and parameters: {'num_leaves': 196, 'max_depth': 23, 'n_estimators': 742, 'learning_rate': 0.0688256020290253, 'min_child_samples': 21}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:27:44,739] Trial 12 finished with value: 0.9757257698936337 and parameters: {'num_leaves': 272, 'max_depth': 25, 'n_estimators': 534, 'learning_rate': 0.042582593678852886, 'min_child_samples': 16}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:28:05,982] Trial 13 finished with value: 0.9711180914043469 and parameters: {'num_leaves': 215, 'max_depth': 30, 'n_estimators': 818, 'learning_rate': 0.015486644011907018, 'min_child_samples': 9}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:28:22,930] Trial 14 finished with value: 0.9763067102875669 and parameters: {'num_leaves': 147, 'max_depth': 22, 'n_estimators': 669, 'learning_rate': 0.0788171434904935, 'min_child_samples': 24}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:28:28,195] Trial 15 finished with value: 0.9729871531890106 and parameters: {'num_leaves': 260, 'max_depth': 17, 'n_estimators': 310, 'learning_rate': 0.05020145657278979, 'min_child_samples': 19}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:28:53,883] Trial 16 finished with value: 0.9760881359764677 and parameters: {'num_leaves': 203, 'max_depth': 24, 'n_estimators': 834, 'learning_rate': 0.06912639789099183, 'min_child_samples': 10}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:29:09,025] Trial 17 finished with value: 0.9712695000390483 and parameters: {'num_leaves': 100, 'max_depth': 28, 'n_estimators': 739, 'learning_rate': 0.02762520818045737, 'min_child_samples': 15}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:29:23,349] Trial 18 finished with value: 0.9761427230138261 and parameters: {'num_leaves': 162, 'max_depth': 16, 'n_estimators': 578, 'learning_rate': 0.09874606719041197, 'min_child_samples': 19}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:29:33,580] Trial 19 finished with value: 0.9763305029072495 and parameters: {'num_leaves': 241, 'max_depth': 27, 'n_estimators': 445, 'learning_rate': 0.08781006431931354, 'min_child_samples': 21}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:30:06,567] Trial 20 finished with value: 0.9754570897303951 and parameters: {'num_leaves': 207, 'max_depth': 20, 'n_estimators': 995, 'learning_rate': 0.06818955964015488, 'min_child_samples': 15}. Best is trial 0 with value: 0.9769482131364002.\n",
            "[I 2024-02-18 00:30:25,717] Trial 21 finished with value: 0.9769658322304259 and parameters: {'num_leaves': 297, 'max_depth': 24, 'n_estimators': 613, 'learning_rate': 0.08131458511546963, 'min_child_samples': 8}. Best is trial 21 with value: 0.9769658322304259.\n",
            "[I 2024-02-18 00:30:51,510] Trial 22 finished with value: 0.976628439691656 and parameters: {'num_leaves': 297, 'max_depth': 23, 'n_estimators': 728, 'learning_rate': 0.0873290438991935, 'min_child_samples': 9}. Best is trial 21 with value: 0.9769658322304259.\n",
            "[I 2024-02-18 00:31:06,369] Trial 23 finished with value: 0.9768116270453153 and parameters: {'num_leaves': 275, 'max_depth': 24, 'n_estimators': 526, 'learning_rate': 0.08758830904185055, 'min_child_samples': 11}. Best is trial 21 with value: 0.9769658322304259.\n",
            "[I 2024-02-18 00:31:26,074] Trial 24 finished with value: 0.9761295933044475 and parameters: {'num_leaves': 250, 'max_depth': 28, 'n_estimators': 668, 'learning_rate': 0.07245100855975711, 'min_child_samples': 7}. Best is trial 21 with value: 0.9769658322304259.\n",
            "[I 2024-02-18 00:31:52,166] Trial 25 finished with value: 0.9770793929545335 and parameters: {'num_leaves': 281, 'max_depth': 21, 'n_estimators': 781, 'learning_rate': 0.049477284466645954, 'min_child_samples': 17}. Best is trial 25 with value: 0.9770793929545335.\n",
            "[I 2024-02-18 00:32:18,994] Trial 26 finished with value: 0.9765012660413471 and parameters: {'num_leaves': 280, 'max_depth': 20, 'n_estimators': 790, 'learning_rate': 0.04803966099958608, 'min_child_samples': 14}. Best is trial 25 with value: 0.9770793929545335.\n",
            "[I 2024-02-18 00:32:49,934] Trial 27 finished with value: 0.9771603243829798 and parameters: {'num_leaves': 286, 'max_depth': 17, 'n_estimators': 876, 'learning_rate': 0.05739488799587504, 'min_child_samples': 17}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:33:18,641] Trial 28 finished with value: 0.9754034250915162 and parameters: {'num_leaves': 287, 'max_depth': 17, 'n_estimators': 855, 'learning_rate': 0.03309735029232504, 'min_child_samples': 17}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:33:50,150] Trial 29 finished with value: 0.9759679444278467 and parameters: {'num_leaves': 264, 'max_depth': 15, 'n_estimators': 907, 'learning_rate': 0.06184492947885433, 'min_child_samples': 17}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:34:16,107] Trial 30 finished with value: 0.976153136649367 and parameters: {'num_leaves': 291, 'max_depth': 18, 'n_estimators': 779, 'learning_rate': 0.049985196783060966, 'min_child_samples': 14}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:34:50,691] Trial 31 finished with value: 0.9763434721102942 and parameters: {'num_leaves': 300, 'max_depth': 21, 'n_estimators': 930, 'learning_rate': 0.05859419177414904, 'min_child_samples': 13}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:35:08,259] Trial 32 finished with value: 0.9764243088895003 and parameters: {'num_leaves': 249, 'max_depth': 19, 'n_estimators': 599, 'learning_rate': 0.05350268952385794, 'min_child_samples': 21}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:35:40,339] Trial 33 finished with value: 0.9755509619721008 and parameters: {'num_leaves': 280, 'max_depth': 11, 'n_estimators': 864, 'learning_rate': 0.045758339616138406, 'min_child_samples': 16}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:36:00,492] Trial 34 finished with value: 0.974054033316997 and parameters: {'num_leaves': 267, 'max_depth': 21, 'n_estimators': 687, 'learning_rate': 0.026726433363174977, 'min_child_samples': 8}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:36:31,235] Trial 35 finished with value: 0.9756584435410302 and parameters: {'num_leaves': 286, 'max_depth': 25, 'n_estimators': 896, 'learning_rate': 0.06449621605880895, 'min_child_samples': 5}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:36:48,744] Trial 36 finished with value: 0.976411371563894 and parameters: {'num_leaves': 250, 'max_depth': 23, 'n_estimators': 623, 'learning_rate': 0.05442432430281705, 'min_child_samples': 12}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:37:06,122] Trial 37 finished with value: 0.9759004046426004 and parameters: {'num_leaves': 141, 'max_depth': 26, 'n_estimators': 701, 'learning_rate': 0.07835210899691712, 'min_child_samples': 11}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:37:34,817] Trial 38 finished with value: 0.9759014858147946 and parameters: {'num_leaves': 271, 'max_depth': 12, 'n_estimators': 809, 'learning_rate': 0.0747204540539629, 'min_child_samples': 18}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:38:01,251] Trial 39 finished with value: 0.9765180590319894 and parameters: {'num_leaves': 300, 'max_depth': 18, 'n_estimators': 760, 'learning_rate': 0.04237059394156135, 'min_child_samples': 22}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:38:31,642] Trial 40 finished with value: 0.9768290924017532 and parameters: {'num_leaves': 222, 'max_depth': 22, 'n_estimators': 944, 'learning_rate': 0.06274080447107674, 'min_child_samples': 7}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:38:51,845] Trial 41 finished with value: 0.9762496741405337 and parameters: {'num_leaves': 194, 'max_depth': 22, 'n_estimators': 706, 'learning_rate': 0.09498585468279629, 'min_child_samples': 18}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:39:05,908] Trial 42 finished with value: 0.976304468078774 and parameters: {'num_leaves': 180, 'max_depth': 25, 'n_estimators': 570, 'learning_rate': 0.08277934036686233, 'min_child_samples': 20}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:39:24,551] Trial 43 finished with value: 0.9759281682217429 and parameters: {'num_leaves': 234, 'max_depth': 21, 'n_estimators': 636, 'learning_rate': 0.09296273430093131, 'min_child_samples': 16}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:39:50,571] Trial 44 finished with value: 0.9764793428531003 and parameters: {'num_leaves': 210, 'max_depth': 24, 'n_estimators': 844, 'learning_rate': 0.0551972010972666, 'min_child_samples': 18}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:40:16,336] Trial 45 finished with value: 0.9762366409828858 and parameters: {'num_leaves': 223, 'max_depth': 19, 'n_estimators': 765, 'learning_rate': 0.09981938127510565, 'min_child_samples': 25}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:40:34,554] Trial 46 finished with value: 0.9759135968230114 and parameters: {'num_leaves': 190, 'max_depth': 27, 'n_estimators': 655, 'learning_rate': 0.09158092239219588, 'min_child_samples': 20}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:40:57,430] Trial 47 finished with value: 0.9762885810388187 and parameters: {'num_leaves': 258, 'max_depth': 15, 'n_estimators': 719, 'learning_rate': 0.08235698177449419, 'min_child_samples': 14}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:41:21,411] Trial 48 finished with value: 0.9757257698936337 and parameters: {'num_leaves': 238, 'max_depth': 22, 'n_estimators': 745, 'learning_rate': 0.07473052974147987, 'min_child_samples': 23}. Best is trial 27 with value: 0.9771603243829798.\n",
            "[I 2024-02-18 00:41:49,174] Trial 49 finished with value: 0.9779867773236043 and parameters: {'num_leaves': 287, 'max_depth': 20, 'n_estimators': 796, 'learning_rate': 0.058795652335588866, 'min_child_samples': 20}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:42:29,382] Trial 50 finished with value: 0.9764243088895003 and parameters: {'num_leaves': 283, 'max_depth': 20, 'n_estimators': 876, 'learning_rate': 0.06556099932939079, 'min_child_samples': 20}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:43:09,049] Trial 51 finished with value: 0.9764793428531003 and parameters: {'num_leaves': 291, 'max_depth': 23, 'n_estimators': 817, 'learning_rate': 0.05880073076623859, 'min_child_samples': 19}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:43:46,188] Trial 52 finished with value: 0.9760205222335842 and parameters: {'num_leaves': 274, 'max_depth': 18, 'n_estimators': 806, 'learning_rate': 0.039761507655665856, 'min_child_samples': 17}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:44:21,016] Trial 53 finished with value: 0.9766499937307901 and parameters: {'num_leaves': 256, 'max_depth': 24, 'n_estimators': 688, 'learning_rate': 0.05816931949363523, 'min_child_samples': 18}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:45:01,453] Trial 54 finished with value: 0.9769050917602714 and parameters: {'num_leaves': 292, 'max_depth': 20, 'n_estimators': 784, 'learning_rate': 0.05198063449486384, 'min_child_samples': 22}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:45:46,550] Trial 55 finished with value: 0.976598943638467 and parameters: {'num_leaves': 291, 'max_depth': 17, 'n_estimators': 829, 'learning_rate': 0.05178884863116921, 'min_child_samples': 22}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:46:16,877] Trial 56 finished with value: 0.974082788987917 and parameters: {'num_leaves': 124, 'max_depth': 19, 'n_estimators': 784, 'learning_rate': 0.04638153564741502, 'min_child_samples': 23}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:47:12,734] Trial 57 finished with value: 0.9760881359764677 and parameters: {'num_leaves': 275, 'max_depth': 14, 'n_estimators': 987, 'learning_rate': 0.03247413783833186, 'min_child_samples': 22}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:47:50,220] Trial 58 finished with value: 0.9767434428855939 and parameters: {'num_leaves': 293, 'max_depth': 21, 'n_estimators': 753, 'learning_rate': 0.06694193449919085, 'min_child_samples': 24}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:48:41,676] Trial 59 finished with value: 0.9765564893717472 and parameters: {'num_leaves': 282, 'max_depth': 16, 'n_estimators': 889, 'learning_rate': 0.04424618845477684, 'min_child_samples': 15}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:49:03,758] Trial 60 finished with value: 0.9754570897303951 and parameters: {'num_leaves': 264, 'max_depth': 20, 'n_estimators': 525, 'learning_rate': 0.04909062790122991, 'min_child_samples': 12}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:49:39,421] Trial 61 finished with value: 0.9758739222468693 and parameters: {'num_leaves': 218, 'max_depth': 25, 'n_estimators': 720, 'learning_rate': 0.061077285464977885, 'min_child_samples': 20}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:50:11,771] Trial 62 finished with value: 0.9756183872558881 and parameters: {'num_leaves': 171, 'max_depth': 23, 'n_estimators': 784, 'learning_rate': 0.07100779802721516, 'min_child_samples': 19}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:50:39,682] Trial 63 finished with value: 0.9761558202718786 and parameters: {'num_leaves': 200, 'max_depth': 22, 'n_estimators': 667, 'learning_rate': 0.055540365979402234, 'min_child_samples': 21}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:51:24,690] Trial 64 finished with value: 0.9766926459536849 and parameters: {'num_leaves': 295, 'max_depth': 26, 'n_estimators': 855, 'learning_rate': 0.05146481744443322, 'min_child_samples': 17}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:51:47,862] Trial 65 finished with value: 0.971167316580699 and parameters: {'num_leaves': 244, 'max_depth': 20, 'n_estimators': 598, 'learning_rate': 0.018779024965527503, 'min_child_samples': 6}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:52:26,739] Trial 66 finished with value: 0.9770850925144768 and parameters: {'num_leaves': 279, 'max_depth': 21, 'n_estimators': 731, 'learning_rate': 0.08890706376561927, 'min_child_samples': 16}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:53:10,233] Trial 67 finished with value: 0.9759547185301212 and parameters: {'num_leaves': 286, 'max_depth': 19, 'n_estimators': 804, 'learning_rate': 0.08916772840922538, 'min_child_samples': 16}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:54:01,692] Trial 68 finished with value: 0.9758606318091436 and parameters: {'num_leaves': 277, 'max_depth': 29, 'n_estimators': 910, 'learning_rate': 0.08270553320923484, 'min_child_samples': 13}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:54:36,026] Trial 69 finished with value: 0.9763434721102942 and parameters: {'num_leaves': 269, 'max_depth': 27, 'n_estimators': 739, 'learning_rate': 0.035142096672438575, 'min_child_samples': 16}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:55:17,388] Trial 70 finished with value: 0.9759942982669039 and parameters: {'num_leaves': 287, 'max_depth': 18, 'n_estimators': 773, 'learning_rate': 0.08554852656790361, 'min_child_samples': 10}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:55:54,538] Trial 71 finished with value: 0.9766926459536849 and parameters: {'num_leaves': 300, 'max_depth': 22, 'n_estimators': 688, 'learning_rate': 0.09762169035927748, 'min_child_samples': 15}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:56:32,746] Trial 72 finished with value: 0.9762914022344682 and parameters: {'num_leaves': 281, 'max_depth': 23, 'n_estimators': 725, 'learning_rate': 0.09504468740787597, 'min_child_samples': 17}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:57:02,928] Trial 73 finished with value: 0.9767735783874336 and parameters: {'num_leaves': 262, 'max_depth': 21, 'n_estimators': 643, 'learning_rate': 0.08988256882210559, 'min_child_samples': 19}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:57:13,190] Trial 74 finished with value: 0.9744567739947324 and parameters: {'num_leaves': 209, 'max_depth': 24, 'n_estimators': 355, 'learning_rate': 0.06029152130738243, 'min_child_samples': 21}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:57:52,561] Trial 75 finished with value: 0.976611753436837 and parameters: {'num_leaves': 228, 'max_depth': 21, 'n_estimators': 830, 'learning_rate': 0.04128828311716172, 'min_child_samples': 18}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:58:28,828] Trial 76 finished with value: 0.9760466172042634 and parameters: {'num_leaves': 294, 'max_depth': 20, 'n_estimators': 706, 'learning_rate': 0.07724027391121845, 'min_child_samples': 14}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:59:08,150] Trial 77 finished with value: 0.9760881359764677 and parameters: {'num_leaves': 271, 'max_depth': 22, 'n_estimators': 761, 'learning_rate': 0.06365451425833257, 'min_child_samples': 18}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 00:59:33,831] Trial 78 finished with value: 0.97548395209688 and parameters: {'num_leaves': 287, 'max_depth': 23, 'n_estimators': 561, 'learning_rate': 0.0854368079447786, 'min_child_samples': 8}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 01:00:19,744] Trial 79 finished with value: 0.976598943638467 and parameters: {'num_leaves': 257, 'max_depth': 26, 'n_estimators': 869, 'learning_rate': 0.05386705802806904, 'min_child_samples': 20}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 01:00:58,695] Trial 80 finished with value: 0.9759811376365077 and parameters: {'num_leaves': 277, 'max_depth': 24, 'n_estimators': 743, 'learning_rate': 0.05694842507438862, 'min_child_samples': 19}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 01:01:38,086] Trial 81 finished with value: 0.9769050917602714 and parameters: {'num_leaves': 220, 'max_depth': 22, 'n_estimators': 843, 'learning_rate': 0.06274668688834302, 'min_child_samples': 7}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 01:02:12,721] Trial 82 finished with value: 0.9770597659284941 and parameters: {'num_leaves': 214, 'max_depth': 21, 'n_estimators': 794, 'learning_rate': 0.04802364157675562, 'min_child_samples': 6}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 01:02:47,790] Trial 83 finished with value: 0.9763434721102942 and parameters: {'num_leaves': 215, 'max_depth': 21, 'n_estimators': 796, 'learning_rate': 0.04731896125553969, 'min_child_samples': 5}. Best is trial 49 with value: 0.9779867773236043.\n",
            "[I 2024-02-18 01:03:24,841] Trial 84 finished with value: 0.9765732288484092 and parameters: {'num_leaves': 187, 'max_depth': 20, 'n_estimators': 841, 'learning_rate': 0.051285753525745915, 'min_child_samples': 6}. Best is trial 49 with value: 0.9779867773236043.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9779867773236043, \n",
            "params {'num_leaves': 287, 'max_depth': 20, 'n_estimators': 796, 'learning_rate': 0.058795652335588866, 'min_child_samples': 20}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveLGBM(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 100, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 10, 30),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 25),\n",
        "        'verbose' : -1,\n",
        "        'boosting' : 'dart',\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = LGBMClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveLGBM(trial, x_train, y_train, x_val, y_val), n_trials=85)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f42df31",
      "metadata": {},
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9067b7c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-18 14:32:22,509] A new study created in memory with name: no-name-f7852b8a-2657-4e7b-bf53-59af7201328d\n",
            "[I 2024-02-18 14:32:25,381] Trial 0 finished with value: 0.9746427424628967 and parameters: {'n_estimators': 1549, 'learning_rate': 0.08006325564606936, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 0 with value: 0.9746427424628967.\n",
            "[I 2024-02-18 14:32:29,192] Trial 1 finished with value: 0.9745494388785899 and parameters: {'n_estimators': 1438, 'learning_rate': 0.09242411005474559, 'max_depth': 10, 'eval_metric': 'logloss'}. Best is trial 0 with value: 0.9746427424628967.\n",
            "[I 2024-02-18 14:32:30,670] Trial 2 finished with value: 0.9630074638478862 and parameters: {'n_estimators': 1568, 'learning_rate': 0.09479176468048628, 'max_depth': 2, 'eval_metric': 'error'}. Best is trial 0 with value: 0.9746427424628967.\n",
            "[I 2024-02-18 14:32:35,259] Trial 3 finished with value: 0.97342192531241 and parameters: {'n_estimators': 1778, 'learning_rate': 0.09090085037727735, 'max_depth': 10, 'eval_metric': 'auc'}. Best is trial 0 with value: 0.9746427424628967.\n",
            "[I 2024-02-18 14:32:36,490] Trial 4 finished with value: 0.9656988368671164 and parameters: {'n_estimators': 1118, 'learning_rate': 0.07479447149292667, 'max_depth': 3, 'eval_metric': 'auc'}. Best is trial 0 with value: 0.9746427424628967.\n",
            "[I 2024-02-18 14:32:38,566] Trial 5 finished with value: 0.975295652125853 and parameters: {'n_estimators': 1264, 'learning_rate': 0.08419635826039518, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:42,629] Trial 6 finished with value: 0.9738189314567817 and parameters: {'n_estimators': 1612, 'learning_rate': 0.07318537978123299, 'max_depth': 10, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:46,310] Trial 7 finished with value: 0.9734540428993155 and parameters: {'n_estimators': 1698, 'learning_rate': 0.03421578301404889, 'max_depth': 8, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:48,804] Trial 8 finished with value: 0.974547671688568 and parameters: {'n_estimators': 1315, 'learning_rate': 0.055459753965983585, 'max_depth': 7, 'eval_metric': 'logloss'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:51,112] Trial 9 finished with value: 0.9730345720370007 and parameters: {'n_estimators': 1209, 'learning_rate': 0.04129166625194974, 'max_depth': 7, 'eval_metric': 'logloss'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:53,398] Trial 10 finished with value: 0.9706302487668358 and parameters: {'n_estimators': 1941, 'learning_rate': 0.05958908222940181, 'max_depth': 4, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:54,900] Trial 11 finished with value: 0.9718656631162804 and parameters: {'n_estimators': 1027, 'learning_rate': 0.07963317380697016, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:57,155] Trial 12 finished with value: 0.9749090330440523 and parameters: {'n_estimators': 1388, 'learning_rate': 0.08201484591986404, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:32:59,027] Trial 13 finished with value: 0.9728469351892263 and parameters: {'n_estimators': 1349, 'learning_rate': 0.08517997621928834, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:00,799] Trial 14 finished with value: 0.9727013830647723 and parameters: {'n_estimators': 1251, 'learning_rate': 0.06605077263235952, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:03,679] Trial 15 finished with value: 0.9745236237565857 and parameters: {'n_estimators': 1412, 'learning_rate': 0.09767445624351982, 'max_depth': 8, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:05,507] Trial 16 finished with value: 0.9733601545141187 and parameters: {'n_estimators': 1142, 'learning_rate': 0.06965879267215175, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:07,943] Trial 17 finished with value: 0.9746300196163914 and parameters: {'n_estimators': 1466, 'learning_rate': 0.08562473092366969, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:09,150] Trial 18 finished with value: 0.9676506380587196 and parameters: {'n_estimators': 1021, 'learning_rate': 0.05446131115379953, 'max_depth': 4, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:11,861] Trial 19 finished with value: 0.9741097228188922 and parameters: {'n_estimators': 1318, 'learning_rate': 0.08459911468564828, 'max_depth': 8, 'eval_metric': 'logloss'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:16,540] Trial 20 finished with value: 0.9742829019304714 and parameters: {'n_estimators': 1999, 'learning_rate': 0.048802214698644986, 'max_depth': 9, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:19,531] Trial 21 finished with value: 0.9748024392652094 and parameters: {'n_estimators': 1538, 'learning_rate': 0.08045498571114225, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:22,193] Trial 22 finished with value: 0.9749090330440523 and parameters: {'n_estimators': 1658, 'learning_rate': 0.07749499570646562, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:25,000] Trial 23 finished with value: 0.9745101807912562 and parameters: {'n_estimators': 1772, 'learning_rate': 0.07512945350093568, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:26,985] Trial 24 finished with value: 0.9701882156468941 and parameters: {'n_estimators': 1663, 'learning_rate': 0.0650996756576915, 'max_depth': 4, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:29,579] Trial 25 finished with value: 0.9747760564570367 and parameters: {'n_estimators': 1850, 'learning_rate': 0.08895374561443674, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:31,781] Trial 26 finished with value: 0.9745886154293616 and parameters: {'n_estimators': 1403, 'learning_rate': 0.07064106993130402, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:33,738] Trial 27 finished with value: 0.9739122227740585 and parameters: {'n_estimators': 1261, 'learning_rate': 0.09941853300126574, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:34,896] Trial 28 finished with value: 0.9663319213648204 and parameters: {'n_estimators': 1185, 'learning_rate': 0.07570889663735014, 'max_depth': 3, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:37,632] Trial 29 finished with value: 0.9741122649146852 and parameters: {'n_estimators': 1539, 'learning_rate': 0.07966901660626255, 'max_depth': 7, 'eval_metric': 'logloss'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:41,049] Trial 30 finished with value: 0.9741508977581422 and parameters: {'n_estimators': 1497, 'learning_rate': 0.08189268077605227, 'max_depth': 9, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:44,160] Trial 31 finished with value: 0.9745504120794829 and parameters: {'n_estimators': 1659, 'learning_rate': 0.07815524581149805, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:47,373] Trial 32 finished with value: 0.9745236237565857 and parameters: {'n_estimators': 1558, 'learning_rate': 0.08819627390577164, 'max_depth': 8, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:49,865] Trial 33 finished with value: 0.974216868438371 and parameters: {'n_estimators': 1366, 'learning_rate': 0.09459174343206823, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:52,172] Trial 34 finished with value: 0.9745629507412116 and parameters: {'n_estimators': 1453, 'learning_rate': 0.08283507643814711, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:54,320] Trial 35 finished with value: 0.9740959308550265 and parameters: {'n_estimators': 1608, 'learning_rate': 0.09095777608754409, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:33:57,460] Trial 36 finished with value: 0.9749355920254713 and parameters: {'n_estimators': 1748, 'learning_rate': 0.07017129832559303, 'max_depth': 7, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:01,519] Trial 37 finished with value: 0.9739779940642168 and parameters: {'n_estimators': 1747, 'learning_rate': 0.07014484812664581, 'max_depth': 9, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:04,421] Trial 38 finished with value: 0.9734452250530191 and parameters: {'n_estimators': 1833, 'learning_rate': 0.06136036806639587, 'max_depth': 6, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:07,918] Trial 39 finished with value: 0.9744967051459932 and parameters: {'n_estimators': 1860, 'learning_rate': 0.07232692522871255, 'max_depth': 7, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:09,399] Trial 40 finished with value: 0.9618590333689876 and parameters: {'n_estimators': 1681, 'learning_rate': 0.07684962202465681, 'max_depth': 2, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:12,414] Trial 41 finished with value: 0.9744288329021991 and parameters: {'n_estimators': 1597, 'learning_rate': 0.06798784854583471, 'max_depth': 7, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:15,241] Trial 42 finished with value: 0.9738050903702913 and parameters: {'n_estimators': 1517, 'learning_rate': 0.08012336481830873, 'max_depth': 7, 'eval_metric': 'logloss'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:18,467] Trial 43 finished with value: 0.9744170180673777 and parameters: {'n_estimators': 1634, 'learning_rate': 0.08780715150655956, 'max_depth': 8, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:21,330] Trial 44 finished with value: 0.9743899095897913 and parameters: {'n_estimators': 1722, 'learning_rate': 0.07326203543518207, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:23,078] Trial 45 finished with value: 0.9730997146386571 and parameters: {'n_estimators': 1266, 'learning_rate': 0.061702925298556546, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:25,928] Trial 46 finished with value: 0.9738707861355302 and parameters: {'n_estimators': 1382, 'learning_rate': 0.09354343508157513, 'max_depth': 8, 'eval_metric': 'logloss'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:29,263] Trial 47 finished with value: 0.9740713020953152 and parameters: {'n_estimators': 1799, 'learning_rate': 0.08435107263206527, 'max_depth': 7, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:31,394] Trial 48 finished with value: 0.9735478761295403 and parameters: {'n_estimators': 1483, 'learning_rate': 0.08076015054781892, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:33,519] Trial 49 finished with value: 0.9745750008880678 and parameters: {'n_estimators': 1293, 'learning_rate': 0.07713462240331509, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:36,534] Trial 50 finished with value: 0.9737946005919264 and parameters: {'n_estimators': 1896, 'learning_rate': 0.08724629112745226, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:38,947] Trial 51 finished with value: 0.9736042199699096 and parameters: {'n_estimators': 1710, 'learning_rate': 0.08997714831441131, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:41,200] Trial 52 finished with value: 0.9725218306101595 and parameters: {'n_estimators': 1913, 'learning_rate': 0.08331482939594625, 'max_depth': 4, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:42,726] Trial 53 finished with value: 0.9738191269815342 and parameters: {'n_estimators': 1082, 'learning_rate': 0.08963021056922603, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:45,276] Trial 54 finished with value: 0.9736600177822329 and parameters: {'n_estimators': 1811, 'learning_rate': 0.09277251670500695, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:48,757] Trial 55 finished with value: 0.9746829931248747 and parameters: {'n_estimators': 1970, 'learning_rate': 0.07267543624745737, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:51,125] Trial 56 finished with value: 0.9750680308168495 and parameters: {'n_estimators': 1430, 'learning_rate': 0.09655665530652133, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:53,340] Trial 57 finished with value: 0.9714068183115168 and parameters: {'n_estimators': 1427, 'learning_rate': 0.03188856952267562, 'max_depth': 6, 'eval_metric': 'logloss'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:55,486] Trial 58 finished with value: 0.974589876053409 and parameters: {'n_estimators': 1347, 'learning_rate': 0.09651165242781992, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:57,914] Trial 59 finished with value: 0.9743373684576375 and parameters: {'n_estimators': 1325, 'learning_rate': 0.09681864341471223, 'max_depth': 7, 'eval_metric': 'auc'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:34:59,819] Trial 60 finished with value: 0.9735933690692915 and parameters: {'n_estimators': 1217, 'learning_rate': 0.05579054950072805, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:35:01,811] Trial 61 finished with value: 0.973107036924143 and parameters: {'n_estimators': 1756, 'learning_rate': 0.09982817737477119, 'max_depth': 4, 'eval_metric': 'error'}. Best is trial 5 with value: 0.975295652125853.\n",
            "[I 2024-02-18 14:35:04,292] Trial 62 finished with value: 0.9753757559948993 and parameters: {'n_estimators': 1566, 'learning_rate': 0.078404956565358, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:07,192] Trial 63 finished with value: 0.9739365437073128 and parameters: {'n_estimators': 1576, 'learning_rate': 0.0675462552135465, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:09,598] Trial 64 finished with value: 0.9750688380851493 and parameters: {'n_estimators': 1516, 'learning_rate': 0.07821718492502827, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:11,926] Trial 65 finished with value: 0.9744034803057674 and parameters: {'n_estimators': 1439, 'learning_rate': 0.074573917809685, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:14,440] Trial 66 finished with value: 0.9746829931248747 and parameters: {'n_estimators': 1638, 'learning_rate': 0.07850162499445848, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:17,016] Trial 67 finished with value: 0.975227555257905 and parameters: {'n_estimators': 1524, 'learning_rate': 0.08616051555672337, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:19,075] Trial 68 finished with value: 0.9739917437904003 and parameters: {'n_estimators': 1515, 'learning_rate': 0.08577453725096247, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:21,429] Trial 69 finished with value: 0.9747893465806128 and parameters: {'n_estimators': 1450, 'learning_rate': 0.08236024577514518, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:23,310] Trial 70 finished with value: 0.9712013357998307 and parameters: {'n_estimators': 1397, 'learning_rate': 0.041294537977079104, 'max_depth': 5, 'eval_metric': 'logloss'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:25,841] Trial 71 finished with value: 0.973576116758472 and parameters: {'n_estimators': 1585, 'learning_rate': 0.07544068436908351, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 62 with value: 0.9753757559948993.\n",
            "[I 2024-02-18 14:35:28,186] Trial 72 finished with value: 0.9754151042228556 and parameters: {'n_estimators': 1496, 'learning_rate': 0.08513894614872088, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:30,455] Trial 73 finished with value: 0.9745629507412116 and parameters: {'n_estimators': 1480, 'learning_rate': 0.08584988086493311, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:33,191] Trial 74 finished with value: 0.9739365437073128 and parameters: {'n_estimators': 1509, 'learning_rate': 0.08163971223899341, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:35,727] Trial 75 finished with value: 0.9742965682985676 and parameters: {'n_estimators': 1534, 'learning_rate': 0.0864006778847751, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:38,395] Trial 76 finished with value: 0.9740682457794511 and parameters: {'n_estimators': 1419, 'learning_rate': 0.09136929068938386, 'max_depth': 7, 'eval_metric': 'auc'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:40,591] Trial 77 finished with value: 0.9728974690378369 and parameters: {'n_estimators': 1558, 'learning_rate': 0.07883571269221352, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:42,973] Trial 78 finished with value: 0.9738984441092841 and parameters: {'n_estimators': 1470, 'learning_rate': 0.08418762518296105, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:45,459] Trial 79 finished with value: 0.9745629507412116 and parameters: {'n_estimators': 1353, 'learning_rate': 0.09508653273599932, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:47,973] Trial 80 finished with value: 0.9744560810420507 and parameters: {'n_estimators': 1150, 'learning_rate': 0.07154656883255597, 'max_depth': 8, 'eval_metric': 'auc'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:50,715] Trial 81 finished with value: 0.9741372061591294 and parameters: {'n_estimators': 1638, 'learning_rate': 0.07658025403662846, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:53,299] Trial 82 finished with value: 0.9748158295450614 and parameters: {'n_estimators': 1613, 'learning_rate': 0.06865873338243479, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:56,000] Trial 83 finished with value: 0.9739779940642168 and parameters: {'n_estimators': 1692, 'learning_rate': 0.08095222768845951, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:35:58,464] Trial 84 finished with value: 0.9748558054584934 and parameters: {'n_estimators': 1539, 'learning_rate': 0.07433136154897886, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:00,468] Trial 85 finished with value: 0.9732580458055807 and parameters: {'n_estimators': 1495, 'learning_rate': 0.07797319972598314, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:03,506] Trial 86 finished with value: 0.974484216365823 and parameters: {'n_estimators': 1728, 'learning_rate': 0.08364018301774363, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:06,229] Trial 87 finished with value: 0.9747362067525377 and parameters: {'n_estimators': 1667, 'learning_rate': 0.07936687638994044, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:08,026] Trial 88 finished with value: 0.9738947892294808 and parameters: {'n_estimators': 1292, 'learning_rate': 0.08890188513439215, 'max_depth': 5, 'eval_metric': 'auc'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:10,588] Trial 89 finished with value: 0.9736837735343242 and parameters: {'n_estimators': 1385, 'learning_rate': 0.06342682137083597, 'max_depth': 7, 'eval_metric': 'logloss'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:13,085] Trial 90 finished with value: 0.9751215899302281 and parameters: {'n_estimators': 1573, 'learning_rate': 0.07074031442036842, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:15,623] Trial 91 finished with value: 0.9741508977581422 and parameters: {'n_estimators': 1577, 'learning_rate': 0.06661541738811343, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:18,043] Trial 92 finished with value: 0.9738189314567817 and parameters: {'n_estimators': 1525, 'learning_rate': 0.0730585756586189, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:20,457] Trial 93 finished with value: 0.9742692022205449 and parameters: {'n_estimators': 1552, 'learning_rate': 0.07051759540698703, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:22,411] Trial 94 finished with value: 0.9739226594895084 and parameters: {'n_estimators': 1225, 'learning_rate': 0.08216646731974148, 'max_depth': 6, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:24,397] Trial 95 finished with value: 0.9732948339662991 and parameters: {'n_estimators': 1452, 'learning_rate': 0.0874409854958364, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:27,241] Trial 96 finished with value: 0.9744151588793917 and parameters: {'n_estimators': 1608, 'learning_rate': 0.0802806563686992, 'max_depth': 7, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:29,312] Trial 97 finished with value: 0.9737633645957334 and parameters: {'n_estimators': 1470, 'learning_rate': 0.07729897204584754, 'max_depth': 5, 'eval_metric': 'error'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:31,896] Trial 98 finished with value: 0.975227555257905 and parameters: {'n_estimators': 1623, 'learning_rate': 0.07432370109038743, 'max_depth': 6, 'eval_metric': 'auc'}. Best is trial 72 with value: 0.9754151042228556.\n",
            "[I 2024-02-18 14:36:34,654] Trial 99 finished with value: 0.9736697680136551 and parameters: {'n_estimators': 1502, 'learning_rate': 0.0690453561729225, 'max_depth': 7, 'eval_metric': 'auc'}. Best is trial 72 with value: 0.9754151042228556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9754151042228556, \n",
            "params {'n_estimators': 1496, 'learning_rate': 0.08513894614872088, 'max_depth': 6, 'eval_metric': 'error'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveXGB(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 1000, 2000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
        "        'objective': 'binary:logistic',  # 이진 분류\n",
        "        'eval_metric': trial.suggest_categorical(\"eval_metric\", [\"auc\", \"logloss\", \"error\"]),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveXGB(trial, x_train, y_train, x_val, y_val), n_trials=100)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1fcab3",
      "metadata": {},
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2630cbaa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:24:29,037] A new study created in memory with name: no-name-a651a7a3-95ce-4a8a-84f8-6916ff40f76a\n",
            "[I 2024-02-17 17:24:29,257] Trial 0 finished with value: 0.9615427574699139 and parameters: {'max_depth': 30, 'min_samples_split': 37, 'min_samples_leaf': 13, 'criterion': 'gini'}. Best is trial 0 with value: 0.9615427574699139.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9615427574699139, \n",
            "params {'max_depth': 30, 'min_samples_split': 37, 'min_samples_leaf': 13, 'criterion': 'gini'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveDT(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 10, 40),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = DecisionTreeClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveDT(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2959a287",
      "metadata": {},
      "source": [
        "ExtraTrees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cefd4703",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:24:34,746] A new study created in memory with name: no-name-4aca2d4a-d2ce-4e08-b4e7-56f635543340\n",
            "[I 2024-02-17 17:24:48,227] Trial 0 finished with value: 0.922567475656384 and parameters: {'n_estimators': 729, 'max_depth': 28, 'min_samples_split': 13, 'min_samples_leaf': 6, 'criterion': 'entropy'}. Best is trial 0 with value: 0.922567475656384.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.922567475656384, \n",
            "params {'n_estimators': 729, 'max_depth': 28, 'min_samples_split': 13, 'min_samples_leaf': 6, 'criterion': 'entropy'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveET(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 400, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 10, 35),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = ExtraTreesClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveET(trial, x_train, y_train, x_val, y_val), n_trials=1)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1baf6cfe",
      "metadata": {},
      "source": [
        "GradientBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca1019e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:26:44,855] A new study created in memory with name: no-name-a1d289c3-67d6-4220-b852-49ba548f1867\n",
            "[I 2024-02-17 17:30:06,455] Trial 0 finished with value: 0.9773593142990754 and parameters: {'n_estimators': 1139, 'learning_rate': 0.07436704297351776, 'max_depth': 10, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.9773593142990754.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9773593142990754, \n",
            "params {'n_estimators': 1139, 'learning_rate': 0.07436704297351776, 'max_depth': 10, 'min_samples_leaf': 11}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveGB(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 700, 1500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 15),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = GradientBoostingClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveGB(trial, x_train, y_train, x_val, y_val), n_trials=1)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40c1c554",
      "metadata": {},
      "source": [
        "AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ea58a2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-02-17 17:30:13,485] A new study created in memory with name: no-name-13940382-acb4-4b58-981e-660f38516d26\n",
            "[I 2024-02-17 17:30:55,339] Trial 0 finished with value: 0.9561994360135005 and parameters: {'n_estimators': 1549, 'learning_rate': 0.7436704297351775, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.9561994360135005.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial: score 0.9561994360135005, \n",
            "params {'n_estimators': 1549, 'learning_rate': 0.7436704297351775, 'algorithm': 'SAMME'}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveAdaBoost(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 1000, 2000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 1.0),\n",
        "        'algorithm': trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R']),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    model = AdaBoostClassifier(**param)\n",
        "    model.fit(x_tr, y_tr)\n",
        "    pred = model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveAdaBoost(trial, x_train, y_train, x_val, y_val), n_trials=1)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82acb64f",
      "metadata": {},
      "source": [
        "CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90d10e93",
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objectiveCAT(trial, x_tr, y_tr, x_val, y_val):\n",
        "    param = {\n",
        "        'iterations': trial.suggest_int('iterations', 500, 1500),\n",
        "        'depth': trial.suggest_int('depth', 5, 15),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.3),\n",
        "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
        "        'max_ctr_complexity': trial.suggest_int('max_ctr_complexity', 1, 10),\n",
        "        'random_state': 0\n",
        "    }\n",
        "    \n",
        "    # 학습 모델 생성\n",
        "    model = CatBoostClassifier(**param)\n",
        "    cat_model = model.fit(x_tr, y_tr, verbose=False)\n",
        "\n",
        "    # 모델 성능 확인\n",
        "    pred = cat_model.predict(x_val)\n",
        "    score = f1_score(y_val, pred, average=\"weighted\")\n",
        "    \n",
        "    return score\n",
        "\n",
        "\n",
        "# 하이퍼 파라미터 튜닝\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
        "study.optimize(lambda trial: objectiveCAT(trial, x_train, y_train, x_val, y_val), n_trials=30)\n",
        "\n",
        "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3401ec15",
      "metadata": {
        "id": "3401ec15"
      },
      "source": [
        "### 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9a019f4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# 보팅\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "# 스테킹\n",
        "from sklearn.ensemble import StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9193fac9",
      "metadata": {
        "id": "9193fac9"
      },
      "outputs": [],
      "source": [
        "# RandomForest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=1056     \n",
        "    , max_depth=30    \n",
        "    , min_samples_split=3   \n",
        "    , min_samples_leaf=1   \n",
        "    , bootstrap=True\n",
        "    , criterion='entropy'\n",
        ")\n",
        "\n",
        "# LightGBM\n",
        "lgb_model = LGBMClassifier(\n",
        "    num_leaves=162\n",
        "    , max_depth=10\n",
        "    , n_estimators=487\n",
        "    , learning_rate=0.07324658507873466\n",
        "    , min_child_samples=31\n",
        "    , verbose = -1\n",
        ")\n",
        "\n",
        "# LightGBM_dart\n",
        "lgb_dart_model = LGBMClassifier(\n",
        "    num_leaves=170\n",
        "    , max_depth=13\n",
        "    , n_estimators=692\n",
        "    , learning_rate=0.0916736042020453\n",
        "    , min_child_samples=10\n",
        "    , verbose = -1\n",
        "    , boosting_type=\"dart\"\n",
        ")\n",
        "\n",
        "# XGBoost \n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=1427\n",
        "    , learning_rate=0.08645845446703926\n",
        "    , max_depth=7\n",
        "    , objective='binary:logistic'\n",
        "    , eval_metric = 'error'\n",
        ")\n",
        "\n",
        "# GradientBoosting\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=1425\n",
        "    , learning_rate=0.09883679411048218\n",
        "    , max_depth=6\n",
        "    , min_samples_leaf=13\n",
        ")\n",
        "\n",
        "# DecisionTree\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    max_depth=24\n",
        "    , min_samples_split=2  # 노드를 분할하기 위한 최소 샘플 수\n",
        "    , min_samples_leaf=1  # 리프 노드에 필요한 최소 샘플 수\n",
        "    , criterion = 'entropy'\n",
        ")  \n",
        "\n",
        "# ExtraTrees\n",
        "et_model = ExtraTreesClassifier(\n",
        "    n_estimators=486\n",
        "    , min_samples_split=3  # 노드를 분할하기 위한 최소 샘플 수\n",
        "    , min_samples_leaf=1   # 리프 노드에 필요한 최소 샘플 수\n",
        "    , max_depth=26 \n",
        "    , criterion = 'entropy'\n",
        ")  \n",
        "\n",
        "# AdaBoost\n",
        "ada_model = AdaBoostClassifier(\n",
        "    n_estimators=1399\n",
        "    , learning_rate=0.9987147599335517\n",
        "    , algorithm='SAMME.R'\n",
        ")  \n",
        "\n",
        "# CatBoost\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=1045\n",
        "    , learning_rate=0.21147352826666405\n",
        "    , depth=9\n",
        "    , bootstrap_type='Bayesian'\n",
        "    , max_ctr_complexity=4\n",
        "    , verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2a8bc26",
      "metadata": {},
      "source": [
        "#### 스태킹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f39ee81f",
      "metadata": {},
      "outputs": [],
      "source": [
        "### 스태킹 분류기 생성 ###\n",
        "model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rf_model),\n",
        "        ('lgb', lgb_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('gb', gb_model),\n",
        "        ('ada', ada_model),\n",
        "        ('dt', dt_model),\n",
        "        ('et', et_model),\n",
        "        ('lgb_dart',lgb_dart_model)\n",
        "        ('cat', cat_model)\n",
        "    ],\n",
        "    final_estimator=lgb_model  # 최종 메타 모델\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75bc12d6",
      "metadata": {},
      "source": [
        "#### 보팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcaecdc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "### 보팅 분류기 생성 ###\n",
        "model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rf_model),\n",
        "        ('lgb', lgb_model),\n",
        "        ('cat', cat_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('gb', gb_model),\n",
        "        ('ada', ada_model),\n",
        "        ('dt', dt_model),\n",
        "        ('et', et_model),\n",
        "        ('lgb_dart',lgb_dart_model)\n",
        "    ],\n",
        "    voting='soft'  # 'hard'는 다수결 투표, 'soft'는 확률 평균\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cacd5ed8",
      "metadata": {
        "id": "cacd5ed8"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9df5f040",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "9df5f040",
        "outputId": "a8b64c9c-5378-4f4b-d555-1213436c7e99"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
              "                                                       max_depth=30,\n",
              "                                                       min_samples_split=3,\n",
              "                                                       n_estimators=1056)),\n",
              "                               (&#x27;lgb&#x27;,\n",
              "                                LGBMClassifier(learning_rate=0.07324658507873466,\n",
              "                                               max_depth=10,\n",
              "                                               min_child_samples=31,\n",
              "                                               n_estimators=487, num_leaves=162,\n",
              "                                               verbose=-1)),\n",
              "                               (&#x27;xgb&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel...\n",
              "                                                     min_samples_split=3,\n",
              "                                                     n_estimators=486)),\n",
              "                               (&#x27;lgb_dart&#x27;,\n",
              "                                LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                               learning_rate=0.0916736042020453,\n",
              "                                               max_depth=13,\n",
              "                                               min_child_samples=10,\n",
              "                                               n_estimators=692, num_leaves=170,\n",
              "                                               verbose=-1))],\n",
              "                   final_estimator=LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                                  learning_rate=0.0916736042020453,\n",
              "                                                  max_depth=13,\n",
              "                                                  min_child_samples=10,\n",
              "                                                  n_estimators=692,\n",
              "                                                  num_leaves=170, verbose=-1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
              "                                                       max_depth=30,\n",
              "                                                       min_samples_split=3,\n",
              "                                                       n_estimators=1056)),\n",
              "                               (&#x27;lgb&#x27;,\n",
              "                                LGBMClassifier(learning_rate=0.07324658507873466,\n",
              "                                               max_depth=10,\n",
              "                                               min_child_samples=31,\n",
              "                                               n_estimators=487, num_leaves=162,\n",
              "                                               verbose=-1)),\n",
              "                               (&#x27;xgb&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel...\n",
              "                                                     min_samples_split=3,\n",
              "                                                     n_estimators=486)),\n",
              "                               (&#x27;lgb_dart&#x27;,\n",
              "                                LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                               learning_rate=0.0916736042020453,\n",
              "                                               max_depth=13,\n",
              "                                               min_child_samples=10,\n",
              "                                               n_estimators=692, num_leaves=170,\n",
              "                                               verbose=-1))],\n",
              "                   final_estimator=LGBMClassifier(boosting_type=&#x27;dart&#x27;,\n",
              "                                                  learning_rate=0.0916736042020453,\n",
              "                                                  max_depth=13,\n",
              "                                                  min_child_samples=10,\n",
              "                                                  n_estimators=692,\n",
              "                                                  num_leaves=170, verbose=-1))</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=30, min_samples_split=3,\n",
              "                       n_estimators=1056)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.07324658507873466, max_depth=10,\n",
              "               min_child_samples=31, n_estimators=487, num_leaves=162,\n",
              "               verbose=-1)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;error&#x27;, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.08645845446703926,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1427, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.09883679411048218, max_depth=6,\n",
              "                           min_samples_leaf=13, n_estimators=1425)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>ada</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;AdaBoostClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(learning_rate=0.9987147599335517, n_estimators=1399)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=24)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>et</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier(criterion=&#x27;entropy&#x27;, max_depth=26, min_samples_split=3,\n",
              "                     n_estimators=486)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb_dart</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(boosting_type=&#x27;dart&#x27;, learning_rate=0.0916736042020453,\n",
              "               max_depth=13, min_child_samples=10, n_estimators=692,\n",
              "               num_leaves=170, verbose=-1)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(boosting_type=&#x27;dart&#x27;, learning_rate=0.0916736042020453,\n",
              "               max_depth=13, min_child_samples=10, n_estimators=692,\n",
              "               num_leaves=170, verbose=-1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "StackingClassifier(estimators=[('rf',\n",
              "                                RandomForestClassifier(criterion='entropy',\n",
              "                                                       max_depth=30,\n",
              "                                                       min_samples_split=3,\n",
              "                                                       n_estimators=1056)),\n",
              "                               ('lgb',\n",
              "                                LGBMClassifier(learning_rate=0.07324658507873466,\n",
              "                                               max_depth=10,\n",
              "                                               min_child_samples=31,\n",
              "                                               n_estimators=487, num_leaves=162,\n",
              "                                               verbose=-1)),\n",
              "                               ('xgb',\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel...\n",
              "                                                     min_samples_split=3,\n",
              "                                                     n_estimators=486)),\n",
              "                               ('lgb_dart',\n",
              "                                LGBMClassifier(boosting_type='dart',\n",
              "                                               learning_rate=0.0916736042020453,\n",
              "                                               max_depth=13,\n",
              "                                               min_child_samples=10,\n",
              "                                               n_estimators=692, num_leaves=170,\n",
              "                                               verbose=-1))],\n",
              "                   final_estimator=LGBMClassifier(boosting_type='dart',\n",
              "                                                  learning_rate=0.0916736042020453,\n",
              "                                                  max_depth=13,\n",
              "                                                  min_child_samples=10,\n",
              "                                                  n_estimators=692,\n",
              "                                                  num_leaves=170, verbose=-1))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bf2de5f",
      "metadata": {
        "id": "6bf2de5f"
      },
      "source": [
        "### 모델 성능 보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c8871444",
      "metadata": {
        "id": "c8871444"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "\n",
        "def get_clf_eval(y_test, y_pred=None):\n",
        "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
        "    weighted_F1 = f1_score(y_test, y_pred, average='weighted')  # 추가된 부분 \n",
        "\n",
        "    metrics = pd.DataFrame({\n",
        "        '정확도': [accuracy],\n",
        "        '정밀도': [precision],\n",
        "        '재현율': [recall],\n",
        "        'F1 Score': [F1],\n",
        "        'Weighted F1': [weighted_F1]  # 추가된 부분\n",
        "    })\n",
        "\n",
        "    confusion_df = pd.DataFrame(confusion, index=['True', 'False'], columns=['True', 'False'])\n",
        "\n",
        "    print(\"\\n오차행렬:\")\n",
        "    display(confusion_df)\n",
        "    print(\"평가 지표:\")\n",
        "    display(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "56a86373",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "56a86373",
        "outputId": "b0c0f95b-f5c0-4530-fdb2-a0ecc2b31b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "오차행렬:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True</th>\n",
              "      <th>False</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>756</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>97</td>\n",
              "      <td>10816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       True  False\n",
              "True    756    191\n",
              "False    97  10816"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "평가 지표:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>정확도</th>\n",
              "      <th>정밀도</th>\n",
              "      <th>재현율</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.975717</td>\n",
              "      <td>0.886284</td>\n",
              "      <td>0.79831</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.975135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        정확도       정밀도      재현율  F1 Score  Weighted F1\n",
              "0  0.975717  0.886284  0.79831      0.84     0.975135"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred = model.predict(x_val)\n",
        "get_clf_eval(y_val, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7adf8300",
      "metadata": {
        "id": "7adf8300"
      },
      "source": [
        "## 4. 제출하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d0b6e17",
      "metadata": {
        "id": "9d0b6e17"
      },
      "source": [
        "### 테스트 데이터 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "43daa73c",
      "metadata": {
        "id": "43daa73c"
      },
      "outputs": [],
      "source": [
        "# 예측에 필요한 데이터 분리\n",
        "x_test = df_test_encoded.drop([\"is_converted\", \"id\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d13f7a6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d13f7a6e",
        "outputId": "dcef4162-f5dc-4624-a9d8-b997299b4591"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "717"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_pred = model.predict(x_test)\n",
        "sum(test_pred) # True로 예측된 개수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f18e6a",
      "metadata": {
        "id": "47f18e6a"
      },
      "source": [
        "### 제출 파일 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3128a458",
      "metadata": {
        "id": "3128a458"
      },
      "outputs": [],
      "source": [
        "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
        "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
        "df_sub[\"is_converted\"] = test_pred\n",
        "\n",
        "# 제출 파일 저장\n",
        "df_sub.to_csv(\"submission_model_12.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7867ce",
      "metadata": {
        "id": "ec7867ce"
      },
      "source": [
        "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "413b3cb9",
      "metadata": {},
      "source": [
        "."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
