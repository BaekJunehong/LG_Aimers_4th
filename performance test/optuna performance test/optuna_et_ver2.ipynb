{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설치안되어있는경우 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 경고 메세지 무시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/train.csv\") # 학습용 데이터\n",
    "df_test = pd.read_csv(\"./data/submission.csv\") # 테스트 데이터(제출파일의 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59299 entries, 0 to 59298\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   bant_submit              59299 non-null  float64\n",
      " 1   customer_country         58317 non-null  object \n",
      " 2   business_unit            59299 non-null  object \n",
      " 3   com_reg_ver_win_rate     14568 non-null  float64\n",
      " 4   customer_idx             59299 non-null  int64  \n",
      " 5   customer_type            15338 non-null  object \n",
      " 6   enterprise               59299 non-null  object \n",
      " 7   historical_existing_cnt  13756 non-null  float64\n",
      " 8   id_strategic_ver         3444 non-null   float64\n",
      " 9   it_strategic_ver         1121 non-null   float64\n",
      " 10  idit_strategic_ver       4565 non-null   float64\n",
      " 11  customer_job             40566 non-null  object \n",
      " 12  lead_desc_length         59299 non-null  int64  \n",
      " 13  inquiry_type             58358 non-null  object \n",
      " 14  product_category         39925 non-null  object \n",
      " 15  product_subcategory      9235 non-null   object \n",
      " 16  product_modelname        9229 non-null   object \n",
      " 17  customer_country.1       58317 non-null  object \n",
      " 18  customer_position        59299 non-null  object \n",
      " 19  response_corporate       59299 non-null  object \n",
      " 20  expected_timeline        28436 non-null  object \n",
      " 21  ver_cus                  59299 non-null  int64  \n",
      " 22  ver_pro                  59299 non-null  int64  \n",
      " 23  ver_win_rate_x           18417 non-null  float64\n",
      " 24  ver_win_ratio_per_bu     15304 non-null  float64\n",
      " 25  business_area            18417 non-null  object \n",
      " 26  business_subarea         5526 non-null   object \n",
      " 27  lead_owner               59299 non-null  int64  \n",
      " 28  is_converted             59299 non-null  bool   \n",
      "dtypes: bool(1), float64(8), int64(5), object(15)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bant_submit, business_unit, enterprise 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따로 처리한 부분 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_country, customer_country.1 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_customer_country_tokenized(df, column_name):\n",
    "    for i, entry in enumerate(df[column_name]):\n",
    "        if isinstance(entry, str):\n",
    "            tokens = [token.strip() for token in entry.replace('/', ',').split(',') if token.strip() != '']\n",
    "            if tokens:\n",
    "                df.at[i, column_name] = tokens[-1]\n",
    "            else:\n",
    "                df.at[i, column_name] = np.nan\n",
    "        else:\n",
    "            df.at[i, column_name] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer_country, customer_country.1 값을 토큰화 하여 말단 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = process_customer_country_tokenized(df_train, 'customer_country')\n",
    "df_train = process_customer_country_tokenized(df_train, 'customer_country.1')\n",
    "\n",
    "df_test = process_customer_country_tokenized(df_test, 'customer_country')\n",
    "df_test = process_customer_country_tokenized(df_test, 'customer_country.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미국 주 이름 카테고리화\n",
    "us_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "df_train['customer_country'] = df_train['customer_country'].replace(us_states, 'United States')\n",
    "df_train['customer_country.1'] = df_train['customer_country.1'].replace(us_states, 'United States')\n",
    "\n",
    "df_test['customer_country'] = df_test['customer_country'].replace(us_states, 'United States')\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].replace(us_states, 'United States')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LG 사이트에서 작성된 나라정보를 리스트화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 Test데이터셋 값중 Corporate은 특정 국가나 지역을 나타내는 것이 아니라,  \n",
    "보통 기업이나 조직을 나타내는 용어로 국가 리스트에 따로 포함시키지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "asia = ['Australia', 'Bangladesh', 'Brunei', 'Cambodia', 'China', 'Fiji', 'Hong Kong', 'India', 'Indonesia', 'Laos', 'Malaysia', 'Maldives', 'Myanmar', 'Nepal', 'New Zealand', 'Papula New Guinea', 'Philippines', 'Singapore', 'Sri Lanka', 'Taiwan', 'Thailand', 'Vietnam', 'Japan', 'South Korea']\n",
    "cis = ['Belarus', 'Kazakhstan', 'Mongolia', 'Russia', 'Turkmenistan', 'Ukraine', 'Uzbekistan']\n",
    "europe = ['Albania', 'Austria', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Cyprus', 'Czech', 'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Kosovo', 'Latvia', 'Lithuania', 'Luxembourg', 'Macedonia', 'Montenegro', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'United Kingdom', 'Isle of Man', 'Malta']\n",
    "latin_america_and_the_caribbean = ['Anguilla', 'Antigua', 'Argentina', 'Aruba', 'Bahamas', 'Barbados', 'Belize', 'Bermuda', 'Bolivia', 'Brazil', 'British Virgin Islands', 'Cayman Islands', 'Chile', 'Colombia', 'COLOMBIA', 'Costa Rica', 'Cuba', 'Curacao', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Grenada', 'Guatemala', 'Guyana Haiti', 'Honduras', 'Jamaica', 'Mexico', 'Netherlands Antilles', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'Puerto Rico', 'Saint Lucia', 'St Kitts', 'St Maarten', 'St Vincent', 'Suriname', 'Trinidad and Tobago', 'Turks and Caicos Islands', 'Uruguay', 'US Virgin Islands', 'Venezuela', 'Antigua and Barbuda', 'Saint Kitts and Nevis']\n",
    "middle_east_and_africa = ['Afghanistan', 'Algeria', 'Angola', 'Armenia', 'Azerbaijan', 'Bahrain', 'Benin', 'Botswana', 'Burkina Faso Cameroon', 'Central African Republic', 'Congo', \"Cote d'Ivoire\", 'Democratic Republic of the Congo', 'Djibouti', 'Egypt', 'EGYPT', 'Equatorial Guinea', 'Ethiopia', 'Gabon', 'Gambia', 'Georgia', 'Ghana', 'Guinea Iran', 'Iraq', 'Israel', 'Ivory Coast', 'Jordan', 'Kenya', 'Kuwait', 'Lebanon', 'Liberia', 'Mali', 'Mauritania', 'Mauritius', 'Morocco', 'Mozambique', 'Namibia', 'Nigeria', 'Oman', 'Pakistan', 'Palestine', 'Qatar', 'Rwanda', 'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Sierra Leone', 'Somalia', 'South Africa', 'Sudan', 'Swaziland', 'Syria', 'Togo', 'Tunisia', 'Türkiye', 'Turkey', 'U.A.E', 'Uganda', 'United Republic of Tanzania', 'Yemen', 'Zambia', 'Eritrea', 'Libya Malawi', 'Zimbabwe']\n",
    "north_america = ['Canada', 'United States', 'UNITED STATES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_country(country):\n",
    "    if country in asia:\n",
    "        return country\n",
    "    elif country in cis:\n",
    "        return country\n",
    "    elif country in europe:\n",
    "        return country\n",
    "    elif country in latin_america_and_the_caribbean:\n",
    "        return country\n",
    "    elif country in middle_east_and_africa:\n",
    "        return country\n",
    "    elif country in north_america:\n",
    "        return country\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_train['customer_country'] = df_train['customer_country'].apply(update_country)\n",
    "df_test['customer_country'] = df_test['customer_country'].apply(update_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_dict = {country: 'Asia' for country in asia}\n",
    "continent_dict.update({country: 'CIS' for country in cis})\n",
    "continent_dict.update({country: 'Europe' for country in europe})\n",
    "continent_dict.update({country: 'Latin America and the Caribbean' for country in latin_america_and_the_caribbean})\n",
    "continent_dict.update({country: 'Middle East & Africa' for country in middle_east_and_africa})\n",
    "continent_dict.update({country: 'North America' for country in north_america})\n",
    "\n",
    "df_train['customer_country.1'] = df_train['customer_country.1'].replace(continent_dict)\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].replace(continent_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer_country.1 빈도수이하값 및 결측값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_country.1'의 빈도 계산\n",
    "counts_train = df_train['customer_country.1'].value_counts()\n",
    "counts_test = df_test['customer_country.1'].value_counts()\n",
    "\n",
    "# 일정 빈도 이하 unknown 처리\n",
    "find_count_train = counts_train[counts_train <= 30].index\n",
    "find_count_test = counts_test[counts_test <= 2].index\n",
    "\n",
    "# 일정 빈도 이하인 국가를 'Unknown'으로 설정\n",
    "df_train.loc[df_train['customer_country.1'].isin(find_count_train), 'customer_country.1'] = 'Other'\n",
    "df_test.loc[df_test['customer_country.1'].isin(find_count_test), 'customer_country.1'] = 'Other'\n",
    "\n",
    "# 결측값에 대한 처리\n",
    "df_train['customer_country.1'] = df_train['customer_country.1'].fillna('Unknown')\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "## {'Corporate'} 값이 test 데이터셋에는 존재하는 반면 train 데이터셋에는 없음\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['customer_country.1'].unique()\n",
    "df_test['customer_country.1'] = df_test['customer_country.1'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_idx 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_idx'의 빈도 계산\n",
    "counts_train = df_train['customer_idx'].value_counts()\n",
    "\n",
    "# 일정 빈도 이하 처리\n",
    "find_count_train = counts_train[counts_train <= 10].index\n",
    "\n",
    "# 일정 빈도 이하인 customer_idx를 '-1'으로 설정\n",
    "df_train.loc[df_train['customer_idx'].isin(find_count_train), 'customer_idx'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return -1\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['customer_idx'].unique()\n",
    "df_test['customer_idx'] = df_test['customer_idx'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer_idx의 값에 대해서 is_converted에 대한 비율 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_idx' 카테고리별로 'is_converted'의 평균과 갯수를 계산\n",
    "idx_target = df_train.groupby('customer_idx')['is_converted'].agg(['mean', 'count']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계산한 비율에 대해서 customer_idx 값을 특정범위에 대한 범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mean' 값이 0.9보다 크면 1, 아니면 0을 부여\n",
    "idx_target['label'] = ((idx_target['mean'] > 0.99) & (idx_target['count'] >= 10)).astype(int)\n",
    "\n",
    "# 'idx_target'를 기준으로 'label' 값을 매핑\n",
    "idx_map = idx_target['label'].to_dict()\n",
    "\n",
    "# 'customer_idx' 열을 업데이트\n",
    "df_train['customer_idx_99'] = df_train['customer_idx'].map(idx_map)\n",
    "df_test['customer_idx_99'] = df_test['customer_idx'].map(idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mean' 값이 0.01보다 작으면 1, 아니면 0을 부여\n",
    "idx_target['label'] = ((idx_target['mean'] < 0.01)& (idx_target['count'] >= 10)).astype(int)\n",
    "\n",
    "# 'idx_target'를 기준으로 'label' 값을 매핑\n",
    "idx_map = idx_target['label'].to_dict()\n",
    "\n",
    "# 'customer_idx' 열을 업데이트\n",
    "df_train['customer_idx_001'] = df_train['customer_idx'].map(idx_map)\n",
    "df_test['customer_idx_001'] = df_test['customer_idx'].map(idx_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_type 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타나 연관 단어에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 재할당\n",
    "df_train['customer_type'] = df_train['customer_type'].replace({\n",
    "    'Others': 'Other',\n",
    "    'Etc.': 'Other',\n",
    "    'Software / Solution Provider': 'Software/Solution Provider',\n",
    "    'Specifier/ Influencer': 'Specifier/Influencer',\n",
    "    'Specifier / Influencer': 'Specifier/Influencer',\n",
    "    'Distributor': 'Dealer/Distributor',\n",
    "    'Homeowner': 'Home Owner',\n",
    "    'Manager / Director' : 'Manager/Director',\n",
    "    'Commercial end-user': 'End-user',\n",
    "    'End-Customer': 'End Customer',\n",
    "    'Consultant': 'Architect/Consultant',\n",
    "    'Installer': 'Specifier/Influencer',\n",
    "    'Installer/Contractor': 'Specifier/Influencer',\n",
    "    \n",
    "    # LG 카테고리 참고함\n",
    "    'Corporate' : 'End Customer',\n",
    "    'Dealer/Distributor' : 'Channel Partner',\n",
    "    'Reseller' : 'Channel Partner',\n",
    "    'Technician': 'Specifier/Influencer',\n",
    "    'Architect/Consultant': 'Specifier/Influencer',\n",
    "    'Developer': 'End Customer',  \n",
    "})\n",
    "\n",
    "df_test['customer_type'] = df_test['customer_type'].replace({\n",
    "    'Specifier/ Influencer': 'Specifier/Influencer',\n",
    "    'End-Customer': 'End Customer',\n",
    "\n",
    "    # LG 카테고리 참고함\n",
    "    'Developer': 'End Customer',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_type' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['customer_type'] = df_train['customer_type'].fillna('Unknown')\n",
    "df_test['customer_type'] = df_test['customer_type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 customer_type 값을 처리하는 과정에서  \n",
    "End Customer가 End-user에 해당한다는것을 알수 있음으로 값을 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 재할당\n",
    "df_train['customer_type'] = df_train['customer_type'].replace({\n",
    "    'End Customer': 'End-user'\n",
    "})\n",
    "df_test['customer_type'] = df_test['customer_type'].replace({\n",
    "    'End Customer': 'End-user'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### historical_existing_cnt 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median 값으로 대체(이때 median값은 4)\n",
    "cnt_train_med = df_train['historical_existing_cnt'].median()\n",
    "cnt_test_med = df_test['historical_existing_cnt'].median()\n",
    "\n",
    "# median 값으로 결측값 대체\n",
    "df_train['historical_existing_cnt'] = df_train['historical_existing_cnt'].fillna(cnt_train_med)\n",
    "df_test['historical_existing_cnt'] = df_test['historical_existing_cnt'].fillna(cnt_test_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Max 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max 스케일링 \n",
    "min_value = df_train['historical_existing_cnt'].min()\n",
    "max_value = df_train['historical_existing_cnt'].max()\n",
    "\n",
    "\n",
    "df_train['historical_existing_cnt'] = (df_train['historical_existing_cnt'] - min_value) / (max_value - min_value)\n",
    "df_test['historical_existing_cnt'] = (df_test['historical_existing_cnt'] - min_value) / (max_value - min_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id_strategic_ver, it_strategic_ver, idit_strategic_ver 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 값을 0으로 채우기\n",
    "df_train['id_strategic_ver'].fillna(0, inplace=True)\n",
    "df_train['it_strategic_ver'].fillna(0, inplace=True)\n",
    "df_train['idit_strategic_ver'].fillna(0, inplace=True)\n",
    "\n",
    "df_test['id_strategic_ver'].fillna(0, inplace=True)\n",
    "df_test['it_strategic_ver'].fillna(0, inplace=True)\n",
    "df_test['idit_strategic_ver'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_job 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타관련 값에 대한 변환  \n",
    "LG 홈페이지에서 제공된 job 리스트에 해당 안되는 값에 대한 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_job(customer_job):\n",
    "    # LG list 참고\n",
    "    job = ['accounting','administrative','arts and design','business development','community and social services','consulting','curation','education','engineering', 'entrepreneurship','finance','healthcare services','human resources','information technology','legal','marketing','media and communication','military and protective services operations','product management', 'program and project management','purchasing','quality assurance','real estate','research','sales','support','others']\n",
    "\n",
    "    # (오타변환)'media and communications'를 'media and communication'으로 변환\n",
    "    if customer_job == 'media and communications':\n",
    "        customer_job = 'media and communication'\n",
    "    \n",
    "    if not customer_job:\n",
    "        return 'others'\n",
    "    elif customer_job in job:\n",
    "        return customer_job\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "df_train['customer_job'] = df_train['customer_job'].apply(search_job)\n",
    "df_test['customer_job'] = df_test['customer_job'].apply(search_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lead_desc_length 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Max 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max 스케일링 \n",
    "min_value = df_train['lead_desc_length'].min()\n",
    "max_value = df_train['lead_desc_length'].max()\n",
    "\n",
    "df_train['lead_desc_length'] = (df_train['lead_desc_length'] - min_value) / (max_value - min_value)\n",
    "df_test['lead_desc_length'] = (df_test['lead_desc_length'] - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 값을 0으로 채우기\n",
    "df_train['lead_desc_length'].fillna(0, inplace=True)\n",
    "df_test['lead_desc_length'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inquiry_type 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타나 연관 단어에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'inquiry_type' 열의 철자오류에 대해 일관된 값으로 변환\n",
    "df_train['inquiry_type'] = df_train['inquiry_type'].replace({\n",
    "\n",
    "    'Quotation or purchase consultation': 'Quotation or Purchase Consultation',\n",
    "    'Request for quotation or purchase': 'Quotation or Purchase Consultation',\n",
    "    'quotation_or_purchase_consultation': 'Quotation or Purchase Consultation',\n",
    "    'quotation_': 'Quotation or Purchase Consultation',\n",
    "    'Purchase or Quotation': 'Quotation or Purchase Consultation',\n",
    "    'Quotation or Purchase consultation': 'Quotation or Purchase Consultation',\n",
    "    'Purchase': 'Quotation or Purchase Consultation',\n",
    "    'quotation_or_purchase_consultation': 'Quotation or Purchase Consultation',\n",
    "    'quotation_': 'Quotation or Purchase Consultation',\n",
    "    'quotation_': 'Quotation or Purchase Consultation',\n",
    "\n",
    "    'Usage or technical consultation': 'Usage or Technical Consultation',\n",
    "    'Technical Consultation': 'Usage or Technical Consultation',\n",
    "    'usage or technical consultation': 'Usage or Technical Consultation',\n",
    "    'usage_or_technical_consultation': 'Usage or Technical Consultation',\n",
    "    'Request for technical consulting': 'Usage or Technical Consultation',\n",
    "    'technical_consultation': 'Usage or Technical Consultation',\n",
    "    'technical': 'Usage or Technical Consultation',\n",
    "\n",
    "    'sales':'Sales Inquiry',\n",
    "    'Sales inquiry':'Sales Inquiry',\n",
    "\n",
    "    'other': 'Other',\n",
    "    'other_': 'Other',\n",
    "    'others': 'Other',\n",
    "    'Others' : 'Other',\n",
    "    'Etc.': 'Other',\n",
    "    'ETC.': 'Other'\n",
    "\n",
    "})\n",
    "\n",
    "df_test['inquiry_type'] = df_test['inquiry_type'].replace({\n",
    "\n",
    "    'Technical Consultation': 'Usage or Technical Consultation',\n",
    "\n",
    "    'other_': 'Other',\n",
    "    'Others' : 'Other',\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정값에 대한 처리('Other' 값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'inquiry_type' 열의 값별 개수를 계산합니다.\n",
    "value_counts = df_train['inquiry_type'].value_counts()\n",
    "\n",
    "# 2개 이하인 값들의 리스트를 만듭니다.\n",
    "to_replace = value_counts[value_counts <= 2].index\n",
    "\n",
    "# 2개 이하인 값들을 'Other'로 업데이트합니다.\n",
    "df_train['inquiry_type'] = df_train['inquiry_type'].replace(to_replace, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "## test 데이터셋 값중 {'Media Inquiry'} 값에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['inquiry_type'].unique()\n",
    "df_test['inquiry_type'] = df_test['inquiry_type'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체('Unknown' 값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'inquiry_type' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['inquiry_type'] = df_train['inquiry_type'].fillna('Unknown')\n",
    "df_test['inquiry_type'] = df_test['inquiry_type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### product_category 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정값에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['product_category'] = df_train['product_category'].replace({\n",
    "    'notebook': 'laptop',\n",
    "    'others': 'other',\n",
    "    'ess': 'other',\n",
    "    'signage care solution': 'other',\n",
    "})\n",
    "\n",
    "df_test['product_category'] = df_test['product_category'].replace({\n",
    "    'notebook': 'laptop',\n",
    "    'others': 'other',\n",
    "    'ess': 'other',\n",
    "    'signage care solution': 'other',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 빈도수 이하 값대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'product_category'의 빈도 계산\n",
    "counts_train = df_train['product_category'].value_counts()\n",
    "\n",
    "# 빈도가 특정수치 이하인 product_category 를 찾음\n",
    "find_count_train = counts_train[counts_train <= 15].index\n",
    "\n",
    "# 빈도가 특정수치 이하값 \n",
    "df_train.loc[df_train['product_category'].isin(find_count_train), 'product_category'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'product_category' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['product_category'] = df_train['product_category'].fillna('unknown')\n",
    "df_test['product_category'] = df_test['product_category'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### product_subcategory, product_modelname 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터셋에 없는 데이터에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "# product_subcategory 결측값 대체\n",
    "unique_subcategory = df_train['product_subcategory'].unique()\n",
    "df_test['product_subcategory'] = df_test['product_subcategory'].apply(lambda x: replace_unknown(x, unique_subcategory))\n",
    "\n",
    "# product_modelname 결측값 대체\n",
    "unique_modelname = df_train['product_modelname'].unique()\n",
    "df_test['product_modelname'] = df_test['product_modelname'].apply(lambda x: replace_unknown(x, unique_modelname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'product_subcategory' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['product_subcategory'] = df_train['product_subcategory'].fillna('Unknown')\n",
    "df_test['product_subcategory'] = df_test['product_subcategory'].fillna('Unknown')\n",
    "\n",
    "# 'product_modelname' 변수에서 NaN 값을 'Unknown' 으로 대체\n",
    "df_train['product_modelname'] = df_train['product_modelname'].fillna('Unknown')\n",
    "df_test['product_modelname'] = df_test['product_modelname'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customer_position 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오타에 대한 값이나 관련값으로 대체가능한 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['customer_position'] = df_train['customer_position'].replace({\n",
    "    'vicepresident': 'vice president',\n",
    "    'vp': 'vice president',\n",
    "    'entrylevel': 'entry level',\n",
    "    'c-levelexecutive': 'c-level executive',\n",
    "    'founder': 'ceo/founder',\n",
    "    'ceo/fundador': 'ceo/founder',\n",
    "    'commercial consultant': 'consultant',\n",
    "    'architect/consultant': 'consultant',\n",
    "    'architecture/consult': 'consultant',\n",
    "    'business unit director': 'director',\n",
    "    'no influence': 'none',\n",
    "    'not applicable': 'none',\n",
    "    'commercial end-user': 'end-user',\n",
    "    'exhibitiontv': 'exhibition',\n",
    "    'decision-influencer': 'decision influencer',\n",
    "    'sales': 'business development/sales',\n",
    "    'subsidiary sales (ise)': 'business development/sales',\n",
    "    'business development': 'business development/sales',\n",
    "    'medical device manufacturer': 'manufacturer',\n",
    "    'assistant professor of enlish': 'assistant professor',\n",
    "    'asst prof.': 'assistant professor',\n",
    "    'prof.': 'professor',\n",
    "    'professor of mathematics': 'professor',\n",
    "    'principal & director': 'director',\n",
    "    'others': 'other',\n",
    "    'decision-maker': 'decision maker',\n",
    "})\n",
    "\n",
    "df_test['customer_position'] = df_test['customer_position'].replace({\n",
    "    'vicepresident': 'vice president',\n",
    "    'vp': 'vice president',\n",
    "    'entrylevel': 'entry level',\n",
    "    'c-levelexecutive': 'c-level executive',\n",
    "    'founder': 'ceo/founder',\n",
    "    'ceo/fundador': 'ceo/founder',\n",
    "    'commercial consultant': 'consultant',\n",
    "    'architect/consultant': 'consultant',\n",
    "    'architecture/consult': 'consultant',\n",
    "    'business unit director': 'director',\n",
    "    'no influence': 'none',\n",
    "    'not applicable': 'none',\n",
    "    'commercial end-user': 'end-user',\n",
    "    'exhibitiontv': 'exhibition',\n",
    "    'decision-influencer': 'decision influencer',\n",
    "    'sales': 'business development/sales',\n",
    "    'subsidiary sales (ise)': 'business development/sales',\n",
    "    'business development': 'business development/sales',\n",
    "    'medical device manufacturer': 'manufacturer',\n",
    "    'assistant professor of enlish': 'assistant professor',\n",
    "    'asst prof.': 'assistant professor',\n",
    "    'prof.': 'professor',\n",
    "    'professor of mathematics': 'professor',\n",
    "    'principal & director': 'director',\n",
    "    'others': 'other'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 범주이하의 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "# 'inquiry_type' 열의 값별 개수 계산\n",
    "counts_train = df_train['customer_position'].value_counts()\n",
    "counts_test = df_test['customer_position'].value_counts()\n",
    "\n",
    "# 특정수 이하인 값들의 리스트로 만듬\n",
    "replace_train = counts_train[counts_train <= 40].index\n",
    "replace_test = counts_test[counts_test <= 2].index\n",
    "\n",
    "# 특정수 이하인 값들을 'other'로 업데이트\n",
    "df_train['customer_position'] = df_train['customer_position'].replace(replace_train, 'other')\n",
    "df_test['customer_position'] = df_test['customer_position'].replace(replace_test, 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### response_corporate 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 범주이하 값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'response_corporate'의 빈도 계산\n",
    "counts_train = df_train['response_corporate'].value_counts()\n",
    "\n",
    "# 빈도가 특정수치 이하인 product_category 를 찾음\n",
    "find_count_train = counts_train[counts_train <= 5].index\n",
    "\n",
    "# 빈도가 특정수치 이하값 \n",
    "df_train.loc[df_train['response_corporate'].isin(find_count_train), 'response_corporate'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터셋에 없는 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['response_corporate'].unique()\n",
    "df_test['response_corporate'] = df_test['response_corporate'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expected_timeline 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'months' , 'year'를 포함하는 값을 추출  \n",
    "(이때 해당안되는 값에 대해서는 etc 값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'months' , 'year' 포함하는 값 추출(아닌경우 'etc' 값으로 변환)\n",
    "df_train['expected_timeline'] = np.where(df_train['expected_timeline'].str.contains('months|year', na=False), df_train['expected_timeline'], 'etc.')\n",
    "df_test['expected_timeline'] = np.where(df_test['expected_timeline'].str.contains('months|year', na=False), df_test['expected_timeline'], 'etc.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추출한 값에 대해서 관련 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['expected_timeline'] = df_train['expected_timeline'].replace({\n",
    "    'less_than_3_months': 'less than 3 months',\n",
    "    '3_months_~_6_months': '3 months ~ 6 months',\n",
    "    '9_months_~_1_year': '9 months ~ 1 year',\n",
    "    'more_than_a_year': 'more than a year',\n",
    "    '6_months_~_9_months': '6 months ~ 9 months',\n",
    "    '9 months - 1 year': '9 months ~ 1 year',\n",
    "    'duplicate lead - il220100042906. less than 3 months': 'less than 3 months',\n",
    "    'less than 3 months ,meeting with the customer for the more details and tentative boq will ne 32 and 43': 'less than 3 months',\n",
    "\n",
    "    'less_than_3_months': 'less than 3 months',\n",
    "    'less than 3 months- outdoor led requiment': 'less than 3 months',\n",
    "    'need to discuss with client in next two months. they need to check the product and accridngly proceed for personal use.': 'less than 3 months',\n",
    "    'quotation sent – 75tr3dj , work in progress, he will buy after 2 months. he has not even seen the quote yet.': 'less than 3 months',\n",
    "    'quote shared with customer, he will confirm after 2 months. lead shared with partner.': 'less than 3 months',\n",
    "    'less than 3 months- outdoor led requiment': 'less than 3 months',\n",
    "    'less than 3 months. customer not answered . to call back': 'less than 3 months',\n",
    "\n",
    "    'purchase planning after 3 months': '3 months ~ 6 months',\n",
    "    'needs hotel tv after 4 months, will call us.': '3 months ~ 6 months',\n",
    "\n",
    "    'we are already in touch with this cutsomer from last 2 years, he has never purchased any product till date. i called him up twice but no reponse.' : 'etc.',\n",
    "    'very abrupt customer. said the inquiry was made months ago and was rude enough. closing in the system as the client behaviour has no scope to discuss on requirement. need marketing team to check if the case was received in dec or jan as per client.' : 'etc.',\n",
    "\n",
    "    # 아래 값들은 근사 기간으로 넣어줌\n",
    "    'more then 3 months': '3 months ~ 6 months',\n",
    "    'less than 5 months': '3 months ~ 6 months',\n",
    "    'less than 6 months': '3 months ~ 6 months',\n",
    "    'less then 6 months': '3 months ~ 6 months',\n",
    "    '3 months': '3 months ~ 6 months',\n",
    "    '4/8 months': '3 months ~ 6 months',\n",
    "\n",
    "})\n",
    "df_test['customer_position'] = df_test['customer_position'].replace({\n",
    "    'less_than_3_months': 'less than 3 months',\n",
    "    '3_months_~_6_months': '3 months ~ 6 months',\n",
    "    '9_months_~_1_year': '9 months ~ 1 year',\n",
    "    'more_than_a_year': 'more than a year',\n",
    "    '6_months_~_9_months': '6 months ~ 9 months'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver_cus, ver_pro 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따로처리할 부분 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver_win_rate_x 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ver_win_rate_x' 변수에서 NaN 값을 0으로 대체\n",
    "df_train['ver_win_rate_x'] = df_train['ver_win_rate_x'].fillna(0)\n",
    "df_test['ver_win_rate_x'] = df_test['ver_win_rate_x'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver_win_ratio_per_bu 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "business_area, business_unit 의 변수로 그룹화 진행  \n",
    "해당하는 그룹에서 'ver_win_ratio_per_bu' 의 결측값에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_train.groupby([\"business_area\",\"business_unit\"])\n",
    "\n",
    "# business_area, business_unit 그룹화하여 샘플 수 계산\n",
    "grouped_counts = df_train.groupby(['business_area', 'business_unit']).size()\n",
    "\n",
    "# business_area, business_unit, is_converted 그룹화하여 영업 전환된(is_converted) 샘플 수 계산\n",
    "converted_counts = df_train[df_train['is_converted']].groupby(['business_area', 'business_unit']).size()\n",
    "\n",
    "# business_area, business_unit별 샘플 수 대비 영업 전환된(is_converted) 샘플 수의 비율 계산\n",
    "conversion_rates = converted_counts / grouped_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 통해 구한 값에 대해서 해당하는 부분의 값이 결측값인 경우 값대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹별 값을 딕셔너리로 정의\n",
    "group_values = {\n",
    "    ('corporate / office', 'AS'): 0.029734,\n",
    "    ('corporate / office', 'ID'): 0.088618,\n",
    "    ('corporate / office', 'IT'): 0.033333,\n",
    "    ('corporate / office', 'Solution'): 0.034483,\n",
    "    ('education', 'AS'): 0.066667,\n",
    "    ('education', 'ID'): 0.064897,\n",
    "    ('education', 'IT'): 0.046667,\n",
    "    ('education', 'Solution'): None,\n",
    "    ('factory', 'AS'): 0.059553,\n",
    "    ('factory', 'ID'): 0.068519,\n",
    "    ('factory', 'IT'): 0.337349,\n",
    "    ('factory', 'Solution'): None,\n",
    "    ('government department', 'AS'): 0.040462,\n",
    "    ('government department', 'ID'): 0.076010,\n",
    "    ('government department', 'IT'): None,\n",
    "    ('government department', 'Solution'): None,\n",
    "    ('hospital & health care', 'AS'): 0.096154,\n",
    "    ('hospital & health care', 'ID'): 0.128378,\n",
    "    ('hospital & health care', 'IT'): 0.378771,\n",
    "    ('hotel & accommodation', 'AS'): 0.004831,\n",
    "    ('hotel & accommodation', 'ID'): 0.118902,\n",
    "    ('hotel & accommodation', 'IT'): 0.002528,\n",
    "    ('hotel & accommodation', 'Solution'): None,\n",
    "    ('power plant / renewable energy', 'AS'): 0.129032,\n",
    "    ('power plant / renewable energy', 'ID'): 0.279070,\n",
    "    ('power plant / renewable energy', 'IT'): None,\n",
    "    ('public facility', 'AS'): 0.030000,\n",
    "    ('public facility', 'ID'): 0.099631,\n",
    "    ('public facility', 'IT'): 0.025000,\n",
    "    ('public facility', 'Solution'): None,\n",
    "    ('residential (home)', 'AS'): 0.017582,\n",
    "    ('residential (home)', 'ID'): 0.038961,\n",
    "    ('residential (home)', 'IT'): 0.142857,\n",
    "    ('residential (home)', 'Solution'): None,\n",
    "    ('retail', 'AS'): 0.026650,\n",
    "    ('retail', 'ID'): 0.061637,\n",
    "    ('retail', 'IT'): 0.073620,\n",
    "    ('retail', 'Solution'): None,\n",
    "    ('special purpose', 'AS'): 0.028050,\n",
    "    ('special purpose', 'ID'): 0.070698,\n",
    "    ('special purpose', 'IT'): 0.046296,\n",
    "    ('special purpose', 'Solution'): None,\n",
    "    ('transportation', 'AS'): 0.037736,\n",
    "    ('transportation', 'ID'): 0.064815,\n",
    "    ('transportation', 'IT'): 0.060606,\n",
    "    ('transportation', 'Solution'): None,\n",
    "}\n",
    "\n",
    "# 'business_area'와 'business_unit'에 해당하는 그룹별 값을 'ver_win_ratio_per_bu' 변수에 적용\n",
    "df_train['ver_win_ratio_per_bu'] = df_train.apply(lambda row: group_values.get((row['business_area'], row['business_unit'])), axis=1)\n",
    "df_test['ver_win_ratio_per_bu'] = df_test.apply(lambda row: group_values.get((row['business_area'], row['business_unit'])), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 0값으로 대체\n",
    "df_train['ver_win_ratio_per_bu'].fillna(0, inplace=True)\n",
    "df_test['ver_win_ratio_per_bu'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### business_area, business_subarea 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 'unknown' 값으로 대체\n",
    "df_train['business_area'].fillna('unknown', inplace=True)\n",
    "df_test['business_area'].fillna('unknown', inplace=True)\n",
    "\n",
    "# 결측값 'Unknown' 값으로 대체\n",
    "df_train['business_subarea'].fillna('Unknown', inplace=True)\n",
    "df_test['business_subarea'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lead_owner 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 빈도수 이하 값에 대한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lead_owner'의 빈도 계산\n",
    "counts_train = df_train['lead_owner'].value_counts()\n",
    "\n",
    "# 빈도가 특정수치 이하인 lead_owner 를 찾음\n",
    "find_count_train = counts_train[counts_train <= 10].index\n",
    "\n",
    "# 빈도가 특정수치 이하값 \n",
    "df_train.loc[df_train['lead_owner'].isin(find_count_train), 'lead_owner'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋에 없는 test 데이터셋에 대한 처리\n",
    "def replace_unknown_values(row, unique):\n",
    "    if row not in unique:\n",
    "        return -1\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "unique_train_values = df_train['lead_owner'].unique()\n",
    "df_test['lead_owner'] = df_test['lead_owner'].apply(lambda x: replace_unknown_values(x, unique_train_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lead_owner에 대하여 카테고리화하여 is_converted의 비율을 계산  \n",
    "계산한 값에대해서 특정 비율에 해당하는 값에대해서 범주화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'customer_idx' 카테고리별로 'is_converted'의 평균과 갯수를 계산\n",
    "owner_target = df_train.groupby('lead_owner')['is_converted'].agg(['mean', 'count']).sort_values(by='mean', ascending=False)\n",
    "\n",
    "# 'mean' 값이 특정 값보다 크면 1, 아니면 0을 부여\n",
    "owner_target['label_09'] = (owner_target['mean'] > 0.9).astype(int)\n",
    "owner_target['label_07'] = ((0.9 >= owner_target['mean']) & (owner_target['mean'] > 0.7)).astype(int)\n",
    "owner_target['label_05'] = ((0.7 >= owner_target['mean']) & (owner_target['mean'] > 0.5)).astype(int)\n",
    "owner_target['label_03'] = ((0.5 >= owner_target['mean']) & (owner_target['mean'] > 0.3)).astype(int)\n",
    "owner_target['label_00'] = ((0.001 >= owner_target['mean']) & (owner_target['count'] <= 100)).astype(int)\n",
    "\n",
    "\n",
    "# 'owner_target'를 기준으로 'label' 값을 매핑\n",
    "label_map_09 = owner_target['label_09'].to_dict()\n",
    "label_map_07 = owner_target['label_07'].to_dict()\n",
    "label_map_05 = owner_target['label_05'].to_dict()\n",
    "label_map_03 = owner_target['label_03'].to_dict()\n",
    "label_map_00 = owner_target['label_00'].to_dict()\n",
    "\n",
    "\n",
    "# 'lead_owner' 열을 업데이트\n",
    "df_train['lead_owner_09'] = df_train['lead_owner'].map(label_map_09)\n",
    "df_train['lead_owner_07'] = df_train['lead_owner'].map(label_map_07)\n",
    "df_train['lead_owner_05'] = df_train['lead_owner'].map(label_map_05)\n",
    "df_train['lead_owner_03'] = df_train['lead_owner'].map(label_map_03)\n",
    "df_train['lead_owner_00'] = df_train['lead_owner'].map(label_map_00)\n",
    "\n",
    "df_test['lead_owner_09'] = df_test['lead_owner'].map(label_map_09)\n",
    "df_test['lead_owner_07'] = df_test['lead_owner'].map(label_map_07)\n",
    "df_test['lead_owner_05'] = df_test['lead_owner'].map(label_map_05)\n",
    "df_test['lead_owner_03'] = df_test['lead_owner'].map(label_map_03)\n",
    "df_test['lead_owner_00'] = df_test['lead_owner'].map(label_map_00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩할 컬럼 목록\n",
    "columns_to_encode = [\"customer_country\",\n",
    "                     \"business_subarea\",\n",
    "                     \"business_area\",\n",
    "                     \"business_unit\",\n",
    "                     \"customer_type\",\n",
    "                     \"enterprise\",\n",
    "                     \"customer_job\",\n",
    "                     \"inquiry_type\",\n",
    "                     \"product_category\",\n",
    "                     \"product_subcategory\",\n",
    "                     \"product_modelname\",\n",
    "                     \"customer_country.1\",\n",
    "                     \"customer_position\",\n",
    "                     \"response_corporate\",\n",
    "                     \"expected_timeline\",\n",
    "                     \"customer_idx\",\n",
    "                     \"lead_owner\"\n",
    "                     ]\n",
    "\n",
    "df_train_encoded = df_train.copy()\n",
    "df_test_encoded = df_test.copy()\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    df_train_encoded[col] = df_train_encoded[col].astype('category')\n",
    "    df_test_encoded[col] = df_test_encoded[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟인코딩을 통해 범주형 변수들 수치형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "smoothing1_list = ['enterprise','response_corporate','business_unit','business_area', 'customer_country.1']\n",
    "smoothing2_list = ['lead_owner', 'customer_idx', 'customer_country']\n",
    "smoothing3_list = [item for item in columns_to_encode if item not in smoothing1_list + smoothing2_list]\n",
    "\n",
    "for col in smoothing1_list:\n",
    "    encoders = {col: TargetEncoder(smoothing=1) for col in smoothing1_list}\n",
    "    df_train_encoded[col] = encoders[col].fit_transform(df_train_encoded[col], df_train['is_converted'])\n",
    "    df_test_encoded[col] = encoders[col].transform(df_test_encoded[col])\n",
    "\n",
    "for col in smoothing2_list:\n",
    "    encoders = {col: TargetEncoder(smoothing=5) for col in smoothing2_list}\n",
    "    df_train_encoded[col] = encoders[col].fit_transform(df_train_encoded[col], df_train['is_converted'])\n",
    "    df_test_encoded[col] = encoders[col].transform(df_test_encoded[col])\n",
    "\n",
    "for col in smoothing3_list:\n",
    "    encoders = {col: TargetEncoder(smoothing=10) for col in smoothing3_list}\n",
    "    df_train_encoded[col] = encoders[col].fit_transform(df_train_encoded[col], df_train['is_converted'])\n",
    "    df_test_encoded[col] = encoders[col].transform(df_test_encoded[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### com_reg_ver_win_rate 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주형 데이터에 대해서 수치형으로 변환을 함  \n",
    "이에 com_reg_ver_win_rate 결측값에 대한 예측이 가능해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤포레스트의 회귀모델을 이용하여 결측값을 예측하여 결측값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    # 데이터에서 결측치가 없는 행과 결측치가 있는 행 분리\n",
    "    train_data = df[df['com_reg_ver_win_rate'].notna()]\n",
    "    test_data = df[df['com_reg_ver_win_rate'].isna()]\n",
    "\n",
    "    # 'com_reg_ver_win_rate'를 예측하는 데 사용할 피처 선택\n",
    "    features = ['business_area', 'business_unit', 'customer_country.1']   \n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터 준비\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data['com_reg_ver_win_rate']\n",
    "    X_test = test_data[features]\n",
    "\n",
    "    # 랜덤 포레스트 모델 생성 및 훈련\n",
    "    model = RandomForestRegressor(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 모델을 사용해 결측치 예측\n",
    "    predicted_values = model.predict(X_test)\n",
    "\n",
    "    # 예측값으로 결측치 대체\n",
    "    df.loc[df['com_reg_ver_win_rate'].isna(), 'com_reg_ver_win_rate'] = predicted_values\n",
    "\n",
    "\n",
    "# df_train_encoded에 대한 데이터 처리\n",
    "fill_missing_values(df_train_encoded)\n",
    "\n",
    "# df_test_encoded에 대한 데이터 처리\n",
    "fill_missing_values(df_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상관관계와 다중공산성을 판단하여 결측값이 많은 product_modelname 변수와  \n",
    "의미없는 변수라고 생각되는 customer_country 변수에 대해서 drop을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = df_train_encoded.drop(['customer_country','product_modelname'], axis=1)\n",
    "df_test_encoded = df_test_encoded.drop(['customer_country','product_modelname'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59299 entries, 0 to 59298\n",
      "Data columns (total 34 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   bant_submit              59299 non-null  float64\n",
      " 1   business_unit            59299 non-null  float64\n",
      " 2   com_reg_ver_win_rate     59299 non-null  float64\n",
      " 3   customer_idx             59299 non-null  float64\n",
      " 4   customer_type            59299 non-null  float64\n",
      " 5   enterprise               59299 non-null  float64\n",
      " 6   historical_existing_cnt  59299 non-null  float64\n",
      " 7   id_strategic_ver         59299 non-null  float64\n",
      " 8   it_strategic_ver         59299 non-null  float64\n",
      " 9   idit_strategic_ver       59299 non-null  float64\n",
      " 10  customer_job             59299 non-null  float64\n",
      " 11  lead_desc_length         59299 non-null  float64\n",
      " 12  inquiry_type             59299 non-null  float64\n",
      " 13  product_category         59299 non-null  float64\n",
      " 14  product_subcategory      59299 non-null  float64\n",
      " 15  customer_country.1       59299 non-null  float64\n",
      " 16  customer_position        59299 non-null  float64\n",
      " 17  response_corporate       59299 non-null  float64\n",
      " 18  expected_timeline        59299 non-null  float64\n",
      " 19  ver_cus                  59299 non-null  int64  \n",
      " 20  ver_pro                  59299 non-null  int64  \n",
      " 21  ver_win_rate_x           59299 non-null  float64\n",
      " 22  ver_win_ratio_per_bu     59299 non-null  float64\n",
      " 23  business_area            59299 non-null  float64\n",
      " 24  business_subarea         59299 non-null  float64\n",
      " 25  lead_owner               59299 non-null  float64\n",
      " 26  is_converted             59299 non-null  bool   \n",
      " 27  customer_idx_99          59299 non-null  int64  \n",
      " 28  customer_idx_001         59299 non-null  int64  \n",
      " 29  lead_owner_09            59299 non-null  int64  \n",
      " 30  lead_owner_07            59299 non-null  int64  \n",
      " 31  lead_owner_05            59299 non-null  int64  \n",
      " 32  lead_owner_03            59299 non-null  int64  \n",
      " 33  lead_owner_00            59299 non-null  int64  \n",
      "dtypes: bool(1), float64(24), int64(9)\n",
      "memory usage: 15.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오버샘플링 및 언더샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟변수에 대한 값을 변환  \n",
    "(데이터의 오버샘플링과 언더샘플링을 적용하기 위함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 타겟변수에 대한 값 변환\n",
    "df_train_encoded.loc[df_train_encoded['is_converted'] == True, 'is_converted'] = 1\n",
    "df_train_encoded.loc[df_train_encoded['is_converted'] == False, 'is_converted'] = 0\n",
    "\n",
    "df_train_encoded['is_converted'] = df_train_encoded['is_converted'].astype(float)\n",
    "\n",
    "X = df_train_encoded[df_train_encoded.columns.drop('is_converted')]\n",
    "Y = df_train_encoded['is_converted']\n",
    "\n",
    "# X와 Y로 나누기\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_encoded.drop([\"is_converted\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# 오버샘플링과 언더샘플링\n",
    "# SMOTE와 RandomUnderSampler를 파이프라인으로 결합\n",
    "resample = Pipeline([('SMOTE', SMOTE(random_state=0)), \n",
    "                     ('RandomUnderSampler', RandomUnderSampler(random_state=0))])\n",
    "\n",
    "# 데이터에 오버샘플링과 언더샘플링 적용\n",
    "x_train, y_train = resample.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 라이브러리\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "# 보팅\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 스테킹\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성능확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
    "    weighted_F1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        '정확도': [accuracy],\n",
    "        '정밀도': [precision],\n",
    "        '재현율': [recall],\n",
    "        'F1 Score': [F1],\n",
    "        'Weighted F1': [weighted_F1]\n",
    "    })\n",
    "\n",
    "    confusion_df = pd.DataFrame(confusion, index=['True', 'False'], columns=['True', 'False'])\n",
    "\n",
    "    print(\"\\n오차행렬:\")\n",
    "    display(confusion_df)\n",
    "    print(\"평가 지표:\")\n",
    "    display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna를 이용하여 파라미터를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 12:38:59,464] A new study created in memory with name: no-name-7eb99c3a-7549-4ca2-a15e-282b7a1c52bf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 12:39:33,169] Trial 0 finished with value: 0.7916666666666666 and parameters: {'n_estimators': 594, 'max_depth': 49, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 0 with value: 0.7916666666666666.\n",
      "[I 2024-02-24 12:42:38,608] Trial 1 finished with value: 0.7907817442385903 and parameters: {'n_estimators': 968, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 0 with value: 0.7916666666666666.\n",
      "[I 2024-02-24 12:43:00,750] Trial 2 finished with value: 0.7727272727272727 and parameters: {'n_estimators': 118, 'max_depth': 54, 'min_samples_split': 5, 'min_samples_leaf': 5, 'criterion': 'gini', 'bootstrap': False}. Best is trial 0 with value: 0.7916666666666666.\n",
      "[I 2024-02-24 12:43:45,121] Trial 3 finished with value: 0.77191452245966 and parameters: {'n_estimators': 206, 'max_depth': 46, 'min_samples_split': 2, 'min_samples_leaf': 5, 'criterion': 'gini', 'bootstrap': False}. Best is trial 0 with value: 0.7916666666666666.\n",
      "[I 2024-02-24 12:45:08,185] Trial 4 finished with value: 0.7713665943600868 and parameters: {'n_estimators': 510, 'max_depth': 43, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 0 with value: 0.7916666666666666.\n",
      "[I 2024-02-24 12:46:22,549] Trial 5 finished with value: 0.8243243243243243 and parameters: {'n_estimators': 423, 'max_depth': 37, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 5 with value: 0.8243243243243243.\n",
      "[I 2024-02-24 12:47:31,526] Trial 6 finished with value: 0.7782685512367492 and parameters: {'n_estimators': 384, 'max_depth': 34, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'gini', 'bootstrap': True}. Best is trial 5 with value: 0.8243243243243243.\n",
      "[I 2024-02-24 12:49:50,773] Trial 7 finished with value: 0.7943840579710144 and parameters: {'n_estimators': 688, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'bootstrap': True}. Best is trial 5 with value: 0.8243243243243243.\n",
      "[I 2024-02-24 12:50:21,161] Trial 8 finished with value: 0.8213769860375542 and parameters: {'n_estimators': 277, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}. Best is trial 5 with value: 0.8243243243243243.\n",
      "[I 2024-02-24 12:53:00,186] Trial 9 finished with value: 0.8260447035957239 and parameters: {'n_estimators': 980, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}. Best is trial 9 with value: 0.8260447035957239.\n",
      "[I 2024-02-24 12:55:19,013] Trial 10 finished with value: 0.7873873873873873 and parameters: {'n_estimators': 970, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'bootstrap': True}. Best is trial 9 with value: 0.8260447035957239.\n",
      "[I 2024-02-24 12:57:26,973] Trial 11 finished with value: 0.8287671232876712 and parameters: {'n_estimators': 794, 'max_depth': 58, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 12:59:51,708] Trial 12 finished with value: 0.8281250000000001 and parameters: {'n_estimators': 801, 'max_depth': 60, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:02:04,413] Trial 13 finished with value: 0.7939972714870397 and parameters: {'n_estimators': 779, 'max_depth': 60, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:04:28,906] Trial 14 finished with value: 0.828696925329429 and parameters: {'n_estimators': 814, 'max_depth': 59, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:06:41,690] Trial 15 finished with value: 0.7952684258416742 and parameters: {'n_estimators': 821, 'max_depth': 54, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:08:41,381] Trial 16 finished with value: 0.8284883720930233 and parameters: {'n_estimators': 684, 'max_depth': 53, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:10:51,623] Trial 17 finished with value: 0.7710320901994797 and parameters: {'n_estimators': 873, 'max_depth': 56, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:13:02,353] Trial 18 finished with value: 0.8071328015016423 and parameters: {'n_estimators': 640, 'max_depth': 48, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:15:08,323] Trial 19 finished with value: 0.8277535177098496 and parameters: {'n_estimators': 732, 'max_depth': 51, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:17:14,516] Trial 20 finished with value: 0.7706978760294756 and parameters: {'n_estimators': 865, 'max_depth': 57, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:19:14,856] Trial 21 finished with value: 0.8263183357522979 and parameters: {'n_estimators': 682, 'max_depth': 52, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 11 with value: 0.8287671232876712.\n",
      "[I 2024-02-24 13:20:44,962] Trial 22 finished with value: 0.8296224588576961 and parameters: {'n_estimators': 530, 'max_depth': 59, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 22 with value: 0.8296224588576961.\n",
      "[I 2024-02-24 13:22:03,434] Trial 23 finished with value: 0.7943713118474807 and parameters: {'n_estimators': 495, 'max_depth': 59, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 22 with value: 0.8296224588576961.\n",
      "[I 2024-02-24 13:23:46,575] Trial 24 finished with value: 0.8284883720930233 and parameters: {'n_estimators': 599, 'max_depth': 57, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 22 with value: 0.8296224588576961.\n",
      "[I 2024-02-24 13:24:47,833] Trial 25 finished with value: 0.7822944896115629 and parameters: {'n_estimators': 436, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 22 with value: 0.8296224588576961.\n",
      "[I 2024-02-24 13:27:52,569] Trial 26 finished with value: 0.8280318091451292 and parameters: {'n_estimators': 879, 'max_depth': 41, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 22 with value: 0.8296224588576961.\n",
      "[I 2024-02-24 13:29:25,024] Trial 27 finished with value: 0.7934634589196551 and parameters: {'n_estimators': 546, 'max_depth': 56, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 22 with value: 0.8296224588576961.\n",
      "[I 2024-02-24 13:31:47,070] Trial 28 finished with value: 0.8330885952031327 and parameters: {'n_estimators': 747, 'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 28 with value: 0.8330885952031327.\n",
      "[I 2024-02-24 13:33:53,758] Trial 29 finished with value: 0.7927437641723356 and parameters: {'n_estimators': 611, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 28 with value: 0.8330885952031327.\n",
      "[I 2024-02-24 13:36:00,701] Trial 30 finished with value: 0.7950931394820536 and parameters: {'n_estimators': 740, 'max_depth': 49, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 28 with value: 0.8330885952031327.\n",
      "[I 2024-02-24 13:38:45,031] Trial 31 finished with value: 0.8329250367466928 and parameters: {'n_estimators': 915, 'max_depth': 58, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 28 with value: 0.8330885952031327.\n",
      "[I 2024-02-24 13:41:30,883] Trial 32 finished with value: 0.8304836345872009 and parameters: {'n_estimators': 930, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 28 with value: 0.8330885952031327.\n",
      "[I 2024-02-24 13:44:14,442] Trial 33 finished with value: 0.8304836345872009 and parameters: {'n_estimators': 926, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}. Best is trial 28 with value: 0.8330885952031327.\n",
      "[I 2024-02-24 13:48:40,811] Trial 34 finished with value: 0.8335847159376572 and parameters: {'n_estimators': 947, 'max_depth': 54, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 13:52:52,703] Trial 35 finished with value: 0.7939972714870397 and parameters: {'n_estimators': 908, 'max_depth': 52, 'min_samples_split': 2, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 13:57:50,053] Trial 36 finished with value: 0.8332498748122185 and parameters: {'n_estimators': 1000, 'max_depth': 46, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:02:04,341] Trial 37 finished with value: 0.8319116909182137 and parameters: {'n_estimators': 1000, 'max_depth': 45, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:04:52,554] Trial 38 finished with value: 0.7768522577816747 and parameters: {'n_estimators': 938, 'max_depth': 46, 'min_samples_split': 3, 'min_samples_leaf': 5, 'criterion': 'gini', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:07:55,937] Trial 39 finished with value: 0.8052434456928839 and parameters: {'n_estimators': 847, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:11:32,134] Trial 40 finished with value: 0.7823008849557522 and parameters: {'n_estimators': 997, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:15:37,022] Trial 41 finished with value: 0.8319116909182137 and parameters: {'n_estimators': 989, 'max_depth': 45, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:20:09,742] Trial 42 finished with value: 0.8323293172690762 and parameters: {'n_estimators': 953, 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:24:23,357] Trial 43 finished with value: 0.8312468703054582 and parameters: {'n_estimators': 896, 'max_depth': 47, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:28:31,151] Trial 44 finished with value: 0.8262817322050772 and parameters: {'n_estimators': 942, 'max_depth': 37, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:31:16,296] Trial 45 finished with value: 0.8298298298298298 and parameters: {'n_estimators': 953, 'max_depth': 42, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:33:17,464] Trial 46 finished with value: 0.8273453093812374 and parameters: {'n_estimators': 749, 'max_depth': 39, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:35:22,110] Trial 47 finished with value: 0.8071161048689139 and parameters: {'n_estimators': 836, 'max_depth': 43, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 34 with value: 0.8335847159376572.\n",
      "[I 2024-02-24 14:38:15,505] Trial 48 finished with value: 0.8345902463549523 and parameters: {'n_estimators': 900, 'max_depth': 51, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 48 with value: 0.8345902463549523.\n",
      "[I 2024-02-24 14:38:53,053] Trial 49 finished with value: 0.8093896713615023 and parameters: {'n_estimators': 243, 'max_depth': 51, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'bootstrap': False}. Best is trial 48 with value: 0.8345902463549523.\n",
      "[I 2024-02-24 14:41:22,444] Trial 50 finished with value: 0.8355957767722474 and parameters: {'n_estimators': 784, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 14:43:47,512] Trial 51 finished with value: 0.8355957767722474 and parameters: {'n_estimators': 784, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 14:46:05,240] Trial 52 finished with value: 0.8355957767722474 and parameters: {'n_estimators': 781, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 14:48:36,054] Trial 53 finished with value: 0.8355957767722474 and parameters: {'n_estimators': 795, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 14:51:35,298] Trial 54 finished with value: 0.8354302969300453 and parameters: {'n_estimators': 709, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 14:54:50,653] Trial 55 finished with value: 0.8337518834756404 and parameters: {'n_estimators': 709, 'max_depth': 52, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 14:58:08,045] Trial 56 finished with value: 0.8073136427566806 and parameters: {'n_estimators': 785, 'max_depth': 54, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 15:01:08,329] Trial 57 finished with value: 0.8350100603621731 and parameters: {'n_estimators': 659, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 15:04:26,359] Trial 58 finished with value: 0.806375996249414 and parameters: {'n_estimators': 673, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 15:07:53,662] Trial 59 finished with value: 0.8238747553816047 and parameters: {'n_estimators': 644, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 15:11:56,164] Trial 60 finished with value: 0.834256926952141 and parameters: {'n_estimators': 716, 'max_depth': 56, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 15:16:14,409] Trial 61 finished with value: 0.8355957767722474 and parameters: {'n_estimators': 774, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 50 with value: 0.8355957767722474.\n",
      "[I 2024-02-24 15:20:18,755] Trial 62 finished with value: 0.8360160965794768 and parameters: {'n_estimators': 773, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 62 with value: 0.8360160965794768.\n",
      "[I 2024-02-24 15:23:45,434] Trial 63 finished with value: 0.8356854838709676 and parameters: {'n_estimators': 767, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 62 with value: 0.8360160965794768.\n",
      "[I 2024-02-24 15:26:17,526] Trial 64 finished with value: 0.8354302969300453 and parameters: {'n_estimators': 774, 'max_depth': 57, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 62 with value: 0.8360160965794768.\n",
      "[I 2024-02-24 15:29:52,387] Trial 65 finished with value: 0.8361069087241554 and parameters: {'n_estimators': 763, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:32:36,552] Trial 66 finished with value: 0.8080713280150164 and parameters: {'n_estimators': 816, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:35:43,559] Trial 67 finished with value: 0.8344172086043021 and parameters: {'n_estimators': 807, 'max_depth': 58, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:39:12,002] Trial 68 finished with value: 0.8328328328328328 and parameters: {'n_estimators': 849, 'max_depth': 50, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:39:39,225] Trial 69 finished with value: 0.8080336291452591 and parameters: {'n_estimators': 152, 'max_depth': 48, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:42:09,225] Trial 70 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 772, 'max_depth': 56, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:44:57,317] Trial 71 finished with value: 0.8338368580060423 and parameters: {'n_estimators': 759, 'max_depth': 60, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:47:28,083] Trial 72 finished with value: 0.8361069087241554 and parameters: {'n_estimators': 795, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:49:46,454] Trial 73 finished with value: 0.8361069087241554 and parameters: {'n_estimators': 803, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:51:57,555] Trial 74 finished with value: 0.8352644836272041 and parameters: {'n_estimators': 723, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:54:33,987] Trial 75 finished with value: 0.8346774193548387 and parameters: {'n_estimators': 874, 'max_depth': 58, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 65 with value: 0.8361069087241554.\n",
      "[I 2024-02-24 15:57:09,707] Trial 76 finished with value: 0.8362720403022671 and parameters: {'n_estimators': 826, 'max_depth': 57, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 15:59:59,234] Trial 77 finished with value: 0.8349222277972905 and parameters: {'n_estimators': 830, 'max_depth': 57, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:02:14,236] Trial 78 finished with value: 0.8352644836272041 and parameters: {'n_estimators': 627, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:04:01,637] Trial 79 finished with value: 0.7833407177669474 and parameters: {'n_estimators': 567, 'max_depth': 51, 'min_samples_split': 3, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:07:41,594] Trial 80 finished with value: 0.8328298086606243 and parameters: {'n_estimators': 858, 'max_depth': 59, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:11:34,059] Trial 81 finished with value: 0.8340040241448692 and parameters: {'n_estimators': 804, 'max_depth': 54, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:15:05,009] Trial 82 finished with value: 0.8341708542713568 and parameters: {'n_estimators': 698, 'max_depth': 57, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:18:37,615] Trial 83 finished with value: 0.7756886751202449 and parameters: {'n_estimators': 741, 'max_depth': 52, 'min_samples_split': 3, 'min_samples_leaf': 5, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:20:28,990] Trial 84 finished with value: 0.8334172118772017 and parameters: {'n_estimators': 334, 'max_depth': 56, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:25:08,412] Trial 85 finished with value: 0.833922261484099 and parameters: {'n_estimators': 836, 'max_depth': 58, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:29:17,054] Trial 86 finished with value: 0.8344237544036235 and parameters: {'n_estimators': 757, 'max_depth': 54, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:33:28,256] Trial 87 finished with value: 0.8262586377097729 and parameters: {'n_estimators': 796, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:37:22,387] Trial 88 finished with value: 0.8328328328328328 and parameters: {'n_estimators': 876, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:40:36,237] Trial 89 finished with value: 0.8080713280150164 and parameters: {'n_estimators': 816, 'max_depth': 55, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:43:25,818] Trial 90 finished with value: 0.8338368580060423 and parameters: {'n_estimators': 675, 'max_depth': 60, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:46:39,420] Trial 91 finished with value: 0.8323293172690762 and parameters: {'n_estimators': 792, 'max_depth': 52, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:49:38,161] Trial 92 finished with value: 0.8344237544036235 and parameters: {'n_estimators': 740, 'max_depth': 54, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:53:10,094] Trial 93 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 767, 'max_depth': 56, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 76 with value: 0.8362720403022671.\n",
      "[I 2024-02-24 16:57:05,552] Trial 94 finished with value: 0.8366013071895425 and parameters: {'n_estimators': 729, 'max_depth': 53, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 94 with value: 0.8366013071895425.\n",
      "[I 2024-02-24 17:00:56,318] Trial 95 finished with value: 0.8330827067669173 and parameters: {'n_estimators': 734, 'max_depth': 48, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 94 with value: 0.8366013071895425.\n",
      "[I 2024-02-24 17:04:41,261] Trial 96 finished with value: 0.833249370277078 and parameters: {'n_estimators': 694, 'max_depth': 51, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 94 with value: 0.8366013071895425.\n",
      "[I 2024-02-24 17:09:14,067] Trial 97 finished with value: 0.8313253012048193 and parameters: {'n_estimators': 836, 'max_depth': 49, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': False}. Best is trial 94 with value: 0.8366013071895425.\n",
      "[I 2024-02-24 17:13:27,739] Trial 98 finished with value: 0.7930877671668939 and parameters: {'n_estimators': 858, 'max_depth': 59, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'entropy', 'bootstrap': False}. Best is trial 94 with value: 0.8366013071895425.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objectiveExtraTrees(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
    "        , 'max_depth': trial.suggest_int('max_depth', 20, 60)\n",
    "        , 'min_samples_split': trial.suggest_int('min_samples_split', 2, 5)\n",
    "        , 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "        , 'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        , 'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "        , 'random_state': 0\n",
    "    }\n",
    "    \n",
    "    model = ExtraTreesClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred = model.predict(x_val)\n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(lambda trial: objectiveExtraTrees(trial, x_train, y_train, x_val, y_val), n_trials=500)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTrees \n",
    "et_model = ExtraTreesClassifier(\n",
    "    n_estimators=747\n",
    "    , max_depth=50\n",
    "    , min_samples_split=3\n",
    "    , min_samples_leaf=1\n",
    "    , criterion='entropy'\n",
    "    , random_state=0\n",
    ") \n",
    "\n",
    "et_model.fit(x_train, y_train)\n",
    "\n",
    "pred = et_model.predict(x_val)\n",
    "get_clf_eval(y_val, pred)\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_encoded.drop([\"is_converted\", \"id\"], axis=1)\n",
    "\n",
    "test_pred = et_model.predict(x_test)\n",
    "sum(test_pred) # True로 예측된 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTrees \n",
    "et_model = ExtraTreesClassifier(\n",
    "    n_estimators=947\n",
    "    , max_depth=54\n",
    "    , min_samples_split=3\n",
    "    , min_samples_leaf=1\n",
    "    , criterion='entropy'\n",
    "    , random_state=0\n",
    ") \n",
    "\n",
    "et_model.fit(x_train, y_train)\n",
    "\n",
    "pred = et_model.predict(x_val)\n",
    "get_clf_eval(y_val, pred)\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_encoded.drop([\"is_converted\", \"id\"], axis=1)\n",
    "\n",
    "test_pred = et_model.predict(x_test)\n",
    "sum(test_pred) # True로 예측된 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# ExtraTrees \n",
    "et_model = ExtraTreesClassifier(\n",
    "    n_estimators=729\n",
    "    , max_depth=53\n",
    "    , min_samples_split=3\n",
    "    , min_samples_leaf=1\n",
    "    , criterion='entropy'\n",
    "    , random_state=0\n",
    ") \n",
    "\n",
    "et_model.fit(x_train, y_train)\n",
    "\n",
    "pred = et_model.predict(x_val)\n",
    "get_clf_eval(y_val, pred)\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_encoded.drop([\"is_converted\", \"id\"], axis=1)\n",
    "\n",
    "test_pred = et_model.predict(x_test)\n",
    "sum(test_pred) # True로 예측된 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
